Rank,Model,Multi Turn Overall Acc,Base,Miss Func,Miss Param,Long Context
1,Claude-3.5-Sonnet-20241022 (FC),41.00%,55.00%,19.00%,42.50%,47.50%
2,GPT-4o-2024-08-06 (FC),39.12%,58.00%,10.00%,37.00%,51.50%
3,GPT-4-turbo-2024-04-09 (FC),38.12%,54.00%,13.50%,35.50%,49.50%
4,GPT-4o-2024-08-06 (Prompt),37.25%,44.00%,31.50%,29.50%,44.00%
5,o1-preview-2024-09-12 (Prompt),36.88%,47.50%,38.50%,31.50%,30.00%
6,GPT-4o-mini-2024-07-18 (FC),34.12%,47.50%,19.50%,29.00%,40.50%
7,Claude-3-Opus-20240229 (FC),30.25%,41.50%,14.00%,33.50%,32.00%
8,GPT-4-turbo-2024-04-09 (Prompt),30.25%,42.50%,25.00%,20.50%,33.00%
9,o1-mini-2024-09-12 (Prompt),28.25%,40.50%,5.00%,34.50%,33.00%
10,Claude-3-Haiku-20240307 (FC),24.50%,35.50%,11.50%,22.00%,29.00%
11,mistral-large-2407 (FC),23.75%,33.50%,18.00%,23.50%,20.00%
12,GPT-4o-mini-2024-07-18 (Prompt),22.00%,33.00%,12.00%,17.00%,26.00%
13,Gemini-1.5-Pro-002 (FC),21.62%,31.00%,5.00%,21.00%,29.50%
14,Functionary-Medium-v3.1 (FC),21.38%,31.50%,21.00%,26.50%,6.50%
15,Gemini-1.5-Pro-002 (Prompt),20.75%,23.00%,19.50%,17.50%,23.00%
16,GPT-3.5-Turbo-0125 (FC),19.50%,32.50%,11.50%,21.50%,12.50%
17,Gemini-1.5-Flash-001 (Prompt),19.50%,27.50%,20.00%,12.00%,18.50%
18,Gemini-1.5-Pro-001 (Prompt),18.88%,26.00%,5.00%,21.50%,23.00%
19,Qwen2.5-72B-Instruct (Prompt),17.25%,23.50%,20.00%,13.50%,12.00%
20,xLAM-8x22b-r (FC),16.25%,25.50%,16.00%,11.50%,12.00%
21,Gemini-1.5-Pro-001 (FC),16.00%,24.50%,3.00%,15.50%,21.00%
22,xLAM-8x7b-r (FC),15.50%,26.00%,13.00%,11.50%,11.50%
23,Gemini-1.5-Flash-001 (FC),13.87%,19.00%,3.50%,14.00%,19.00%
24,Gemini-1.5-Flash-002 (Prompt),12.50%,17.50%,6.00%,11.50%,15.00%
25,Llama-3.1-70B-Instruct (Prompt),12.38%,16.50%,13.00%,10.50%,9.50%
26,Gemini-1.5-Flash-002 (FC),11.62%,19.00%,0.50%,10.50%,16.50%
27,palmyra-x-004 (FC),11.37%,12.00%,2.50%,18.50%,12.50%
28,xLAM-7b-r (FC),10.00%,16.50%,8.50%,7.50%,7.50%
29,Functionary-Small-v3.1 (FC),9.88%,17.00%,2.50%,14.00%,6.00%
30,claude-3.5-haiku-20241022 (Prompt),9.75%,16.00%,0.50%,8.00%,14.50%
31,Llama-3.1-8B-Instruct (Prompt),9.25%,12.00%,10.00%,7.00%,8.00%
32,Open-Mistral-Nemo-2407 (FC),9.12%,15.00%,3.50%,9.00%,9.00%
33,FireFunction-v2 (FC),8.62%,13.50%,7.00%,11.00%,3.00%
34,mistral-large-2407 (Prompt),8.38%,15.00%,6.00%,6.00%,6.50%
35,ToolACE-8B (FC),7.75%,7.50%,11.50%,5.00%,7.00%
36,Qwen2.5-7B-Instruct (Prompt),7.62%,9.50%,8.50%,7.00%,5.50%
37,Claude-3.5-Sonnet-20241022 (Prompt),7.50%,9.00%,5.50%,5.00%,10.50%
38,Claude-3-Opus-20240229 (Prompt),7.13%,11.50%,2.50%,6.00%,8.50%
39,Meta-Llama-3-70B-Instruct (Prompt),5.62%,10.00%,4.00%,6.00%,2.50%
40,GPT-3.5-Turbo-0125 (Prompt),5.62%,9.00%,2.00%,7.00%,4.50%
41,Hammer2.0-7b (FC),5.50%,9.00%,2.00%,7.00%,4.00%
42,Llama-3.1-8B-Instruct (FC),5.38%,5.00%,7.50%,5.00%,4.00%
43,Llama-3.2-3B-Instruct (Prompt),5.25%,8.50%,2.50%,4.50%,5.50%
44,Llama-3.1-70B-Instruct (FC),4.88%,7.00%,4.00%,4.50%,4.00%
45,DeepSeek-Coder-V2 (FC),4.50%,7.50%,3.00%,4.00%,3.50%
46,GLM-4-9b-Chat (FC),3.50%,3.50%,4.00%,2.50%,4.00%
47,Granite-20b-FunctionCalling (FC),3.38%,6.00%,1.50%,4.50%,1.50%
48,Qwen2-7B-Instruct (Prompt),3.25%,4.00%,4.50%,2.50%,2.00%
49,Gemini-1.0-Pro-002 (FC),2.88%,4.50%,1.00%,3.50%,2.50%
50,Hermes-2-Pro-Mistral-7B (FC),2.63%,3.50%,4.00%,2.50%,0.50%
51,Mistral-small-2402 (FC),2.62%,4.50%,0.00%,3.00%,3.00%
52,MiniCPM3-4B-FC (FC),2.62%,5.00%,1.00%,3.00%,1.50%
53,FireFunction-v1 (FC),2.38%,5.00%,0.00%,2.00%,2.50%
54,Hermes-2-Pro-Llama-3-8B (FC),2.38%,4.50%,1.50%,2.00%,1.50%
55,Gemma-2-27b-it (Prompt),2.38%,4.50%,2.00%,1.50%,1.50%
56,MiniCPM3-4B (Prompt),2.00%,3.00%,3.50%,1.00%,0.50%
57,Command-R-Plus (FC) (Original),2.00%,3.50%,0.00%,1.50%,3.00%
58,Hammer2.0-1.5b (FC),1.75%,2.00%,1.00%,1.50%,2.50%
59,Claude-3-Haiku-20240307 (Prompt),1.62%,3.50%,0.00%,0.00%,3.00%
60,Gemma-2-9b-it (Prompt),1.62%,2.00%,4.00%,0.50%,0.00%
61,Open-Mixtral-8x22b (FC),1.50%,3.50%,0.00%,1.00%,1.50%
62,Open-Mixtral-8x7b (Prompt),1.50%,2.50%,0.00%,1.50%,2.00%
63,Gemini-1.0-Pro-002 (Prompt),1.38%,2.50%,1.50%,0.50%,1.00%
64,Qwen2.5-1.5B-Instruct (Prompt),1.12%,1.50%,2.50%,0.50%,0.00%
65,Nexusflow-Raven-v2 (FC),1.00%,1.50%,0.50%,1.00%,1.00%
66,GoGoAgent,1.00%,1.50%,2.00%,0.50%,0.00%
67,Meta-Llama-3-8B-Instruct (Prompt),0.75%,1.50%,0.00%,1.00%,0.50%
68,Mistral-Small-2402 (Prompt),0.75%,0.50%,0.00%,1.50%,1.00%
69,Hammer2.0-0.5b (FC),0.50%,0.50%,0.00%,0.50%,1.00%
70,Open-Mixtral-8x22b (Prompt),0.50%,1.00%,0.00%,0.00%,1.00%
71,Qwen2-1.5B-Instruct (Prompt),0.50%,0.50%,1.00%,0.00%,0.50%
72,Mistral-Medium-2312 (Prompt),0.38%,1.00%,0.00%,0.00%,0.50%
73,Command-R-Plus (Prompt) (Original),0.38%,1.00%,0.00%,0.00%,0.50%
74,Open-Mistral-Nemo-2407 (Prompt),0.25%,0.50%,0.00%,0.00%,0.50%
75,DeepSeek-Coder-V2-Lite-Instruct (FC),0.12%,0.50%,0.00%,0.00%,0.00%
76,xLAM-1b-fc-r (FC),0.12%,0.50%,0.00%,0.00%,0.00%
77,DBRX-Instruct (Prompt),0.00%,0.00%,0.00%,0.00%,0.00%
78,Gemma-2-2b-it (Prompt),0.00%,0.00%,0.00%,0.00%,0.00%
79,Llama-3.2-1B-Instruct (Prompt),0.00%,0.00%,0.00%,0.00%,0.00%
80,xLAM-7b-fc-r (FC),0.00%,0.00%,0.00%,0.00%,0.00%