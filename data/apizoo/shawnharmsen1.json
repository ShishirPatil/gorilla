[
  {
    "user_name": "example_username_api",
    "api_name": "GPT4All Python API",
    "api_call": "chat_completion(messages, default_prompt_header=True, default_prompt_footer=True, verbose=True, streaming=True, **generate_kwargs)",
    "api_version": "2.0",
    "api_arguments": {
      "messages": "[{'role': 'user', 'content': 'Name 3 colors'}]",
      "default_prompt_header": true,
      "default_prompt_footer": true,
      "verbose": true,
      "streaming": true,
      "generate_kwargs": "{}"
    },
    "functionality": "Text generation",
    "env_requirements": ["gpt4all"],
    "example_code": "import gpt4all\n\nmodel = gpt4all.GPT4All('ggml-gpt4all-j-v1.3-groovy')\nmessages = [{'role': 'user', 'content': 'Name 3 colors'}]\nmodel.chat_completion(messages)",
    "meta_data": {
      "description": "The GPT4All package provides Python bindings and an API to the C/C++ model backend libraries. By default, models are stored in ~/.cache/gpt4all/ (you can change this with model_path). If the file already exists, model download will be skipped.",
      "performance": null
    },
    "questions": [
      "Can you name three colors?",
      "What is the meaning of life?",
      "What is the capital of France?"
    ]
  }
]
