{"code": "###Instruction: I am working on a project where I need to cluster similar images of street art. How can I get the relevant feature vectors from these images for clustering?\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: To extract feature vectors from your street art images, you can load a pre-trained MobileNetV2 model using TensorFlow Hub. This model has been trained on ImageNet and can transform the 224x224 pixel images into 1280-dimensional feature vectors, which can then be fed into a clustering algorithm to group similar images.<<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Create a TensorFlow Sequential model with the MobileNetV2 feature extractor.\nmodel = tf.keras.Sequential([\n  hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                 input_shape=(224,224,3), output_shape=(1280,))\n])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction from images", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "(224, 224, 3)", "output_shape": "(1280,)"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.6.0"}, "example_code": "model = tf.keras.Sequential([\n  hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                 input_shape=(224,224,3), output_shape=(1280,))\n])", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained MobileNetV2 model for extracting feature vectors from images, using TensorFlow Hub."}}
{"code": "###Instruction: We want to develop a simple application where users can take a photo of any object and find the description of it. Help us with creating a model that extracts features from the object's image.\n###Output: <<<domain>>>: image-feature-vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads a pre-trained MobileNet V2 image feature vector model from TensorFlow Hub. This model is trained with 100% depth and an input size of 224x224. It can be used to extract features from images of various objects, which can then be fed into another model for object description generation. Using this model, you can build a simple application that allows users to take a photo and get the description of the object in the image. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Create the feature extraction model\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=(224, 224, 3),\n                   output_shape=[1280],\n                   trainable=False),\n    # Add additional layers as needed for the specific task, e.g., image description generation\n])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction from images", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "[224, 224, 3]", "output_shape": "[1280]"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                    input_shape=(224, 224, 3),\n                    trainable=False),\n    tf.keras.layers.Dense(10, activation='softmax')\n])", "performance": {"dataset": "ImageNet", "accuracy": "71.9%"}, "description": "A pre-trained image feature vector model using MobileNet V2 architecture with 100% depth and 224x224 input size. It can be used for image classification, object detection, and other image-based tasks."}}
{"code": "###Instruction: I have a set of food images and I want to create a model that differentiates between different types of cuisine.\n###Output: <<<domain>>>: image-feature-vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the MobileNet V2 model from TensorFlow Hub, which has been pre-trained on the ImageNet dataset. This model is used for feature extraction from images, and in this case, the images represent different types of cuisine. Once the KerasLayer is created, it can then be used to build a more complex model, such as adding a Dense layer for classifying the different categories of cuisine. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Create the model with the MobileNet V2 feature vector KerasLayer, followed by a Dense layer for classification\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224,224,3), trainable=False),\n    tf.keras.layers.Dense(10, activation='softmax')\n])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction from images", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "[None, 224, 224, 3]", "output_shape": "[None, 1280]"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "model = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=(224,224,3),\n                   trainable=False),\n    tf.keras.layers.Dense(10, activation='softmax')\n])", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "This API provides a feature vector for an image using the MobileNet V2 architecture trained on the ImageNet dataset. The feature vector can be used as input for training other models or for image similarity tasks."}}
{"code": "###Instruction: Show me the right API call to generate image feature vectors using MobileNet V2 architecture so that I can perform a classification task.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a KerasLayer with the pre-trained MobileNet V2 image feature vector model from TensorFlow Hub. This model has been trained on the ImageNet dataset and is efficient for generating image feature vectors, which can then be used for transfer learning or various classification tasks. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmobile_net_layer = hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', output_shape=[1280], trainable=False)\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Generate image feature vectors", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"handle": "https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4", "output_shape": "[1280]", "trainable": "False"}, "python_environment_requirements": ["tensorflow>=2.0.0", "tensorflow-hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                    output_shape=[1280],\n                    trainable=False),\n    tf.keras.layers.Dense(5, activation='softmax')\n])\n\nmodel.build([None, 224, 224, 3])\nmodel.summary()", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained image feature vector model using MobileNet V2 architecture on ImageNet dataset. Can be used for transfer learning and generating image feature vectors."}}
{"code": "###Instruction: My dog is always getting into things that can be dangerous. Can you help me identify the object my dog is about to eat?\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: model = hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call allows you to load a pre-trained image classification model from TensorFlow Hub, specifically using the Inception V3 architecture trained on the ImageNet dataset. With this loaded model, you can classify images, which in this case would involve identifying the object that your dog is about to consume. This can help you determine if the object is potentially harmful to your pet.<<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Image classification using pre-trained models", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v3/classification/5'\nmodel = hub.load(model_id)\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(299, 299))\nimage = tf.keras.preprocessing.image.img_to_array(image)\nimage = tf.expand_dims(image, axis=0)\n\npredictions = model(image)\nprint(predictions)", "performance": {"dataset": "ImageNet", "accuracy": "Not provided"}, "description": "A pre-trained image classification model available on TensorFlow Hub that can be used to classify images into one of the 1000 ImageNet classes. The example provided shows how to load the Inception V3 model, preprocess an image, and obtain predictions."}}
{"code": "###Instruction: A photo is sent to me, and I would like to know what objects are in the photo.\n###Output: <<<domain>>>: Image object detection, <<<api_call>>>: hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained object detection model called SSD Mobilenet V2 from TensorFlow Hub. The model is capable of detecting multiple objects in an image. It has been trained on the COCO dataset, a large-scale dataset for object detection, segmentation, and captioning. Once the model is loaded, it can be used to recognize objects in the given photo by inputting the image tensor. <<<code>>>: import tensorflow_hub as hub\ndetector = hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')\nresult = detector(image_tensor)\n", "api_call": "hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image object detection", "framework": "TensorFlow Hub", "functionality": "Object detection", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nmodel_id = 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'\ndetector = hub.load(model_id)\nresult = detector(image_tensor)", "performance": {"dataset": "COCO", "accuracy": "Not specified"}, "description": "A pre-trained object detection model that can detect multiple objects in an image. The model is based on the SSD Mobilenet V2 architecture and is trained on the COCO dataset."}}
{"code": "###Instruction: Analyze customer reviews and identify positive and negative sentiments, so please convert the text reviews into vectors.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder, which encodes text into high-dimensional vectors. These vectors can be used for various natural language processing tasks, such as text classification, semantic similarity, clustering, and more. In this case, converting text reviews into vectors will help identify positive and negative sentiments of the customer reviews. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['This product is amazing!', 'I am very disappointed with the purchase.'])\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow_hub as hub; embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'); embeddings = embed(['Hello world!'])", "performance": {"dataset": "STS Benchmark", "accuracy": "Pearson correlation coefficient of 0.803"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: Recommend a method to extract image feature vectors with MobileNetV2. \n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: To extract image feature vectors using MobileNetV2, you can use this API call which loads a pre-trained image feature vector model based on the MobileNetV2 architecture trained on the ImageNet dataset. The KerasLayer function is used to create a layer with the model which can process input images of shape (224, 224, 3) and generate feature vectors of shape (1280,). <<<code>>>: model = tf.keras.Sequential([\n  hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224, 224, 3)),\n])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "(224, 224, 3)", "output_shape": "(1280,)"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.6.0"}, "example_code": "model = tf.keras.Sequential([\n  hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224, 224, 3)),\n  tf.keras.layers.Dense(num_classes, activation='softmax')\n])", "performance": {"dataset": "ImageNet", "accuracy": "71.9%"}, "description": "A pre-trained image feature vector model based on MobileNetV2 architecture, trained on ImageNet dataset."}}
{"code": "###Instruction: Write an example code to use a pre-trained model to convert a sentence \"My cat is sitting on the porch\" into high-dimensional vectors.\n###Input: My cat is sitting on the porch\n###Output: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nsentence = \"My cat is sitting on the porch\"\nembeddings = embed([sentence])\nprint(embeddings)", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text classification", "framework": "TensorFlow Hub", "functionality": "Loading", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": {"model_url": "https://tfhub.dev/google/universal-sentence-encoder/4"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.8.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello, world!'])\nprint(embeddings)", "performance": {"dataset": "STSbenchmark", "accuracy": "0.803"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering and other natural language tasks."}}
{"code": "###Instruction: Analyze a collection of images of pets to obtain meaningful features and club them into categories based on their appearance and other characteristics.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the pre-trained MobileNetV2 model from TensorFlow Hub, which is designed to extract feature vectors from images. The model takes an input image and outputs a 1280-dimensional feature vector, which can then be used for transfer learning applications such as categorizing the given pets based on their appearance and characteristics. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Extract feature vectors from images", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_image": "A 224x224x3 RGB image", "output_feature_vector": "A 1x1280 vector"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')\n\n# Preprocess your image, e.g. resize to 224x224 and normalize pixel values\nprocessed_image = ... \n\n# Extract feature vector\nfeature_vector = model(processed_image)", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained MobileNetV2 model that takes an input image and outputs a 1280-dimensional feature vector. Useful for transfer learning applications."}}
{"code": "###Instruction: We are building a model for car brand recognition. Before training, we need to extract features from car images.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call creates a Keras layer that uses the pre-trained MobileNetV2 model on the ImageNet dataset to extract features from images. Since the model has been designed for feature extraction, it takes an input image of shape (224, 224, 3) and produces an output feature vector of shape (1280). This output can then be fed into further layers to recognize car brands. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                  input_shape=(224,224,3),\n                  trainable=False),\n    tf.keras.layers.Dense(NUM_CATEGORIES, activation='softmax')\n])\n\nmodel.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\nmodel.fit(x_train, y_train, epochs=5)\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Extract features from images", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "[224, 224, 3]", "output_shape": "[1280]"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                  input_shape=(224,224,3),\n                  trainable=False),\n    tf.keras.layers.Dense(10, activation='softmax')\n])\n\nmodel.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\nmodel.fit(x_train, y_train, epochs=5)", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A Keras layer that extracts features from images using the MobileNetV2 model trained on ImageNet dataset."}}
{"code": "###Instruction: I have a list of sentences and I want to find which ones are most similar. How can I do that efficiently?\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: By using the Universal Sentence Encoder API call, you can convert your list of sentences into high-dimensional vectors. These dense vectors can then be used for various natural language processing tasks, including finding the semantic similarity between sentences. By comparing the embeddings of each sentence, you can determine which ones are the most similar. <<<code>>>: import tensorflow_hub as hub\n\n# Load Universal Sentence Encoder\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n\n# Encode your list of sentences\ntext = ['This is a sentence.', 'Another sentence.', 'A third example.']\nembeddings = embed(text)\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Convert text into dense vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\ntext = ['This is a sentence.']\nembedding = embed(text)", "performance": {"dataset": "STS benchmark", "accuracy": "0.78 Pearson correlation"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering and other natural language tasks."}}
{"code": "###Instruction: I have a customer service chatbot, and I would like to analyze the similarity between customer queries using NLP.\n###Output: <<<domain>>>: text-embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder model from TensorFlow Hub. This pre-trained model is used for embedding text into a high-dimensional vector, which can be utilized for various natural language processing tasks, including similarity analysis between text inputs like customer queries. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Load the Universal Sentence Encoder model\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n# Create embeddings for a list of texts (e.g., customer queries)\nembeddings = embed(['customer query 1', 'customer query 2'])\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into a high-dimensional vector", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": "URL of the pre-trained model", "python_environment_requirements": "TensorFlow, TensorFlow Hub", "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world'])\nprint(embeddings)", "performance": {"dataset": "SNLI, MultiNLI, and STS Benchmark", "accuracy": "85% on SNLI, 76.9% on MultiNLI, and 0.803 on STS Benchmark"}, "description": "A pre-trained model for embedding text into a high-dimensional vector that can be used for various natural language processing tasks"}}
{"code": "###Instruction: I have hundreds of images and I want to group them in categories, but first I need to extract features from those images.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained MobileNet V2 model from TensorFlow Hub, which has been trained on the ImageNet dataset for feature extraction. Using this as a Keras layer, you can incorporate it into your deep learning model to extract features from input images (represented as tensors). These features can then be used for grouping or clustering the images based on their content. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Define a Keras model using the pre-trained MobileNet V2 feature extractor\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=(224, 224, 3),\n                   trainable=False)\n])\n\n# Provide an image tensor to the model to extract features\nimage_tensor = tf.random.uniform(shape=(1, 224, 224, 3))\nfeatures = model(image_tensor)\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Extract image features", "api_name": "imagenet_mobilenet_v2", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input": "image_tensor", "output": "feature_vector"}, "python_environment_requirements": {"tensorflow": ">=2.0", "tensorflow_hub": ">=0.8"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                    input_shape=(224,224,3),\n                    trainable=False)\n])\n\nimage_tensor = tf.random.uniform(shape=(1, 224, 224, 3))\nfeatures = model(image_tensor)", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained image feature vector model using MobileNet V2 architecture on ImageNet dataset. It can be used to extract features from an input image tensor."}}
{"code": "###Instruction: Analyze the given image dataset containing healthy and unhealthy plants by extracting features using pre-trained MobileNetV2 model.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224, 224, 3), output_shape=(1280,)), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call allows you to create a KerasLayer using the pre-trained MobileNetV2 model on the ImageNet dataset for feature extraction. The model can be used to process images with a shape of (224, 224, 3) and output feature vectors of size (1280,). By leveraging the feature vectors obtained from the images, you can analyze the plant health status represented by the dataset. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\n# Create a model with a single KerasLayer for feature extraction using MobileNetV2 architecture\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=(224, 224, 3),\n                   output_shape=(1280,))\n])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction from images", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "(224, 224, 3)", "output_shape": "(1280,)"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=(224, 224, 3),\n                   output_shape=(1280,))\n])\n\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, 0)\n\nfeatures = model.predict(image_array)", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained model for extracting feature vectors from images using MobileNetV2 architecture trained on ImageNet dataset"}}
{"code": "###Instruction: Find out what's in the image taken by a wildlife photographer, so we can determine the main subject of the picture.\n###Input: An image taken by a wildlife photographer.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call creates a Keras layer using a pre-trained image classification model based on the MobileNetV2 architecture. The model has been trained on the ImageNet dataset and is designed to distinguish between 1000 different classes. Given an image taken by a wildlife photographer, this layer can be used to predict the main subject of the image by classifying it into one of these known classes. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nfrom PIL import Image\nimport numpy as np\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\n])\n\nimage = Image.open('path/to/your/image.jpg').resize((224, 224))\ninput_image = np.array(image) / 255.0\ninput_image = np.expand_dims(input_image, axis=0)\n\npredictions = model.predict(input_image)\npredicted_class = np.argmax(predictions[0])\nprint('Predicted class:', predicted_class)\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Image classification using pre-trained model", "api_name": "imagenet_mobilenet_v2_100_224_classification", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": {"url": "https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0", "numpy": ">=1.19.5", "PIL": ">=8.3.2"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nfrom PIL import Image\nimport numpy as np\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\n])\n\nimage = Image.open('path/to/your/image.jpg').resize((224, 224))\ninput_image = np.array(image) / 255.0\ninput_image = np.expand_dims(input_image, axis=0)\n\npredictions = model.predict(input_image)\npredicted_class = np.argmax(predictions[0])\nprint('Predicted class:', predicted_class)", "performance": {"dataset": "ImageNet", "accuracy": "71.8%"}, "description": "A pre-trained image classification model using MobileNetV2 architecture on ImageNet dataset with 100% depth and 224x224 input size."}}
{"code": "###Instruction: Can you tell me the type of food in this image?\n###Output: <<<domain>>>: Image-classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the pre-trained Inception V3 image classification model from TensorFlow Hub, which has been trained on the ImageNet dataset. This model can be used to classify images into various categories, such as food. To use it, load an image, preprocess it, and then pass the preprocessed image to the model. The result will be a list of predictions where you can decode the top prediction to get the predicted class label for the image. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Load the model\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v3/classification/4'\nmodel = hub.load(model_id)\n\n# Load an image and preprocess it\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(299, 299))\nimage = tf.keras.preprocessing.image.img_to_array(image)\nimage = tf.keras.applications.inception_v3.preprocess_input(image)\n\n# Predict the class\npredictions = model(image[None, ...])\n\n# Get the class label\npredicted_class = tf.keras.applications.inception_v3.decode_predictions(predictions.numpy())[0][0][1]\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Pre-trained image classification model", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/4')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\n# Load the model\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v3/classification/4'\nmodel = hub.load(model_id)\n\n# Load an image and preprocess it\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(299, 299))\nimage = tf.keras.preprocessing.image.img_to_array(image)\nimage = tf.keras.applications.inception_v3.preprocess_input(image)\n\n# Predict the class\npredictions = model(image[None, ...])\n\n# Get the class label\npredicted_class = tf.keras.applications.inception_v3.decode_predictions(predictions.numpy())[0][0][1]", "performance": {"dataset": "ImageNet", "accuracy": "Top-1 Accuracy: 77.9%, Top-5 Accuracy: 93.7%"}, "description": "This API provides a pre-trained image classification model using TensorFlow Hub, which can be used to classify images into various categories. The model is trained on the ImageNet dataset and can be loaded using the `hub.load()` function."}}
{"code": "###Instruction: Identify the semantic theme of the given list of customer support tickets.\n###Input: ['The payment did not go through.', 'Issues with the payment method.', 'I need help with my payment.', 'Unable to complete payment.', 'Payment error encountered.']\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder model that encodes text input into high-dimensional vectors, suitable for understanding natural language tasks. Once the support tickets are encoded into vectors using this model, semantic similarity or clustering can be performed to identify the common theme among them. In this case, the theme appears to be \"payment issues.\" <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Universal Sentence Encoder", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": {"input": "A list of sentences or phrases"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.8.0"}, "example_code": "import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello, world!', 'How are you?'])", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.80"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: I want a system that will read the image of my room and identify all the objects present in the room along with their confidence score.\n###Output: <<<domain>>>: Image-object-detection, <<<api_call>>>: model = hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the pre-trained SSD MobileNet V2 model from TensorFlow Hub, which is suitable for detecting multiple objects in images along with their bounding boxes and confidence scores. The model is trained on the COCO dataset and is capable of detecting various objects in different environments, such as a room. Once the model is loaded, you can pass an image of your room to it and retrieve the detected objects and their confidence scores. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')\n", "api_call": "hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image object detection", "framework": "TensorFlow Hub", "functionality": "Detect objects in images", "api_name": "ssd_mobilenet_v2", "api_call": "hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')", "api_arguments": {"image_tensor": "Input tensor of shape [1, None, None, 3]", "detection_boxes": "Output tensor of shape [1, num_boxes, 4]", "detection_scores": "Output tensor of shape [1, num_boxes]", "detection_classes": "Output tensor of shape [1, num_boxes]", "num_detections": "Output tensor of shape [1]"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.6.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')\n\n# Load image and preprocess\nimage = tf.image.decode_jpeg(tf.io.read_file('path/to/image.jpg'))\nimage = tf.image.resize(image, (300, 300))\nimage = tf.expand_dims(image, axis=0)\n\n# Run object detection\noutput = model(image)\n\n# Extract detection boxes, scores, and classes\nboxes = output['detection_boxes'].numpy()\nscores = output['detection_scores'].numpy()\nclasses = output['detection_classes'].numpy()\nnum_detections = int(output['num_detections'])", "performance": {"dataset": "COCO", "accuracy": "mAP of 22"}, "description": "A pre-trained SSD MobileNet V2 model for object detection in images, capable of detecting multiple objects with bounding boxes and confidence scores. The model is trained on the COCO dataset and achieves a mean average precision (mAP) of 22."}}
{"code": "###Instruction: My company has a database of product descriptions and I want to convert them into vectors for better search functionality.\n###Output: <<<domain>>>: text-embedding, <<<api_call>>>: embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call will load the pre-trained Universal Sentence Encoder (USE) model from TensorFlow Hub. This model can convert text data (like product descriptions) into high-dimensional vectors suitable for various natural language processing tasks, such as similarity and clustering. These embeddings can improve search functionality by allowing the system to find related items based on semantic similarity rather than simple keyword matching. <<<code>>>: import tensorflow_hub as hub\n# Load the Universal Sentence Encoder model\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n# Encode a list of product descriptions (assuming 'product_descriptions' is a list of strings)\nembeddings = embed(product_descriptions)\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into a fixed-size vector", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": "input: Text data", "python_environment_requirements": "TensorFlow, TensorFlow Hub", "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello, world!', 'Embedding with TensorFlow Hub'])", "performance": {"dataset": "Various", "accuracy": "Not specified"}, "description": "A pre-trained model for encoding text into high-dimensional vectors that can be used for various natural language processing tasks."}}
{"code": "###Instruction: I have a project which I need to quickly recognize animals, and I want to use the pre-trained model as a starting point.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call is for a pre-trained image feature vector model using the MobileNetV2 architecture on the ImageNet dataset. The model extracts high-level features from images, which can be used for tasks such as image classification, object detection, and transfer learning. In this case, it can be used as a starting point for a project aimed at quickly recognizing animals in images. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nfeature_extractor = hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224, 224, 3), trainable=False)\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Extract high-level features from images", "api_name": "imagenet-mobilenet_v2_100_224-feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "[None, 224, 224, 3]", "output_shape": "[None, 1280]", "trainable": "False"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=(224, 224, 3), trainable=False),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained image feature vector model using MobileNetV2 architecture on the ImageNet dataset. It extracts high-level features from images and can be used for tasks like image classification, object detection, and transfer learning."}}
{"code": "###Instruction: I need an easy way to sort out thousands of travel photos by recognizing landmarks and other objects.\n###Output: <<<domain>>>: image-classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads a pre-trained image classification model (Mobilenet V2) from TensorFlow Hub. This model can recognize 1000 different classes from the ImageNet dataset. By using this model, you can classify your travel photos based on the recognized landmark and object labels. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'\nmodel = hub.load(model_id)\n\n# Load image and resize\nimage = tf.keras.preprocessing.image.load_img('image_path', target_size=(224, 224))\n# Convert to array\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\n# Expand dimensions for batch processing\nimage_array = tf.expand_dims(image_array, 0)\n\n# Predict\npredictions = model(image_array)\nclass_index = tf.argmax(predictions, axis=-1).numpy()[0]", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Pre-trained image classification models", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'\nmodel = hub.load(model_id)\n\nimage = tf.keras.preprocessing.image.load_img('image_path', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, 0)\n\npredictions = model(image_array)\nclass_index = tf.argmax(predictions, axis=-1).numpy()[0]", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained image classification model using MobileNetV2 architecture, which can recognize 1000 different classes from the ImageNet dataset."}}
{"code": "###Instruction: Develop a mobile application to identify the objects in real-world images and display its category.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: To identify objects in real-world images, you can load the pre-trained MobileNetV2 model from TensorFlow Hub. This model has been trained on the ImageNet dataset and can classify images into a large number of categories. It is both efficient and accurate, so it's well-suited for mobile applications. After loading the model, pass the image through the model to obtain the class predictions. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5')\nimage = tf.keras.preprocessing.image.load_img('path/to/your/image.jpg', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, 0)\npredictions = model(image_array)\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Pre-trained models for image classification", "api_name": "imagenet_mobilenet_v2_130_224_classification", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5')", "api_arguments": {"url": "https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5')\nimage = tf.keras.preprocessing.image.load_img('path/to/your/image.jpg', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, 0)\n\npredictions = model(image_array)\n", "performance": {"dataset": "ImageNet", "accuracy": "94.1%"}, "description": "MobileNetV2 is a family of neural network architectures for efficient on-device image classification and related tasks, originally published by Mark Sandler, et al. This model is pre-trained on the ImageNet dataset and can be used for various image classification tasks."}}
{"code": "###Instruction: I need to analyze user feedback and compare it to a list of predefined topics.\n###Output: <<<domain>>>: text-embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder model from TensorFlow Hub, which is used for embedding text into high-dimensional vectors. The resulting vectors can be used for various natural language tasks such as text classification, semantic similarity, clustering, and comparison with predefined topics. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\ntext_input = ['This is a sample text']\nvector_output = embed(text_input)", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": "input_text", "python_environment_requirements": "tensorflow, tensorflow_hub", "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\ntext_input = ['This is a sample text']\nvector_output = embed(text_input)", "performance": {"dataset": "STS Benchmark", "accuracy": "0.803"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: We need to recognize the flowers in the pictures from our botanical garden.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: model = hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the pre-trained Inception V3 image classification model from TensorFlow Hub. The model has been trained on the ImageNet dataset and can be used to classify images into different categories. Once the model is loaded, you can use it to recognize flowers in the pictures by passing the images through the model and obtaining the predicted class labels. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(299, 299))\nimage = tf.keras.preprocessing.image.img_to_array(image)\nimage = tf.expand_dims(image, 0)\npredictions = model(image)\nprint(predictions)\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading pre-trained models", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v3/classification/5'\nmodel = hub.load(model_id)\n\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(299, 299))\nimage = tf.keras.preprocessing.image.img_to_array(image)\nimage = tf.expand_dims(image, 0)\n\npredictions = model(image)\nprint(predictions)", "performance": {"dataset": "ImageNet", "accuracy": "Not specified"}, "description": "Load a pre-trained image classification model from TensorFlow Hub and use it to predict the class of an input image."}}
{"code": "###Instruction: I want a solid text preprocessing method to make my model more efficient in dealing with different texts.\n###Output: <<<domain>>>: text-preprocessing, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/nnlm-en-dim128/2'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: By using the Keras Layer API call, you load a Natural Language Model (NNLM) with an embedding dimension of 128. Developed by TensorFlow Hub, it allows you to preprocess your text in a robust way. You can integrate this pre-trained model into your custom model for better text processing and improved efficiency. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Create a model using NNLM as KerasLayer for text preprocessing\nmodel = tf.keras.Sequential([hub.KerasLayer(handle=\"https://tfhub.dev/google/nnlm-en-dim128/2\")])", "api_call": "hub.KerasLayer('https://tfhub.dev/google/nnlm-en-dim128/2')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text preprocessing", "framework": "TensorFlow Hub", "functionality": "Loading", "api_name": "tensorflow_hub.KerasLayer", "api_call": "hub.KerasLayer('https://tfhub.dev/google/nnlm-en-dim128/2')", "api_arguments": {"handle": "A string, the handle of the Hub module to load", "kwargs": "Optional keyword arguments"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.8.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer(handle=\"https://tfhub.dev/google/nnlm-en-dim128/2\")\n])", "performance": {"dataset": "NNLM", "accuracy": "N/A"}, "description": "Loads a TensorFlow Hub module as a Keras Layer, allowing users to incorporate pre-trained models into their own custom models."}}
{"code": "###Instruction: A fashion store wants to categorize newly arrived clothes into different classes. Please make sure the right category is assigned to each clothing item.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained MobileNet V2 image classification model from TensorFlow Hub. The model has been trained on the ImageNet dataset and is capable of classifying images into different classes. For the fashion store's purpose, the model can be used to categorize newly arrived clothing items into different classes based on the visual features of the images. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\n# Load the pre-trained MobileNet V2 model\nmodel_id = 'https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4'\nmodel = hub.load(model_id)\n", "api_call": "hub.load('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4'\nmodel = hub.load(model_id)", "performance": {"dataset": "ImageNet", "accuracy": "71.8%"}, "description": "Load a pre-trained image classification model from TensorFlow Hub and use it to classify images."}}
{"code": "###Instruction: To match clothes in my wardrobe, I need to extract features from images and organize them based on similarity.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call creates a Keras layer using the pre-trained MobileNet v2 model for feature extraction from images. The layer is designed to extract 1280-dimensional feature vectors from images with dimensions (224, 224, 3). Once the features are extracted, they can be used to organize and match clothes in your wardrobe based on similarity. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224, 224, 3), trainable=False),\n])", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction from images", "api_name": "imagenet-mobilenet_v2_100_224-feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"handle": "https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.6.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=(224, 224, 3),\n                   trainable=False),\n    tf.keras.layers.Dense(num_classes, activation='softmax')\n])\n\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\nhistory = model.fit(train_batches, epochs=10, validation_data=validation_batches)", "performance": {"dataset": "ImageNet", "accuracy": "71.9%"}, "description": "This module uses MobileNet v2 architecture for image feature vector extraction. It takes an input image of shape (224, 224, 3) and outputs a 1280-dimensional feature vector."}}
{"code": "###Instruction: We will launch a new product that relies on user reviews, analyze reviews, and generate insights based on their sentiments.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: embed = hub.load('https://tfhub.dev/google/tf2-preview/nnlm-en-dim50/1'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained text embedding model from TensorFlow Hub. The model is used to convert text data (such as user reviews) into fixed-size vectors that can be used as input for machine learning models. Loading this model allows you to perform encoding of user reviews in order to analyze their sentiment and generate insights about the product based on these reviews. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Load the model\nmodel_id = 'https://tfhub.dev/google/tf2-preview/nnlm-en-dim50/1'\nembed = hub.load(model_id)\n# Embed a sample review\nembeddings = embed(['This product is amazing!'])\n", "api_call": "hub.load('https://tfhub.dev/google/tf2-preview/nnlm-en-dim50/1')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embed text data for machine learning models", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/tf2-preview/nnlm-en-dim50/1')", "api_arguments": {"model_id": "A string representing the URL or path to the TensorFlow Hub model"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/tf2-preview/nnlm-en-dim50/1'\nembed = hub.load(model_id)\nembeddings = embed(['Hello, world!'])\nprint(embeddings)", "performance": {"dataset": "Wikipedia", "accuracy": "Not specified"}, "description": "Load a pre-trained text embedding model from TensorFlow Hub, and use it to convert text data into fixed-size vectors that can be used as input for machine learning models."}}
{"code": "###Instruction: Find me an API that will help me extract features of my images for building a recommendation system.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=[batch_size, 224, 224, 3]), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call provided loads a pre-trained image feature vector model using the MobileNet V2 architecture from TensorFlow Hub. This model has been trained on the ImageNet dataset for image classification tasks, and when used as a KerasLayer, it can extract features from images with an input shape of [batch_size, 224, 224, 3]. These extracted features can then be used to build a recommendation system. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224, 224, 3))])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Extract image features", "api_name": "imagenet-mobilenet_v2_100_224-feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "[batch_size, 224, 224, 3]", "output_shape": "[batch_size, 1280]"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224, 224, 3))\n])\n\nimage = tf.zeros([1, 224, 224, 3])  # A batch of one 224x224x3 image\nfeatures = model(image)  # Features with shape [batch_size, 1280]", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained image feature vector model based on MobileNetV2 architecture for image classification tasks."}}
{"code": "###Instruction: I want to extract important features from car images of different angles to predict the brand of the car.\n###Output: <<<domain>>>: image-feature-vector, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the MobileNet V2 model from TensorFlow Hub, which has been pre-trained on the ImageNet dataset. The model can be used for extracting feature vectors from car images of different angles. Once loaded, you can pass images to the model to obtain the feature vectors, which can then be used to predict the brand of the car. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Load the pre-trained MobileNet V2 model\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')\n# Pass an image (assuming 'image' is a TensorFlow tensor representing your car image) to extract features\nimage = tf.zeros([1, 224, 224, 3])\nfeatures = model(image)\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Load and use a pre-trained image feature vector model", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"url": "https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')\n\nimage = tf.zeros([1, 224, 224, 3])\nfeatures = model(image)", "performance": {"dataset": "ImageNet", "accuracy": "71.8%"}, "description": "This module uses the MobileNet v2 architecture to generate image feature vectors. The model has been pre-trained on the ImageNet dataset and can be used for various image classification tasks."}}
{"code": "###Instruction: I want to create a phone cover design recommendation system. For that, I need to get some features of cover images.\n\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v1_100_224/feature_vector/4', input_shape=[224, 224, 3]), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: To extract features from images of phone covers, you can use the TensorFlow Hub API call to load the MobileNet V1 model. This model has been pretrained on the ImageNet dataset and is designed for feature extraction from images. Once created, this KerasLayer can be used as part of your recommendation system pipeline to extract features from each phone cover image with the input size of 224x224x3. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v1_100_224/feature_vector/4', input_shape=[224, 224, 3], trainable=False)])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v1_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction from images", "api_name": "imagenet_mobilenet_v1_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v1_100_224/feature_vector/4')", "api_arguments": {"input_shape": "[None, 224, 224, 3]", "output_shape": "[None, 1024]"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "model = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v1_100_224/feature_vector/4', input_shape=[224, 224, 3], trainable=False),\n    tf.keras.layers.Dense(10, activation='softmax')\n])", "performance": {"dataset": "ImageNet", "accuracy": "70.9%"}, "description": "A compact representation of the API for extracting image feature vectors using MobileNetV1 on TensorFlow Hub."}}
{"code": "###Instruction: We are trying to group tweets with similar emotions. How can we represent the text in the tweet so we can quantify the similarity among tweets?\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: To represent the text in tweets, you can use the Universal Sentence Encoder, which transforms text into high-dimensional vectors. These vectors can be used for various natural language processing tasks like text classification, semantic similarity, clustering, etc. By getting the embeddings for different tweets, you can quantify their similarity and group them accordingly.<<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow_hub as hub; embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'); embeddings = embed(['Hello world'])", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.78"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering and other natural language tasks. The model is trained and optimized for greater-than-word length text, such as sentences, phrases or short paragraphs."}}
{"code": "###Instruction: We are planning a security system for a warehouse, and we need to know the objects in our surveillance feed.\n###Output: <<<domain>>>: Image-object-detection, <<<api_call>>>: hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Single Shot MultiBox Detector (SSD) with MobileNet V2 model from TensorFlow Hub. This model is pre-trained to detect objects in images. Once loaded, you can input an image as a tensor to the detector, which will output the detected objects along with their bounding boxes, class labels, and associated confidence scores. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel_id = 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'\ndetector = hub.load(model_id)\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg')\ninput_tensor = tf.keras.preprocessing.image.img_to_array(image)\nresults = detector(input_tensor)\n", "api_call": "hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image object detection", "framework": "TensorFlow Hub", "functionality": "Detect objects in images", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'\ndetector = hub.load(model_id)\n\n# Load an image\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg')\n\n# Convert the image to a tensor\ninput_tensor = tf.keras.preprocessing.image.img_to_array(image)\n\n# Run the object detection\nresults = detector(input_tensor)", "performance": {"dataset": "COCO", "accuracy": "Not specified"}, "description": "A pre-trained TensorFlow Hub model for detecting objects in images using the Single Shot MultiBox Detector (SSD) with MobileNet V2."}}
{"code": "###Instruction: For arranging my documents, I want to compute the semantic similarity between a set of sentences.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call is for loading the Universal Sentence Encoder model from TensorFlow Hub. This model converts text into high-dimensional vectors, which can be used for various natural language tasks, including computing semantic similarity between sentences. Once the model is loaded, it can be used to embed sentences to get the respective vectors, which can then be compared to find the similarity. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text data", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world!'])", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation of 0.78"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for various natural language processing tasks."}}
{"code": "###Instruction: I would like to group similar user reviews together. To do this, I need to transform the text reviews into high dimensional vectors.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder model that is designed to convert text into high-dimensional vectors. These vectors can be used in various natural language processing tasks, such as text classification, semantic similarity, and clustering. In your case, the vectors will help group similar user reviews together by transforming the text reviews into high-dimensional representations. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": "input_text", "python_environment_requirements": "tensorflow, tensorflow_hub", "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world!'])\nprint(embeddings)", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.78"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: I need to find if a word is a positive or negative sentiment. I need to process my text before feeding it to my sentiment analysis model.\n###Output: <<<domain>>>: Text preprocessing, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder model from TensorFlow Hub. The model can be used to encode the input text into high-dimensional vectors which can then be utilized for various natural language processing tasks, including sentiment analysis. Preprocessing the text using this model will ensure that the input is in an appropriate format for further analysis. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text preprocessing", "framework": "TensorFlow Hub", "functionality": "Text preprocessing", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": {"input": "List of sentences"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.8.0"}, "example_code": "import tensorflow_hub as hub; embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'); embeddings = embed(['sample sentence'])", "performance": {"dataset": "Various datasets", "accuracy": "Not mentioned"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: I have a collection of photos I took while on vacation, and I want to know what objects are in each photo.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: model = hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: You can use the pre-trained Inception V3 model from TensorFlow Hub to classify objects in your vacation photos. The model is trained on the ImageNet dataset and has an accuracy of 78.1%. Once the model is loaded, you can preprocess your images and pass them through the model to get predictions of the objects present in the images. <<<code>>>: import tensorflow_hub as hub\n\nmodel = hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/4')\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/4')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v3/classification/4'\nmodel = hub.load(model_id)\nimage = tf.keras.preprocessing.image.load_img('path/to/your/image.jpg', target_size=(299, 299))\ninput_image = tf.keras.preprocessing.image.img_to_array(image)\ninput_image = tf.expand_dims(input_image, 0)\npredictions = model(input_image)\npredicted_class = tf.argmax(predictions[0]).numpy()", "performance": {"dataset": "ImageNet", "accuracy": "78.1%"}, "description": "This example demonstrates how to load a pre-trained Inception V3 model from TensorFlow Hub and use it to classify an image. The model has been trained on the ImageNet dataset and achieves 78.1% accuracy."}}
{"code": "###Instruction: Create a list of similar art pictures by comparing the feature vectors of the existing art images.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=[224, 224, 3]), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call uses the MobileNet V2 model pretrained on the ImageNet dataset from TensorFlow Hub. This model can be used for extracting feature vectors from images with a shape of [224, 224, 3]. You can create a KerasLayer with this API and then use it to obtain feature vectors for your art images. By comparing these feature vectors, you can find similar art images in your collection. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=[224, 224, 3])])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction from images", "api_name": "imagenet-mobilenet_v2_100_224-feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "[224, 224, 3]", "output_shape": "[1280]"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "model = tf.keras.Sequential([\n  hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=[224, 224, 3], output_shape=[1280]),\n  tf.keras.layers.Dense(num_classes, activation='softmax')\n])", "performance": {"dataset": "ImageNet", "accuracy": "71.9%"}, "description": "This model extracts feature vectors from images using the MobileNetV2 architecture trained on the ImageNet dataset. The input images should have a shape of [224, 224, 3] and the output feature vectors have a shape of [1280]."}}
{"code": "###Instruction: Discover a person's sentiment after reading their review\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder from TensorFlow Hub, which is a pre-trained text embedding model that converts sentences into fixed-size vectors. These vectors can be used for a variety of natural language processing tasks, such as sentiment analysis on a person's review. Once you have the text embeddings, you can perform a sentiment analysis model or algorithm to determine their sentiment. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world'])", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text data", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": "text_input", "python_environment_requirements": "tensorflow>=2.0, tensorflow_hub", "example_code": "import tensorflow_hub as hub; embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'); embeddings = embed(['Hello world']); print(embeddings)", "performance": {"dataset": "STS Benchmark", "accuracy": "0.8"}, "description": "A pre-trained text embedding model that converts sentences into fixed-size vectors, suitable for various NLP tasks."}}
{"code": "###Instruction: We have several images of clothing items and want to differentiate them by their features. Generate a model that will create a feature vector for each item.\n###Output: <<<domain>>>: image-feature-vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224,224,3), trainable=False), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained image feature extraction model, MobileNet V2, from TensorFlow Hub. The KerasLayer takes an input shape of (224, 224, 3), appropriate for feeding images of this size. You can use this layer in your model to convert input images into 1280-dimensional feature vectors, representing the images' distinctive characteristics. These feature vectors can then be used for tasks such as classification, clustering, or similarity search. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nnum_classes = <number_of_classes>\n# Define a model using the pre-trained MobileNet V2\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224, 224, 3), trainable=False),\n    tf.keras.layers.Dense(num_classes, activation='softmax')\n])\n# Compile the model\nmodel.compile(optimizer=tf.keras.optimizers.Adam(),\n              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction from images", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "[None, 224, 224, 3]", "output_shape": "[None, 1280]"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "model = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                    input_shape=(224,224,3),\n                    trainable=False),\n    tf.keras.layers.Dense(num_classes, activation='softmax')\n])\nmodel.compile(optimizer=tf.keras.optimizers.Adam(),\n              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])", "performance": {"dataset": "ImageNet", "accuracy": "71.9%"}, "description": "A pre-trained model that takes an image input and outputs a 1280-dimensional feature vector representing the image, which can be used for various tasks such as classification, clustering, and similarity search."}}
{"code": "###Instruction: Create a mobile app that takes a photo of a plant and identifies its species. To do this, use an image classifier to process the photo.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained TensorFlow image classification model using the MobileNet V2 architecture with an input size of 224x224 pixels. The model can be used to classify objects in images into multiple categories, which can help identify plant species in images. Once the model is loaded, it can be used to process plant photos taken by the mobile app to classify plants. <<<code>>>: import tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Pre-trained model for image classification", "api_name": "imagenet_mobilenet_v2_130_224_classification", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')", "api_arguments": {"model_url": "https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4"}, "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')\n\n# Load and preprocess an image\nimage = tf.keras.preprocessing.image.load_img('path/to/your/image.jpg', target_size=(224, 224))\ninput_array = tf.keras.preprocessing.image.img_to_array(image)\ninput_array = tf.expand_dims(input_array, 0)\ninput_array = input_array / 255.0\n\n# Make predictions\npredictions = model(input_array)\n\n# Get the top predicted class\npredicted_class = tf.argmax(predictions, axis=-1).numpy()[0]", "performance": {"dataset": "ImageNet", "accuracy": "Top-1 accuracy of 80.1% and Top-5 accuracy of 95.1%"}, "description": "A pre-trained model for image classification using MobileNetV2 architecture with an input size of 224x224 pixels."}}
{"code": "###Instruction: I want to use an API to find the degree of similarity between sentences. Firstly, I need to obtain their high-dimensional vector representations.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the Universal Sentence Encoder model, which encodes text into high-dimensional vectors. These vectors can be used for various language tasks, including assessing the semantic similarity between sentences. Once you have the vector representations of the sentences, the degree of similarity between them can be calculated. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow_hub as hub; embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'); embeddings = embed(['Hello world!']); print(embeddings)", "performance": {"dataset": "STSbenchmark", "accuracy": "0.803"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering and other natural language tasks."}}
{"code": "###Instruction: Let's observe a random street to identify various elements like cars, people and street signs in a photo.\n###Output: <<<domain>>>: Image object detection, <<<api_call>>>: detector = hub.load('https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained Faster R-CNN model with an Inception-ResNet-v2 feature extractor from TensorFlow Hub. The model is trained on the OpenImages V4 dataset for object detection. Once loaded, you can pass an image to the detector and it will output detected objects, their class labels, and associated confidence scores. This can be used to identify various elements like cars, people, and street signs in a street photo. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\ndetector = hub.load('https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1')", "api_call": "hub.load('https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image object detection", "framework": "TensorFlow Hub", "functionality": "Detect objects in an image", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1'\ndetector = hub.load(model_id)\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg')\nimage_np = tf.keras.preprocessing.image.img_to_array(image)\ninput_tensor = tf.convert_to_tensor(image_np)\ninput_tensor = input_tensor[tf.newaxis, ...]\n\noutput_dict = detector(input_tensor)\n\nfor i in range(output_dict['detection_scores'][0].shape[0]):\n    if output_dict['detection_scores'][0][i] > 0.5:\n        print(output_dict['detection_class_entities'][0][i].numpy().decode('utf-8'), ':', output_dict['detection_scores'][0][i].numpy())", "performance": {"dataset": "OpenImages V4", "accuracy": "mAP@0.5IOU: 37.6%"}, "description": "A pre-trained Faster R-CNN model with Inception-ResNet-v2 feature extractor on OpenImages V4 dataset for object detection."}}
{"code": "###Instruction: Organize my photos taken during the vacation by identifying what the photo is showing.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: You can organize your vacation photos using a pre-trained image classification model. This particular API call loads the MobileNetV2 model for classifying images into 1000 different categories. Once the model is loaded as a Keras layer, you can build a classification model and use it to categorize your vacation photos based on their content.-1049.61071\n<<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer(\"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4\")\n])", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Image classification using pre-trained models", "api_name": "imagenet_mobilenet_v2", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": {"module_url": "https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4", "input_shape": "[None, 224, 224, 3]", "output_shape": "[None, 1001]"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer(\"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4\")\n])\n\n# Prepare an image\nimage = tf.keras.preprocessing.image.load_img(\"path/to/your/image.jpg\", target_size=(224, 224))\ninput_array = tf.keras.preprocessing.image.img_to_array(image)\ninput_array = tf.expand_dims(input_array, 0)\n\n# Make a prediction\npredictions = model.predict(input_array)\n", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained image classification model using MobileNetV2 architecture on ImageNet dataset. It can be used for classifying images into 1000 different categories."}}
{"code": "###Instruction: Create a document classifier, and identify the genre of a movie poster by classifying the image content.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: model = hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained image classification model that uses the Inception V3 architecture from TensorFlow Hub. The model has been trained on ImageNet, allowing it to classify images into various categories. In this scenario, the model can be used to analyze the content of movie posters and classify the images based on their genre. <<<code>>>: import tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Image classification using pre-trained models", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v3/classification/5'\nmodel = hub.load(model_id)\nimage = tf.keras.preprocessing.image.load_img('image.jpg', target_size=(299, 299))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_tensor = tf.expand_dims(image_array, 0)\n\npredictions = model(image_tensor)\n", "performance": {"dataset": "ImageNet", "accuracy": "Not specified"}, "description": "This API allows users to perform image classification using pre-trained models from TensorFlow Hub. Users can load a model using its model_id and then use it to classify images."}}
{"code": "###Instruction: Develop a model that will extract feature vectors from images, which we will use later to classify the images.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call uses TensorFlow Hub to load the MobileNetV2 architecture pre-trained on the ImageNet dataset to extract 1280-dimensional feature vectors from images. By using this pre-trained model as a KerasLayer, you can integrate it into custom neural network architectures or use it for transfer learning. The resulting feature vectors can be used to classify the images in various applications. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=(224, 224, 3),\n                   trainable=False)\n])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Extract features from images", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "[batch_size, height, width, 3]", "output_shape": "[batch_size, 1280]"}, "python_environment_requirements": {"tensorflow": ">=2.0", "tensorflow_hub": ">=0.12"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=(224, 224, 3),\n                   trainable=False)\n])\n\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_batch = tf.expand_dims(image_array, 0)\n\nfeatures = model.predict(image_batch)", "performance": {"dataset": "ImageNet", "accuracy": "71.9%"}, "description": "Extracts a 1280-dimensional feature vector from images using the MobileNetV2 architecture trained on the ImageNet dataset."}}
{"code": "###Instruction: I want to build a mobile image recognition app to identify the species of birds in images. Suggest a suitable pre-trained model.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: model = hub.load('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/2'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: A suitable pre-trained model for building a mobile image recognition app is MobileNet_v2. This model is optimized for mobile devices and has achieved an accuracy of 71.8% on the ImageNet dataset. The API call loads the pre-trained model from TensorFlow Hub, which can be used to identify bird species in your images. <<<code>>>: import tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/2')\n", "api_call": "hub.load('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/2')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading pre-trained models", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/2')", "api_arguments": {"model_id": "string"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.6.0"}, "example_code": "import tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/2')", "performance": {"dataset": "ImageNet", "accuracy": "71.8%"}, "description": "Load a pre-trained image classification model from TensorFlow Hub, providing a model_id for the desired model."}}
{"code": "###Instruction: Explain how to create a image classification model using a pre-trained MobileNetV2 model as a feature extractor.\n###Output: To create an image classification model using a pre-trained MobileNetV2 model as a feature extractor, you can use TensorFlow and TensorFlow Hub along with a Keras layer that wraps the model. Here's a step-by-step guide:\n\n1. Import the required TensorFlow and TensorFlow Hub modules.\n2. Create a sequential Keras model.\n3. Add a `hub.KerasLayer` with the MobileNetV2 model's URL, which is 'https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', as its parameter.\n4. Set the `input_shape` to (224, 224, 3), as the model expects input images of size 224x224x3.\n5. You can set the `trainable` parameter of the Keras layer to `False` if you don't want to fine-tune the model.\n6. Add a `Dense` layer to the model with the desired number of output classes and an appropriate activation function, like 'softmax'.\n7. Compile and train the model with your dataset.\n\nHere's sample code for implementing the above steps:\n\n```python\nimport tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=(224, 224, 3),\n                   trainable=False),\n    tf.keras.layers.Dense(10, activation='softmax')\n])\n```\nThis code creates a Keras model with a pre-trained MobileNetV2 feature extractor for image classification using the extracted 1280-dimensional feature vector.", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction", "api_name": "imagenet-mobilenet_v2_100_224-feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "[None, 224, 224, 3]", "output_shape": "[None, 1280]"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.6.0"}, "example_code": "model = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                    input_shape=(224, 224, 3),\n                    trainable=False),\n    tf.keras.layers.Dense(10, activation='softmax')\n])", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A Keras layer that wraps a pre-trained MobileNetV2 model for feature extraction. It takes an input image of size 224x224x3 and outputs a 1280-dimensional feature vector."}}
{"code": "###Instruction: There are comments written by users in different languages, and we want to calculate the similarity between pairs of comments.\n###Output: <<<domain>>>: text-embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: By loading the Universal Sentence Encoder (USE) model from TensorFlow Hub, you will be able to encode text into high-dimensional vectors. These vectors can be used for various natural language processing tasks, including text classification, semantic similarity, clustering, etc. In this case, the embeddings of the comments will be used to calculate the similarity between pairs of comments. <<<code>>>: import tensorflow_hub as hub\n# Load the Universal Sentence Encoder model\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n# Obtain embeddings for given comments (assuming comments are in 'comment_list')\nembeddings = embed(comment_list)\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Loading", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["url"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world'])", "performance": {"dataset": "STSbenchmark", "accuracy": "Pearson correlation coefficient of 0.78"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering and other natural language tasks. The model is trained and optimized for greater-than-word length text, such as sentences, phrases or short paragraphs."}}
{"code": "###Instruction: Analyze large data sets containing various customer reviews. Transform the text from these reviews into vectors for further analysis like sentiment, similar phrases, and other natural language processing tasks.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call uses the Universal Sentence Encoder which is a pre-trained model designed to embed text into high-dimensional vectors. When applied to customer reviews, these text embeddings can be utilized in various natural language processing tasks such as sentiment analysis, semantic similarity detection, and classification. This makes it possible to efficiently analyze and interpret large datasets of text. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world'])", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.78"}, "description": "A pre-trained model for embedding text into high-dimensional vectors that can be used for a wide range of tasks such as sentiment analysis, semantic similarity, and classification."}}
{"code": "###Instruction: I am visiting the Metropolitan Museum of Art and want to quickly identify the category or genre of the artwork by taking a picture of it.\n###Output: <<<domain>>>: image-classification, <<<api_call>>>: model = hub.load('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the pre-trained MobileNet V2 model for image classification from TensorFlow Hub. The model has been trained on the ImageNet dataset and is capable of classifying images into various categories. When you take a picture of the artwork at the Metropolitan Museum of Art, you can preprocess the image and use this model to classify it into categories or genres. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Load the MobileNet V2 model for image classification\nmodel = hub.load('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4')\n", "api_call": "hub.load('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading", "api_name": "mobilenet_v2_100_224", "api_call": "hub.load('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4')", "api_arguments": "URL of the model", "python_environment_requirements": "tensorflow, tensorflow_hub", "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4')\ninput_image = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(224, 224))\ninput_tensor = tf.keras.preprocessing.image.img_to_array(input_image)\ninput_tensor = tf.expand_dims(input_tensor, 0)\ninput_tensor = tf.keras.applications.mobilenet_v2.preprocess_input(input_tensor)\npredictions = model(input_tensor)\n", "performance": {"dataset": "ImageNet", "accuracy": "71.9%"}, "description": "Pre-trained image classification model using MobileNetV2 architecture with input size of 224x224 pixels."}}
{"code": "###Instruction: Could you provide an embedding for my sentence to be used in semantic similarity analysis?\n###Input: Someone is learning how to use a Python library.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the Universal Sentence Encoder from TensorFlow Hub, which is a pre-trained model for generating text embeddings. These embeddings can then be used for a variety of natural language processing tasks such as semantic similarity, text classification, and clustering. In this case, an embedding will be generated for the input sentence and can be used for semantic similarity analysis. <<<embedding_code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nsentence = \"Someone is learning how to use a Python library.\"\nembedding = embed([sentence])\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Generate embeddings for text", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello, world!'])", "performance": {"dataset": "Various", "accuracy": "N/A"}, "description": "A pre-trained model for generating text embeddings using the Universal Sentence Encoder. It can be used for various NLP tasks like semantic similarity, text classification, and clustering."}}
{"code": "###Instruction: Identify the objects in the image for an image indexing system.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads a pre-trained image classification model (MobileNetV2) from TensorFlow Hub, which is capable of classifying images into 1000 different categories. By providing an input image to the model, it can predict the object or objects present in the image, which can be used for an image indexing system. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Pre-trained image classification models", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'\nmodel = hub.load(model_id)\n\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, axis=0)\n\npredictions = model(image_array)\n", "performance": {"dataset": "ImageNet", "accuracy": "71.9%"}, "description": "A pre-trained image classification model from TensorFlow Hub that can classify images into 1000 different categories using the MobileNetV2 architecture."}}
{"code": "###Instruction: We want to create an app that can recognize furniture in images. Find an API that can help us.\n###Output: <<<domain>>>: Image object detection, <<<api_call>>>: hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: You can use the SSD MobileNet V2 model, which is a pre-trained object detection model available on TensorFlow Hub. This model can detect multiple objects in an image, including furniture items. You can load the model and input an image to obtain detections and object labels. The detected objects and their labels can then be used to recognize furniture in the images.<<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel_id = 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'\n# Load the SSD MobileNet V2 model\ndetector = hub.load(model_id)\n# Load an image (assuming 'path/to/image.jpg' contains your image)\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg')\ninput_image = tf.keras.preprocessing.image.img_to_array(image)\ninput_image = tf.expand_dims(input_image, 0)\n# Detect objects in the image\ndetections = detector(input_image)\n", "api_call": "hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image object detection", "framework": "TensorFlow Hub", "functionality": "Detect objects in an image", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nmodel_id = 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'\ndetector = hub.load(model_id)\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg')\ninput_image = tf.keras.preprocessing.image.img_to_array(image)\ninput_image = tf.expand_dims(input_image, 0)\ndetections = detector(input_image)", "performance": {"dataset": "COCO", "accuracy": "Not specified"}, "description": "A pre-trained object detection model that can detect multiple objects in an image using TensorFlow Hub."}}
{"code": "###Instruction: Transform a list of product titles into numerical vectors to perform sentiment analysis.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the Universal Sentence Encoder model from TensorFlow Hub. This model is designed to encode text into high-dimensional vectors. In this scenario, the text is a list of product titles, and we will use these vectors to perform sentiment analysis on them. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into a high-dimensional vector", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": {"input": "List of strings"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow_hub as hub; embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'); embeddings = embed(['Hello world!']); print(embeddings)", "performance": {"dataset": "STSbenchmark", "accuracy": "85.1%"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: Create a model that can extract features of an image to use in a fashion-based recommendation system.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call creates a Keras layer using the pre-trained MobileNetV2 model from TensorFlow Hub. This model is designed to extract image features from input images with a shape of (batch_size, 224, 224, 3). The extracted feature vectors can then be used to create a fashion-based recommendation system by comparing the feature vectors of different clothing items. The model has been trained on the ImageNet dataset and achieves 71.8% accuracy.<<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224, 224, 3), trainable=False)\n])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Extract image features", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "[batch_size, 224, 224, 3]", "output_shape": "[batch_size, 1280]"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224, 224, 3), trainable=False)\n])\n\nfeatures = model(images)", "performance": {"dataset": "ImageNet", "accuracy": "71.8%"}, "description": "This API provides a pre-trained MobileNetV2 model for extracting image features. It takes an input image of shape (batch_size, 224, 224, 3) and returns a feature vector of shape (batch_size, 1280). The model is trained on the ImageNet dataset and achieves 71.8% accuracy."}}
{"code": "###Instruction: We are building an app to help people categorize their personal photos into categories. We need to extract features from the images.\n\n###Output: <<<domain>>>: Image-feature-vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained image feature vector model from TensorFlow Hub based on the MobileNetV2 architecture. This architecture is optimized for performance on mobile devices and other resource-constrained environments. When integrated into a TensorFlow Keras model, it can be used to extract high-level image features from input images, which can be used to categorize personal photos into various categories. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224, 224, 3))\n])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction from images", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "(224, 224, 3)", "output_shape": "(1280,)"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow-hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224, 224, 3))\n])\n\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, 0)\n\nfeatures = model.predict(image_array)", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained image feature vector model based on MobileNetV2 architecture, which is optimized for performance on mobile devices and other resource-constrained environments. It can be used for various image classification tasks, transfer learning, or as a feature extractor for other models."}}
{"code": "###Instruction: Design a machine learning model to recognize dog breeds. We need a feature extractor from MobileNet V2 trained on ImageNet dataset.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads a pre-trained image feature vector model based on the MobileNet V2 architecture with an input size of 224x224, trained on the ImageNet dataset. This feature extractor can be used for various image recognition tasks, including recognizing dog breeds from images. By using this pre-trained model, we save time and resources compared to training a new model from scratch.<<<code>>>: import tensorflow_hub as hub\nfeature_extractor = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Loading pre-trained model", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": "URL of the pre-trained model", "python_environment_requirements": "tensorflow, tensorflow_hub", "example_code": "", "performance": {"dataset": "ImageNet", "accuracy": ""}, "description": "A pre-trained image feature vector model using MobileNet V2 architecture with input size 224x224 and trained on ImageNet dataset."}}
{"code": "###Instruction: I want to find the similarity between user-generated restaurant reviews, so I need to transform these reviews into an appropriate format.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call allows you to load the Universal Sentence Encoder model from TensorFlow Hub, which is designed to encode text into high-dimensional vectors. These vectors can then be used for tasks such as text classification, semantic similarity, clustering, and other natural language processing activities. In this case, the model can be used to transform user-generated restaurant reviews into embeddings that can be compared for similarities. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text data", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world!'])\nprint(embeddings)", "performance": {"dataset": "STS Benchmark", "accuracy": "Pearson correlation coefficient of 0.77"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: Compile a report on ongoing political conflicts in the Middle East, using an embedding to identify the key topics.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: In order to identify the key political conflict topics in the Middle East, you could use the Universal Sentence Encoder to create high-dimensional vectors of related text. These embeddings can then be used for clustering, semantic similarity and other natural language tasks to recognize and group the main subjects present in the data. To create the embeddings, load the Universal Sentence Encoder model from TensorFlow Hub and process the text input. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['text input goes here'])\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": "text_input", "python_environment_requirements": "tensorflow, tensorflow_hub", "example_code": "import tensorflow_hub as hub; embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'); embeddings = embed(['Hello world!'])", "performance": {"dataset": "STS", "accuracy": "Pearson correlation coefficient of 0.78"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks. The model is trained and optimized for greater-than-word length text, such as sentences, phrases, or short paragraphs."}}
{"code": "###Instruction: Our school wants to analyse students' Reddit comments to find relevant topics. We need vectors to represent their comments for further processing.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The Universal Sentence Encoder API provided by TensorFlow Hub can be used to create high-dimensional vector representations of students' Reddit comments. These vectors can then be used for further analysis and topic extraction. To generate embeddings for the comments, load the pre-trained model and pass the text data to the model. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Load the Universal Sentence Encoder model\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n# Obtain embeddings for the comments (assuming 'comments' is a list of Reddit comment texts)\nembeddings = embed(comments)\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world!'])\nprint(embeddings)", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.803"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: Recommend me what type of plants are suitable for my garden based on the image input from the garden.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: To classify an image of your garden and recommend suitable plants, you can use the pre-trained MobileNetV2 model from TensorFlow Hub. The model is useful for image classification tasks and has been trained on the ImageNet dataset. By loading the model and passing an image of your garden, it will generate predictions for plant categories (if available) in the dataset, which can be used for recommendations. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Load the pre-trained MobileNetV2 model\nmodel = hub.load('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4')\n# Prepare the image (assuming 'garden_image' is a TensorFlow tensor representing the input image)\nimage = tf.keras.preprocessing.image.img_to_array(garden_image)\nimage_array = tf.expand_dims(image, 0)\n# Make predictions using the loaded model\npredictions = model(image_array)", "api_call": "hub.load('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading pre-trained models for image classification", "api_name": "mobilenet_v2", "api_call": "hub.load('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4')", "api_arguments": "URL of the pre-trained model", "python_environment_requirements": "tensorflow, tensorflow_hub", "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4')\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, 0)\npredictions = model(image_array)\n", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained MobileNetV2 model for image classification using TensorFlow Hub"}}
{"code": "###Instruction: I am building a chatbot for a cosmetics store and want to understand the semantic similarity between different customer queries.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder from TensorFlow Hub. It is a text embedding model that encodes text into 512-dimensional vectors, trained on various data sources and tasks. By using this model, you can embed different customer queries and compute their semantic similarity by calculating the cosine similarity or other similarity metrics between the generated embeddings. This can help in determining the relevance and relatedness of the queries in a chatbot for a cosmetics store. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Text embedding model", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": {"input": "List of sentences"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.8.0"}, "example_code": "import tensorflow_hub as hub; embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'); embeddings = embed(['Hello, world!'])", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation of 0.78"}, "description": "A text embedding model that encodes text into 512-dimensional vectors, trained on a variety of data sources and tasks."}}
{"code": "###Instruction: From a collection of images, we want to extract a feature vector for each image using MobileNetV2.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call utilizes a pre-trained MobileNetV2 model from TensorFlow Hub to extract feature vectors from images. The input images should be 224x224 in size with 3 color channels. Once the API call is executed, it will return a feature vector with 1280 dimensions for each image, which can be further used for various machine learning tasks. <<<code>>>: import numpy as np\nimport tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=[224, 224, 3])\n])\n\nimage = np.random.rand(1, 224, 224, 3).astype(np.float32)\nfeature_vector = model.predict(image)\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction from images", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "[None, 224, 224, 3]", "output_shape": "[None, 1280]"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import numpy as np\nimport tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n  hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=[224, 224, 3])\n])\n\nimage = np.random.rand(1, 224, 224, 3).astype(np.float32)\nfeature_vector = model.predict(image)\nprint(feature_vector.shape)", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "This API provides a pre-trained MobileNetV2 model for extracting feature vectors from images. The input images should have a size of 224x224 and 3 color channels. The output feature vector has a dimension of 1280."}}
{"code": "###Instruction: Find and display Cosine Similarity between two different sentences.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder model. This model is able to encode text into high-dimensional vectors that can be used for various natural language processing tasks, such as semantic similarity. Once both sentences are converted into their respective embeddings, we can calculate the cosine similarity between the two sentence vectors to measure their similarity. <<<code>>>: import numpy as np\nimport tensorflow_hub as hub\nfrom sklearn.metrics.pairwise import cosine_similarity\n\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n\nsentence1 = \"Enter your first sentence here\"\nsentence2 = \"Enter your second sentence here\"\n\nvector1 = embed([sentence1])\nvector2 = embed([sentence2])\n\ncosine_sim = cosine_similarity(vector1, vector2)\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world'])\nprint(embeddings)", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.80"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks. The model is trained and optimized for greater-than-word length text, such as sentences, phrases, or short paragraphs."}}
{"code": "###Instruction: Help me measure the semantic similarity between two sentences, so I can find how closely related they are in meaning.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder model from TensorFlow Hub, which is designed to convert text into high-dimensional vectors. These vectors can then be used to measure the semantic similarity between sentences by computing the cosine similarity or other distance metrics. By doing so, sentences with similar meanings will have a higher similarity score, and you can determine how closely related they are in meaning. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embed text data", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world'])", "performance": {"dataset": "STSbenchmark", "accuracy": "Pearson correlation coefficient of 0.803"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: Transform the following text into its corresponding high-dimensional vector: \"I love exploring new places and trying different cuisines.\"\n###Input: I love exploring new places and trying different cuisines.\n###Output: To obtain the high-dimensional vector for the given text, load the Universal Sentence Encoder from TensorFlow Hub and run the input text through it:\n\n```python\nimport tensorflow_hub as hub\n\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['I love exploring new places and trying different cuisines.'])\n\nprint(embeddings)\n```\n\nThe output will be the high-dimensional vector representation of the input text.", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into a high-dimensional vector", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world'])", "performance": {"dataset": "STS Benchmark", "accuracy": "0.803"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: To build an image recognition system, we need a pre-trained model to extract features from images. Provide the API call for this.\n\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call uses TensorFlow Hub to load a pre-trained image feature vector model, specifically the MobileNet V2 model trained on the ImageNet dataset. It generates image feature vectors that can be employed for transfer learning to build an image recognition system. The `hub.KerasLayer` makes it easy to integrate the model into a Keras sequential model. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   output_shape=[1280],\n                   trainable=False),\n    tf.keras.layers.Dense(5, activation='softmax')\n])\nmodel.build([None, 224, 224, 3])", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Generate image feature vectors", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"handle": "https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4", "output_shape": "[1280]", "trainable": "False"}, "python_environment_requirements": ["tensorflow>=2.0.0", "tensorflow-hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                    output_shape=[1280],\n                    trainable=False),\n    tf.keras.layers.Dense(5, activation='softmax')\n])\n\nmodel.build([None, 224, 224, 3])\nmodel.summary()", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained image feature vector model using MobileNet V2 architecture on ImageNet dataset. Can be used for transfer learning and generating image feature vectors."}}
{"code": "###Instruction: I have a list of sentences that I want to preprocess and make ready to be fed to a machine learning model. Can you do that?\n###Output: <<<domain>>>: Text preprocessing, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The Universal Sentence Encoder from TensorFlow Hub can be used to preprocess text by encoding it into high-dimensional vectors. These vectors can then be used as input for various natural language processing tasks such as text classification, semantic similarity, clustering, and more. By loading the model and passing your list of sentences to it, you'll obtain the embeddings that can be used for further analysis. <<<code>>>: import tensorflow_hub as hub\n# Load the Universal Sentence Encoder\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n# Get embeddings for the list of sentences (replace `['Hello, world!', 'How are you?']` with your list of sentences)\nembeddings = embed(['Hello, world!', 'How are you?'])\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text preprocessing", "framework": "TensorFlow Hub", "functionality": "Text preprocessing module", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello, world!', 'How are you?'])", "performance": {"dataset": "Multiple", "accuracy": "N/A"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: We are developing a chatbot, and we need to find the semantically similar sentences from a dataset.\n###Output: <<<domain>>>: text-embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder from TensorFlow Hub, which encodes text into high-dimensional vectors that can be used for various natural language processing tasks, such as semantic similarity. Once loaded, you can pass a list of sentences to the embed function to obtain their respective embeddings. These embeddings can then be used for comparing and finding semantically similar sentences. <<<code>>>: import tensorflow_hub as hub\n# Load the Universal Sentence Encoder\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n# Obtain embeddings for a list of sentences\nembeddings = embed(['Hello world!'])\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into a high-dimensional vector", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text: A list of strings to be embedded"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow_hub as hub; embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'); embeddings = embed(['Hello world!'])", "performance": {"dataset": "STSbenchmark", "accuracy": "Pearson correlation of 0.803"}, "description": "The Universal Sentence Encoder encodes text into a high-dimensional vector that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: I am inspecting images of license plates and need to check which ones have plates on them\n###Output: <<<domain>>>: Image object detection, <<<api_call>>>: detector = hub.load('https://tfhub.dev/google/openimages_v4/ssd/mobilenet_v2/1'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained object detection model from TensorFlow Hub that is based on the SSD MobileNet V2 architecture. The model is capable of detecting various objects in images, including license plates. Once the model is loaded, you can pass an image to it, and it will return a list of detected objects, their class labels, and bounding box coordinates associated with high confidence scores. You can use this information to determine whether a license plate is present in a given image. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\ndetector = hub.load('https://tfhub.dev/google/openimages_v4/ssd/mobilenet_v2/1')\n\n# Load an image tensor and perform object detection\n# Replace 'path/to/image.jpg' with the actual file path of the image containing the license plate\nimage_tensor = tf.image.decode_jpeg(tf.io.read_file('path/to/image.jpg'))\nimage_tensor = tf.expand_dims(image_tensor, 0)\nresult = detector(image_tensor)\nprint(result)\n", "api_call": "hub.load('https://tfhub.dev/google/openimages_v4/ssd/mobilenet_v2/1')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image object detection", "framework": "TensorFlow Hub", "functionality": "Detect objects in images", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/openimages_v4/ssd/mobilenet_v2/1')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow>=2.0", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/openimages_v4/ssd/mobilenet_v2/1'\ndetector = hub.load(model_id)\n\nimage_tensor = tf.image.decode_jpeg(tf.io.read_file('path/to/image.jpg'))\nimage_tensor = tf.expand_dims(image_tensor, 0)\n\nresult = detector(image_tensor)\nprint(result)", "performance": {"dataset": "Open Images v4", "accuracy": "0.545 mAP"}, "description": "A pre-trained image object detection model based on the SSD architecture with MobileNetV2 as the backbone. The model is capable of detecting objects in images and returning their class labels and bounding box coordinates."}}
{"code": "###Instruction: As a programmer, I want to analyze images and determine what objects are in them.\n###Output: <<<domain>>>: Image object detection, <<<api_call>>>: hub.load('https://tfhub.dev/google/openimages_v4/ssd_mobilenet_v2/1'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the SSD MobileNet V2 model from TensorFlow Hub. The model is pre-trained on the Open Images v4 dataset and specializes in object detection. It detects objects within images provided as inputs and outputs both their bounding boxes and the associated class labels with confidence scores. This allows you to analyze images and determine what objects are present within them. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\ndetector = hub.load('https://tfhub.dev/google/openimages_v4/ssd_mobilenet_v2/1')\nresult = detector(image, score_threshold=0.5)\n", "api_call": "hub.load('https://tfhub.dev/google/openimages_v4/ssd_mobilenet_v2/1')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image object detection", "framework": "TensorFlow Hub", "functionality": "Detect objects in images", "api_name": "ssd_mobilenet_v2", "api_call": "hub.load('https://tfhub.dev/google/openimages_v4/ssd_mobilenet_v2/1')", "api_arguments": "image, score_threshold", "python_environment_requirements": "Python 3, TensorFlow 2.x, TensorFlow Hub", "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\ndetector = hub.load('https://tfhub.dev/google/openimages_v4/ssd_mobilenet_v2/1')\nresult = detector(image, score_threshold=0.5)", "performance": {"dataset": "Open Images v4", "accuracy": "mAP@0.5IOU = 32.8%"}, "description": "A pre-trained SSD MobileNet V2 model for object detection in images, trained on the Open Images v4 dataset. Detects objects and outputs their bounding boxes and class labels with associated confidence scores."}}
{"code": "###Instruction: I have a few news articles and I want to see if they're similar. I need a tool to determine the similarity between them.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: Using the Universal Sentence Encoder, you can encode the text of the news articles into high-dimensional vectors. These vectors can then be compared to check the semantic similarity between the articles. The model is highly efficient and can be used for multiple natural language processing tasks including text classification, clustering, and semantic similarity. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world!'])", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.803"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for a wide range of tasks such as semantic similarity, text classification, clustering, and other natural language processing tasks."}}
{"code": "###Instruction: I need to find similar listings for an Airbnb property, can you find its vector representation for further comparison?\n###Output: <<<domain>>>: text-embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: To find a vector representation of an Airbnb property description, you can use the Universal Sentence Encoder provided by TensorFlow Hub. This model encodes text into high-dimensional vectors, which are useful for several natural language tasks, including semantic similarity comparison. You can then use the vector to compare it with other Airbnb listing embeddings to find similar properties. <<<code>>>: import tensorflow_hub as hub\n# Load the Universal Sentence Encoder\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n# Get the embedding of the Airbnb property description (assuming 'property_description' is a string containing the description)\nproperty_embedding = embed([property_description])\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": "input_text", "python_environment_requirements": "tensorflow, tensorflow_hub", "example_code": "import tensorflow_hub as hub; embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'); embeddings = embed(['Hello world!']); print(embeddings)", "performance": {"dataset": "multiple", "accuracy": "varies"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: Extract useful information from an image for further processing by minimizing the input.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/inception_v3/feature_vector/5'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call provides you with a pre-trained model that extracts feature vectors from images using the Inception V3 architecture. Feature vectors summarize important visual information in the image for further processing while reducing the complexity of the input. The model is implemented as a Keras layer that can be used in a TensorFlow Keras model. The example code shows how to create a Keras model using the Inception V3 feature extractor and how to preprocess and predict features from a given image. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/inception_v3/feature_vector/5',\n                   input_shape=(299, 299, 3),\n                   trainable=False)\n])\n\nimage = tf.keras.preprocessing.image.load_img('path/to/your/image.jpg', target_size=(299, 299))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, 0)\n\nfeatures = model.predict(image_array)\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/inception_v3/feature_vector/5')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction from images", "api_name": "image_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/inception_v3/feature_vector/5')", "api_arguments": "input_shape, input_tensor, trainable, output_shape", "python_environment_requirements": "tensorflow, tensorflow_hub", "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/inception_v3/feature_vector/5',\n                   input_shape=(299, 299, 3),\n                   trainable=False)\n])\n\nimage = tf.keras.preprocessing.image.load_img('path/to/your/image.jpg', target_size=(299, 299))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, 0)\n\nfeatures = model.predict(image_array)", "performance": {"dataset": "ImageNet", "accuracy": "78.1%"}, "description": "A pre-trained model that extracts feature vectors from images using Inception V3 architecture"}}
{"code": "###Instruction: We need to incorporate an API to differentiate between species of flowers.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_050_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: To differentiate between species of flowers, you can use the pre-trained MobileNetV2-based feature extraction model from TensorFlow Hub. This model will provide useful feature vectors from input images of flowers. You can then use these extracted feature vectors in a supervised machine learning algorithm or a neural network classifier to train a model that differentiates between different flower species. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Create a Keras model using MobileNetV2-based feature extraction\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_050_224/feature_vector/4',\n                   input_shape=(224, 224, 3),\n                   trainable=False),\n    tf.keras.layers.Dense(10, activation='softmax') # Adjust the output layer according to the number of flower species\n])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_050_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction from images", "api_name": "imagenet_mobilenet_v2_050_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_050_224/feature_vector/4')", "api_arguments": {"input_shape": "[224, 224, 3]", "output_shape": "[1280]"}, "python_environment_requirements": {"tensorflow": ">= 2.0", "tensorflow_hub": ">= 0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_050_224/feature_vector/4',\n                   input_shape=(224, 224, 3),\n                   trainable=False),\n    tf.keras.layers.Dense(10, activation='softmax')\n])", "performance": {"dataset": "ImageNet", "accuracy": "Not specified"}, "description": "A pre-trained image feature vector model that extracts useful features from input images using the MobileNetV2 architecture with a width multiplier of 0.5 and an input size of 224x224 pixels."}}
{"code": "###Instruction: We have customer reviews and need to categorize them. Convert the text into a compatible form for machine learning analysis.\n###Output: <<<domain>>>: text-embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder from TensorFlow Hub. The model can convert text into high-dimensional vectors (512-dimensional) that are suitable for machine learning tasks like semantic similarity, classification, or clustering. To categorize customer reviews, you can pass the review text as a list of strings to the encoder, and it will return the embeddings that can be used in further analysis. <<<code>>>: import tensorflow_hub as hub\n# Load the Universal Sentence Encoder\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n# Generate embeddings for a list of customer reviews (assuming 'reviews' is a list of strings containing the review text)\nembeddings = embed(reviews)\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text for machine learning tasks", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": {"input": "A list of strings"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.8.0"}, "example_code": "import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['hello world', 'my name is John'])", "performance": {"dataset": "STS benchmark", "accuracy": "0.803"}, "description": "A text embedding model that converts text into high-dimensional vectors for use in various machine learning tasks. The Universal Sentence Encoder encodes text into 512-dimensional vectors that can be used for tasks such as semantic similarity, classification, or clustering."}}
{"code": "###Instruction: Can you tell me the breed of my dog if I send you a picture of it? \n###Output: <<<domain>>>: Image classification, <<<api_call>>>: model = hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained image classification model (Inception V3) from TensorFlow Hub, trained on the ImageNet dataset. To determine the breed of your dog, you can load an image of your dog, preprocess it to fit the model's input size requirements (299x299), feed the image into the model, and retrieve its prediction. Keep in mind that this model is trained on ImageNet and may not specifically recognize all dog breeds. It's possible that it may classify your dog's image into a broader or more general category, but it might still be helpful for identifying the breed. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Load and use pre-trained models for image classification", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v3/classification/5'\nmodel = hub.load(model_id)\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(299, 299))\nimage = tf.keras.preprocessing.image.img_to_array(image)\nimage = tf.expand_dims(image, axis=0)\npredictions = model(image)\n", "performance": {"dataset": "ImageNet", "accuracy": "N/A"}, "description": "Load and use a pre-trained image classification model from TensorFlow Hub to classify images."}}
{"code": "###Instruction: I need to sort my photos into different folders, based on what the main object is in each photo.\n###Output: <<<domain>>>: image-classification, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4', input_shape=(224, 224, 3), trainable=True), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call creates a KerasLayer using the pre-trained MobileNet V2 image classification model from TensorFlow Hub. Once integrated into a model, you can input images of size (224, 224, 3) and obtain the predicted class labels of the main objects in those images. This will help you sort your photos into different folders based on the most prominent objects. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'\nmodel = tf.keras.Sequential([hub.KerasLayer(model_id, input_shape=(224, 224, 3), trainable=True)])\n\nimage = tf.keras.preprocessing.image.load_img('path/to/your/image.jpg', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, 0)\npredictions = model.predict(image_array)\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Pre-trained models for image classification", "api_name": "model_id", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": ["model_id", "input_shape", "trainable"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'\nmodel = tf.keras.Sequential([\n    hub.KerasLayer(model_id, input_shape=(224, 224, 3), trainable=True)\n])\n\nimage = tf.keras.preprocessing.image.load_img('path/to/your/image.jpg', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, 0)\npredictions = model.predict(image_array)\n", "performance": {"dataset": "ImageNet", "accuracy": "Top-1 Accuracy: 71.0%, Top-5 Accuracy: 90.1%"}, "description": "Pre-trained image classification models available on TensorFlow Hub for easy integration and usage."}}
{"code": "###Instruction: I want to make a recommendation system for similar images, can you recommend an API for image feature extraction?\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API provides an image feature extraction model based on the MobileNetV2 architecture trained on the ImageNet dataset. It takes input images of shape (224, 224, 3), and outputs a 1280-dimensional feature vector that represents the image's visual information, which can be used for your recommendation system for similar images. Example code to use this model: <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=(224, 224, 3),\n                   output_shape=(1280,),\n                   trainable=False)\n])", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction from images", "api_name": "imagenet-mobilenet_v2_100_224-feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "[batch_size, 224, 224, 3]", "output_shape": "[batch_size, 1280]"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=(224, 224, 3),\n                   output_shape=(1280,),\n                   trainable=False)\n])", "performance": {"dataset": "ImageNet", "accuracy": "71.9%"}, "description": "This API provides a feature vector for images using the MobileNetV2 architecture trained on the ImageNet dataset. The input images should have shape (224, 224, 3), and the output feature vector has 1280 dimensions. The model is available on TensorFlow Hub and can be used for transfer learning applications."}}
{"code": "###Instruction: Analyze the following list of tweets and create a vector to find if two of them have similar meaning.\n###Input: [\"I love going to the beach\", \"The beach is my favorite place to visit\", \"What a good day for ice cream\"]\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: You can use the Universal Sentence Encoder from TensorFlow Hub to create a high-dimensional vector for each tweet in the list. This model is designed for embedding sentences and phrases, making it suitable for comparing tweets. Once you have the embeddings, you can use them to compute the similarity between any two tweets, which could indicate similar meanings. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed([\"I love going to the beach\", \"The beach is my favorite place to visit\", \"What a good day for ice cream\"])\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": "input_text", "python_environment_requirements": "tensorflow, tensorflow_hub", "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello, world!', 'My name is John Doe.'])", "performance": {"dataset": "STS Benchmark", "accuracy": "0.803"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks. The model is trained and optimized for greater-than-word length text, such as sentences, phrases, or short paragraphs."}}
{"code": "###Instruction: I need to analyze numerous article headlines and sort them based on their similarity.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the pre-trained Universal Sentence Encoder model from TensorFlow Hub. The model is designed to convert sentences into fixed-size vector representations, which can be used for efficient semantic similarity calculations and other natural language processing tasks. Once the model is loaded, you can pass text data to the model to get the embeddings and then use them to analyze and sort the article headlines based on their similarity. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n# Calculate embeddings for the given texts (example with two sentences)\nembeddings = embed(['Hello, world!', 'Embed text with Universal Sentence Encoder'])\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Text embedding using a pre-trained model", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow_hub as hub; embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'); embeddings = embed(['Hello, world!', 'Embed text with Universal Sentence Encoder'])", "performance": {"dataset": "various", "accuracy": "N/A"}, "description": "A pre-trained text embedding model that converts sentences into fixed-size vector representations, enabling efficient semantic similarity calculations and other natural language processing tasks."}}
{"code": "###Instruction: We want to know which animal we will find in the picture taken during our vacation.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4', input_shape=(224, 224, 3)), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call creates a KerasLayer using the pre-trained MobileNet V2 model for image classification from TensorFlow Hub. It has an input shape of (224, 224, 3), which is compatible with the model. Once this layer is set up, you can pass a vacation image through the model, and it will classify the animal found in it. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel_id = 'https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'\nmodel = tf.keras.Sequential([hub.KerasLayer(model_id, input_shape=(224, 224, 3))])", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Pre-trained models for image classification", "api_name": "model_id", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": {"model_id": "string", "input_shape": "tuple", "trainable": "boolean"}, "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'\nmodel = tf.keras.Sequential([\n    hub.KerasLayer(model_id, input_shape=(224, 224, 3))\n])\n\n# Load an image and make predictions\nfrom PIL import Image\nimport numpy as np\n\nimage = Image.open('path/to/your/image.jpg')\nimage = image.resize((224, 224))\ninput_data = np.array(image) / 255.0\ninput_data = np.expand_dims(input_data, axis=0)\n\npredictions = model.predict(input_data)\nprint(predictions)", "performance": {"dataset": "ImageNet", "accuracy": "71.9%"}, "description": "A pre-trained image classification model using MobileNetV2 architecture from TensorFlow Hub."}}
{"code": "###Instruction: Summarize an article by representing its content in a high-dimensional vector format.\n###Output: <<<domain>>>: Text preprocessing, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the Universal Sentence Encoder model from TensorFlow Hub. This pre-trained model is capable of encoding text into high-dimensional vectors, which can be used for various natural language tasks. In this case, it would be used to represent the content of an article as a high-dimensional vector, effectively summarizing its essence. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text preprocessing", "framework": "TensorFlow Hub", "functionality": "Text preprocessing and embedding", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world!'])\nprint(embeddings)", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.78"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks. It is pre-trained on a large corpus of text and can be fine-tuned on specific tasks."}}
{"code": "###Instruction: Show me how I can convert this sentence \"I enjoy machine learning and natural language processing\" into a high-dimensional vector.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the Universal Sentence Encoder model from TensorFlow Hub, which transforms text into high-dimensional vectors. These vectors can be used for various natural language processing tasks like text classification, semantic similarity, clustering and more. In this case, it will be used to convert the given sentence into a high-dimensional vector. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nsentence = \"I enjoy machine learning and natural language processing\"\nvector = embed([sentence])\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world', 'Embedding text with TensorFlow Hub'])", "performance": {"dataset": "SNLI", "accuracy": "86.9%"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: Provide a solution to recognize different types of fruits through image processing.\n###Output: <<<domain>>>: image-feature-vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=[224, 224, 3]), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the pre-trained MobileNet V2 model from TensorFlow Hub for feature extraction from images. This model has been trained on the ImageNet dataset and can recognize various objects, including fruits, by extracting meaningful feature vectors from input images. By creating a single KerasLayer with the specified input shape, you can extract features from fruit images and use these features for further classification or comparison tasks. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Create a model with a single KerasLayer for feature extraction\nmodel = tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=[224, 224, 3])])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction", "api_name": "imagenet-mobilenet_v2_100_224-feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "[224, 224, 3]", "output_shape": "[1280]"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.6.0"}, "example_code": "", "performance": {"dataset": "ImageNet", "accuracy": "71.9%"}, "description": "A pre-trained image feature vector model based on MobileNetV2, designed for efficient feature extraction from images."}}
{"code": "###Instruction: I have recorded some animal sounds and I want to analyze them to identify the animal species.\n###Output: <<<domain>>>: Audio embedding, <<<api_call>>>: model = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: By using this API call, you can load a pre-trained audio embedding model from TensorFlow Hub. The model is capable of processing audio data and generating audio embeddings. These embeddings can then be used to analyze animal sounds and train a classifier to identify the animal species based on the different audio features. Please note, the provided API call refers to an ImageNet MobileNet V2 model for image feature extraction, which should be replaced with an appropriate audio embedding model from TensorFlow Hub.<<<code>>>: import tensorflow_hub as hub\n# Replace the `https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4` URL with an appropriate audio embedding model URL.\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Audio embedding", "framework": "TensorFlow Hub", "functionality": "Audio processing", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "", "performance": {"dataset": "", "accuracy": ""}, "description": "Load and use an audio embedding model from TensorFlow Hub to process audio data."}}
{"code": "###Instruction: Can you provide me with the semantic similarity of two sentences \"I love pizza\" and \"Pizza is my favorite food\"?\n###Input: \"I love pizza\", \"Pizza is my favorite food\"\n###Output: <<<domain>>>: text-embedding, <<<api_call>>>: embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder model from TensorFlow Hub, a pre-trained machine learning model used for embedding text into high-dimensional space. Once loaded, it can be used to compute embeddings for the given sentences. The cosine similarity between the embeddings can then be calculated to measure the semantic similarity between the sentences. <<<code>>>: import tensorflow_hub as hub\n# Load the Universal Sentence Encoder\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n# Compute embeddings for the input sentences\nsentence1 = \"I love pizza\"\nsentence2 = \"Pizza is my favorite food\"\nembeddings = embed([sentence1, sentence2])", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional space", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": "input_text", "python_environment_requirements": "tensorflow, tensorflow_hub", "example_code": "import tensorflow_hub as hub; embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'); embeddings = embed(['Hello world!'])", "performance": {"dataset": "Semantic Textual Similarity", "accuracy": "0.8"}, "description": "This API provides a pre-trained model to convert text into high-dimensional space, which can be used for various natural language processing tasks such as semantic similarity, clustering, and classification."}}
{"code": "###Instruction: My friend sent me a picture of an animal and I want to find out the type of animal in the picture.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: model = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads a pre-trained TensorFlow model for image classification from TensorFlow Hub. The model, MobileNet V2, has been trained on the ImageNet dataset and can be used to classify images into various categories, including animal types. By loading this model, you can use it to classify the animal image to determine the type of animal. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading pre-trained models for image classification", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'\nmodel = hub.load(model_id)\n\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_batch = tf.expand_dims(image_array, 0)\n\npredictions = model(image_batch)\n", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "Load and use a pre-trained model from TensorFlow Hub for image classification"}}
{"code": "###Instruction: Summarize the article and identify the key topics discussed.\n###Output: <<<domain>>>: Text Summarization, <<<api_call>>>: None, <<<api_provider>>>: None, <<<explanation>>>: We do not have an API call specifically for text summarization. However, you can use Transformer-based models such as T5 or BERT for summarizing text and identifying key topics discussed in a given article. You would need to find a suitable pre-trained model and fine-tune it on a text summarization dataset before using it for summarizing articles. The details provided in the current API don't support text summarization tasks.", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading pre-trained models", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v3/classification/5'\nmodel = hub.load(model_id)", "performance": {"dataset": "ImageNet", "accuracy": "Not specified"}, "description": "Load a pre-trained image classification model from TensorFlow Hub using the model_id"}}
{"code": "###Instruction: Help me identify what's in a photo using a model that is pre-trained on the ImageNet dataset.\n###Output: <<<domain>>>: image-classification, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4', input_shape=[224, 224, 3], trainable=False), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a MobileNet V2 model from TensorFlow Hub that is pre-trained on the ImageNet dataset. This model is designed for image classification tasks and has an input shape of [224, 224, 3], meaning it takes 3-channel images of size 224x224 pixels. The model has 1001 output classes, corresponding to the classes found in the ImageNet dataset, and it is not trainable, meaning its weights will not be updated during training. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Create a model with KerasLayer for image classification\nmodel = tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4', input_shape=[224, 224, 3], trainable=False)])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading pre-trained models for image classification", "api_name": "imagenet_mobilenet_v2_100_224_classification", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": {"handle": "https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4", "output_shape": [1001], "input_shape": [224, 224, 3], "trainable": false}, "python_environment_requirements": {"tensorflow": ">=2.0", "tensorflow_hub": ">=0.6.0"}, "example_code": "", "performance": {"dataset": "ImageNet", "accuracy": "71.8%"}, "description": "A pre-trained MobileNetV2 model for image classification on ImageNet dataset with 224x224 input size and 1001 output classes."}}
{"code": "###Instruction: Translate the following sentence into every possible language and create a high-dimensional vector representation for each translated sentence.\n###Input: \"The current world population is 7.9 billion.\"\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder from TensorFlow Hub. The encoder converts text into high-dimensional vectors that can be used for various natural language processing tasks such as text classification, semantic similarity, clustering, etc. After translating the input sentence into multiple languages, use the Universal Sentence Encoder to create high-dimensional vector representations for each translated sentence. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional space", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": {"input": "List of strings"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world!', 'My name is John Doe'])", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.803"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: I am trying to find objects in an image with high accuracy. Help me use a pre-trained model to detect objects.\n###Output: <<<domain>>>: Image object detection, <<<api_call>>>: detector = hub.load('https://tfhub.dev/tensorflow/centernet/hourglass_1024x1024/1'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the pre-trained CenterNet Hourglass model from TensorFlow Hub. This model is designed for detecting objects in images with high accuracy. Once the model is loaded, you can process your image and pass it to the detector to get the detected objects, their bounding boxes, class labels, and associated confidence scores.<<<code>>>: # Import libraries\nimport tensorflow as tf\nimport tensorflow_hub as hub\n\n# Load the CenterNet Hourglass model\ndetector = hub.load('https://tfhub.dev/tensorflow/centernet/hourglass_1024x1024/1')\n\n# Load an image\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg')\n\n# Process the image\ninput_image = tf.keras.preprocessing.image.img_to_array(image)\ninput_image = tf.image.resize(input_image, (1024, 1024))\ninput_image = tf.expand_dims(input_image, axis=0) / 255.0\n\n# Detect objects\nresults = detector(input_image)\n\n# Print the results\nprint(results)\n", "api_call": "hub.load('https://tfhub.dev/tensorflow/centernet/hourglass_1024x1024/1')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image object detection", "framework": "TensorFlow Hub", "functionality": "Detect objects in images", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/tensorflow/centernet/hourglass_1024x1024/1')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/tensorflow/centernet/hourglass_1024x1024/1'\ndetector = hub.load(model_id)\n\n# Load an image\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg')\n\n# Process the image\ninput_image = tf.keras.preprocessing.image.img_to_array(image)\ninput_image = tf.image.resize(input_image, (1024, 1024))\ninput_image = tf.expand_dims(input_image, axis=0) / 255.0\n\n# Detect objects\nresults = detector(input_image)\n\n# Print the results\nprint(results)", "performance": {"dataset": "COCO", "accuracy": "mAP@0.5IOU"}, "description": "A pre-trained TensorFlow Hub model for detecting objects in images using the CenterNet architecture with an Hourglass backbone."}}
{"code": "###Instruction: I have a fashion catalog and I want to find visually similar clothes from the catalog using the images.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the pre-trained MobileNetV2 model which extracts feature vectors of images when passed through the TensorFlow Hub KerasLayer. These feature vectors can be used for various purposes, such as finding visually similar items in a fashion catalog by measuring the distance between the feature vectors. By adding it to a Keras model and using the feature vector as an input layer, you can compare the images of clothes from your catalog to find the visually similar ones. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=(224, 224, 3),\n                   trainable=False),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Extracting image features", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "[batch_size, 224, 224, 3]", "output_shape": "[batch_size, 1280]"}, "python_environment_requirements": {"tensorflow": ">=2.0", "tensorflow_hub": ">=0.12"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=(224, 224, 3),\n                   trainable=False),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n# Train and evaluate the model\n# model.fit(train_data, train_labels, epochs=5)\n# model.evaluate(test_data, test_labels)", "performance": {"dataset": "ImageNet", "accuracy": "71.8%"}, "description": "A pre-trained image feature vector model based on MobileNetV2 architecture, which is optimized for low-latency and small size, while maintaining competitive accuracy on the ImageNet dataset."}}
{"code": "###Instruction: I want to identify what objects are in the image I took on my vacation. I want a lightweight and fast model for this task.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call allows you to use a pre-trained and lightweight TensorFlow model, MobileNetV2 with a depth multiplier of 130 and an input size of 224x224, for image classification. It's been trained on the ImageNet dataset and is capable of classifying images into 1000 different categories. This model is suitable for quick and efficient object identification in images taken during your vacation. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')\n])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Image classification using pre-trained models", "api_name": "imagenet-mobilenet_v2_130_224-classification", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')", "api_arguments": {"model_url": "https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4"}, "python_environment_requirements": {"tensorflow": ">=2.0", "tensorflow_hub": ">=0.12"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')\n])\n\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(224, 224))\ninput_arr = tf.keras.preprocessing.image.img_to_array(image)\ninput_arr = np.array([input_arr])\n\npredictions = model.predict(input_arr)", "performance": {"dataset": "ImageNet", "accuracy": "94.1%"}, "description": "A pre-trained image classification model using MobileNetV2 architecture with 130 depth multiplier and 224x224 input size. The model has been trained on the ImageNet dataset and can be used for classifying images into 1000 different categories."}}
{"code": "###Instruction: Could you identify the object in an image? Which pre-trained model can I use?\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: To identify objects in an image, you can use the pre-trained model MobileNetV2, which has been trained on the ImageNet dataset. This model is optimized for low-latency and small model size, making it suitable for mobile and edge devices. By simply loading the model using the given API call and providing an input image, you can obtain the classification output. <<<code>>>: import tensorflow as tf, tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')\ninput_image = tf.zeros([1, 224, 224, 3])\noutput = model(input_image)", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading pre-trained models for image classification", "api_name": "imagenet_mobilenet_v2_130_224_classification", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')", "api_arguments": {"url": "https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.6.0"}, "example_code": "import tensorflow as tf, tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')\ninput_image = tf.zeros([1, 224, 224, 3])\noutput = model(input_image)", "performance": {"dataset": "ImageNet", "accuracy": "Top-1: 80.9%, Top-5: 95.5%"}, "description": "A pre-trained model for image classification using MobileNetV2 architecture, trained on ImageNet dataset. The model is optimized for low-latency and small model size, suitable for mobile and edge devices."}}
{"code": "###Instruction: Find out what an image is about by using a pre-trained image classification model, considering its contents.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: model = hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads a pre-trained image classification model from TensorFlow Hub. The Inception V3 model has been trained on the ImageNet dataset and can identify the contents of an image based on the trained classes. By using the model, it's possible to analyze an image and determine what it is about by classifying its contents. <<<code>>>: import tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v3/classification/5'\nmodel = hub.load(model_id)", "performance": {"dataset": "ImageNet", "accuracy": "Not provided"}, "description": "Load a pre-trained image classification model from TensorFlow Hub using the provided model_id."}}
{"code": "###Instruction: Develop a model for product categories from images I provide.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call creates a KerasLayer using a pre-trained image feature vector model based on the MobileNetV2 architecture, which has been trained on the ImageNet dataset. The model can be used for image classification tasks, such as categorizing products from images. By adding this layer to your neural network, it effectively acts as a feature extractor that can help train a classifier for product categories using the provided images. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224,224,3), trainable=False),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n# Train the model with your data (x_train, y_train)\nmodel.fit(x_train, y_train, epochs=5, batch_size=32)\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Image feature extraction", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": [224, 224, 3], "output_shape": [1280]}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224,224,3), trainable=False),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n# Train the model with your data\nmodel.fit(x_train, y_train, epochs=5, batch_size=32)", "performance": {"dataset": "ImageNet", "accuracy": "71.9%"}, "description": "A pre-trained image feature vector model based on MobileNetV2 architecture, trained on ImageNet dataset. It can be used for image classification, object detection, and other computer vision tasks."}}
{"code": "###Instruction: Can you please provide an API that will help us find semantic similarity between multiple sentences?\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder model from TensorFlow Hub. The model encodes text into 512-dimensional vectors designed for various natural language tasks, including semantic similarity. By converting sentences into high-dimensional vectors, you can measure the similarity between them, which represents how semantically similar their meanings are. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello, world!', 'How are you?'])\nprint(embeddings)", "performance": {"dataset": "STS benchmark", "accuracy": "pearson_correlation=0.803"}, "description": "A model that encodes text into 512-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks"}}
{"code": "###Instruction: Describe an object in an image.\n###Output: <<<domain>>>: Image Classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained Inception V3 model from TensorFlow Hub, which has been trained on the ImageNet dataset for image classification tasks. Once loaded, you can pass an image to the model to obtain the predictions for the object depicted in the image. The model is capable of recognizing and classifying thousands of different objects. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v3/classification/5'\nmodel = hub.load(model_id)\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(299, 299))\nimage = tf.keras.preprocessing.image.img_to_array(image)\nimage = tf.expand_dims(image, axis=0)\npredictions = model(image)\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Pre-trained model for image classification", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v3/classification/5'\nmodel = hub.load(model_id)\n\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(299, 299))\nimage = tf.keras.preprocessing.image.img_to_array(image)\nimage = tf.expand_dims(image, axis=0)\n\npredictions = model(image)\n", "performance": {"dataset": "ImageNet", "accuracy": "77.9%"}, "description": "A pre-trained model for image classification using Inception V3 architecture and trained on ImageNet dataset."}}
{"code": "###Instruction: I have a collection of paintings and I'm looking for a way to generate a list of their most common features.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=[224, 224, 3]), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained model, MobileNet V2, from TensorFlow Hub for feature extraction from images. The model is trained on the ImageNet dataset and can be used to extract 1280-dimensional feature vectors representing the images. Once the feature vectors are obtained, they can be used to analyze similarities and common features among the paintings. The API_CREATE_MODEL code example shows the model instantiation with this KerasLayer. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=[224, 224, 3])])", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction from images", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "[None, 224, 224, 3]", "output_shape": "[None, 1280]"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "model = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                    input_shape=(224,224,3),\n                    trainable=False),\n    tf.keras.layers.Dense(num_classes, activation='softmax')\n])\nmodel.compile(optimizer=tf.keras.optimizers.Adam(),\n              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])", "performance": {"dataset": "ImageNet", "accuracy": "71.9%"}, "description": "A pre-trained model that takes an image input and outputs a 1280-dimensional feature vector representing the image, which can be used for various tasks such as classification, clustering, and similarity search."}}
{"code": "###Instruction: We have new images containing scenes from different locations. Let's classify these locations by implementing a pre-trained image classification model based on MobileNet V2.\n\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads a pre-trained image classification model using the MobileNet V2 architecture from TensorFlow Hub. This model is trained on the ImageNet dataset, making it capable of classifying scenes in the images from different locations. You can input images of size 224x224 pixels and the model will output a 1001-element vector of logits, from which you can determine the most likely class for each image. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Load a pre-trained MobileNet V2 model for image classification\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading pre-trained model", "api_name": "imagenet_mobilenet_v2_130_224_classification", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')", "api_arguments": {"url": "https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.11.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')", "performance": {"dataset": "ImageNet", "accuracy": "0.919"}, "description": "This module uses the MobileNet v2 architecture for image classification, pre-trained on the ImageNet dataset. The model accepts image input of size 224x224 pixels and outputs a 1001-element vector of logits."}}
{"code": "###Instruction: Can you help extract meaning from a list of sentences by converting them into high-dimensional vectors?\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The Universal Sentence Encoder model from TensorFlow Hub encodes text into high-dimensional vectors that can be used for various natural language tasks. By using this API call, you can load the pre-trained model and transform your list of sentences into numerical representations that capture their meaning. These high-dimensional vectors can then be used for text classification, semantic similarity, clustering, and other tasks. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(input_text)\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow_hub as hub; embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'); embeddings = embed(['Hello world!']); print(embeddings)", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.803"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: We have a list of YouTube video descriptions, and we want to find similar videos based on the descriptions, so start with getting the embeddings of each description.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the Universal Sentence Encoder model from TensorFlow Hub, which encodes text into high-dimensional vectors. In this case, you can apply it to YouTube video descriptions to create embeddings for each description. Once these embeddings are obtained, you can use them to perform semantic similarity analysis and cluster similar videos based on their content. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "embeddings = embed(['Hello world'])", "performance": {"dataset": "STS Benchmark", "accuracy": "Mean Squared Error (MSE) of 0.30 on the development set"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering and other natural language tasks."}}
{"code": "###Instruction: I want a tool to help me count how many cars are parked in our parking lot.\n###Output: <<<domain>>>: image-object-detection, <<<api_call>>>: hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads a pre-trained SSD MobileNet V2 model from TensorFlow Hub, which can be used for object detection in images. Once loaded, you can pass it an image from your parking lot to get back the detected objects, their bounding boxes, class labels, and confidence scores. Post-processing of the results can be done to filter out and count detected cars. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'\nloaded_model = hub.load(model_id)\n\nimage = tf.io.read_file('parking_lot_image.jpg')\ndecoded_image = tf.image.decode_jpeg(image)\nresized_image = tf.image.resize(decoded_image, [640, 480])\ninput_image = tf.expand_dims(resized_image, 0)\n\nresult = loaded_model(input_image)", "api_call": "hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image object detection", "framework": "TensorFlow Hub", "functionality": "Object detection in images", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'\nloaded_model = hub.load(model_id)\n\nimage = tf.io.read_file('image.jpg')\ndecoded_image = tf.image.decode_jpeg(image)\nresized_image = tf.image.resize(decoded_image, [640, 480])\ninput_image = tf.expand_dims(resized_image, 0)\n\nresult = loaded_model(input_image)", "performance": {"dataset": "COCO", "accuracy": "Not specified"}, "description": "A TensorFlow Hub model for detecting objects in images using the SSD MobileNet V2 architecture."}}
{"code": "###Instruction: Can you help me classify the species of a bird that I have in my photo? \n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained image classification model using the MobileNet V2 architecture from TensorFlow Hub. The model has been trained on the ImageNet dataset and can classify images into 1000 different categories. You can classify the bird species in your photo by using this model. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = tf.keras.Sequential([hub.KerasLayer(\"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4\")])", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Image classification using pre-trained models", "api_name": "imagenet_mobilenet_v2", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": {"module_url": "https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4", "input_shape": "[None, 224, 224, 3]", "output_shape": "[None, 1001]"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer(\"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4\")\n])\n\n# Prepare an image\nimage = tf.keras.preprocessing.image.load_img(\"path/to/your/image.jpg\", target_size=(224, 224))\ninput_array = tf.keras.preprocessing.image.img_to_array(image)\ninput_array = tf.expand_dims(input_array, 0)\n\n# Make a prediction\npredictions = model.predict(input_array)\n", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained image classification model using MobileNetV2 architecture on ImageNet dataset. It can be used for classifying images into 1000 different categories."}}
{"code": "###Instruction: Can you help me analyze the contents of a photograph?\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: model = hub.load('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/2'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained image classification model from TensorFlow Hub, specifically the MobileNet V2 model. This model is trained on the ImageNet dataset and can classify images into multiple classes. It has an accuracy of 71.8%. Once loaded, you can use the model to analyze and determine the contents of a photograph. <<<code>>>: import tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/2')\n", "api_call": "hub.load('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/2')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading pre-trained models", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/2')", "api_arguments": {"model_id": "string"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.6.0"}, "example_code": "import tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/2')", "performance": {"dataset": "ImageNet", "accuracy": "71.8%"}, "description": "Load a pre-trained image classification model from TensorFlow Hub, providing a model_id for the desired model."}}
{"code": "###Instruction: I have some random objects lying around my home office desk. Could you please create a model that can classify these objects for me?\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the MobileNet V2 model pre-trained on the ImageNet dataset from TensorFlow Hub. Once the model is loaded, it can be used to classify images of objects commonly found in home offices or elsewhere. You can feed in images with a size of 224x224 pixels and the model will return the most likely class labels for the objects present in the images. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\n# Load the pre-trained MobileNet V2 model\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Image classification using pre-trained models", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": {"model_id": "string"}, "python_environment_requirements": {"tensorflow": ">=2.0", "tensorflow_hub": ">=0.12"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'\nmodel = hub.load(model_id)\n\n# Load an image and preprocess it\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, 0)\n\n# Make a prediction\nprediction = model(image_array)\n\n# Decode the prediction\ndecoded_prediction = tf.keras.applications.mobilenet_v2.decode_predictions(prediction.numpy())", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "Pre-trained image classification model using MobileNetV2 architecture on the ImageNet dataset."}}
{"code": "###Instruction: Analyze various photograps and determine what objects each one contains.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained image classification model using the Inception V3 architecture from TensorFlow Hub. It has been trained on the ImageNet dataset, and can be used to classify images into 1000 different categories. Simply provide an image to the model, and it will return its best guess at what object the image contains. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v3/classification/5'\nmodel = hub.load(model_id)\n\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(299, 299))\ninput_image = tf.keras.preprocessing.image.img_to_array(image)\ninput_image = tf.expand_dims(input_image, 0)\n\npredictions = model(input_image)\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Pre-trained image classification model", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "api_arguments": {"model_id": "string"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v3/classification/5'\nmodel = hub.load(model_id)\n\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(299, 299))\ninput_image = tf.keras.preprocessing.image.img_to_array(image)\ninput_image = tf.expand_dims(input_image, 0)\n\npredictions = model(input_image)\n", "performance": {"dataset": "ImageNet", "accuracy": "0.779"}, "description": "A pre-trained image classification model using Inception V3 architecture, trained on ImageNet dataset. The model can be used to classify images into 1000 different categories."}}
{"code": "###Instruction: Determine the type of animal we found during the hike. It's important to know if it could be dangerous.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the pre-trained Inception V3 model from TensorFlow Hub. The model has been trained on the ImageNet dataset and can classify images into 1000 different classes. With this model, you can determine the type of animal found during the hike, and even check if it belongs to a dangerous category. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v3/classification/5'\nmodel = hub.load(model_id)\n\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(299, 299))\ninput_image = tf.keras.preprocessing.image.img_to_array(image)\ninput_image = tf.expand_dims(input_image, 0)\npredictions = model(input_image)", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Pre-trained model for image classification", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v3/classification/5'\nmodel = hub.load(model_id)\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(299, 299))\ninput_image = tf.keras.preprocessing.image.img_to_array(image)\ninput_image = tf.expand_dims(input_image, 0)\npredictions = model(input_image)\n", "performance": {"dataset": "ImageNet", "accuracy": "0.779"}, "description": "A pre-trained model for image classification using Inception V3 architecture, available on TensorFlow Hub. The model has been trained on the ImageNet dataset and can be used to classify images into 1000 different classes."}}
{"code": "###Instruction: Expedia wants to recommend hotels based on the image of their rooms. They need a way to extract features from these images.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call wraps a pre-trained MobileNetV2 model from TensorFlow Hub as a KerasLayer, which allows the extraction of feature vectors from images. The model has been trained on the ImageNet dataset and is designed for efficient feature extraction. With this KerasLayer, you can build a model to recommend hotels by comparing the features of room images provided by Expedia. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\n# Create a sequential model using the pre-trained MobileNetV2 feature vector extractor\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', trainable=False)\n])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction from images", "api_name": "imagenet-mobilenet_v2_100_224-feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"handle": "https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4", "trainable": "Optional: Set to True if you want to fine-tune the model"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "model = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   trainable=False),\n    tf.keras.layers.Dense(num_classes, activation='softmax')\n])", "performance": {"dataset": "ImageNet", "accuracy": "71.0% top-1 accuracy"}, "description": "A pre-trained image feature vector model based on MobileNetV2 architecture, trained on ImageNet dataset, for extracting features from images."}}
{"code": "###Instruction: Automate the process of training a deep learning model to distinguish between images of cats and dogs.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer(\"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4\"), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: To train a deep learning model for distinguishing between images of cats and dogs, you can use the MobileNetV2 architecture from TensorFlow Hub. This API call loads a pre-trained mobile_net_v2 model and constructs a KerasLayer to use in the final architecture as a feature extractor. The extracted features can be fed into a sigmoid activation layer for binary classification. Finally, the model can be compiled and trained in TensorFlow. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer(\"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4\",\n                   input_shape=(224, 224, 3),\n                   output_shape=[1280],\n                   trainable=False),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n", "api_call": "hub.KerasLayer(\"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4\")", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Extract feature vector from images", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer(\"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4\")", "api_arguments": {"input_shape": "[224, 224, 3]", "output_shape": "[1280]"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.8.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer(\"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4\",\n                   input_shape=(224, 224, 3),\n                   output_shape=[1280],\n                   trainable=False),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "This API provides a pre-trained model to extract feature vectors from images using the MobileNetV2 architecture trained on the ImageNet dataset. It can be used for various image classification tasks and transfer learning."}}
{"code": "###Instruction: We need to detect broken objects in an assembly line from images. Suggest an appropriate API call that can help us generate feature vectors for this purpose.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the pre-trained MobileNetV2 model from TensorFlow Hub. This model is designed for generating image feature vectors with 100% depth and 224x224 input size. By using these feature vectors, you can train a classifier to detect broken objects in images taken from the assembly line. This model provides good performance on the ImageNet dataset, with an accuracy of 71.0%. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224, 224, 3), trainable=False),\n    tf.keras.layers.Dense(100, activation='softmax')\n])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Generating image feature vectors", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "[None, 224, 224, 3]", "output_shape": "[None, 1280]"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.8.0"}, "example_code": {"import": ["import tensorflow as tf", "import tensorflow_hub as hub"], "model": ["model = tf.keras.Sequential([", "  hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',", "                 input_shape=(224,224,3),", "                 trainable=False),", "  tf.keras.layers.Dense(100, activation='softmax')", "])"]}, "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained deep learning model for generating image feature vectors using MobileNetV2 architecture with 100% depth and 224x224 input size."}}
{"code": "###Instruction: I need a model that can classify different architectural styles in images.\n###Output: <<<domain>>>: image-feature-vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224, 224, 3), trainable=False), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call allows you to create a model using TensorFlow Hub that includes the MobileNet v2 architecture for feature extraction. The model takes an image as input, with a shape of (224, 224, 3), and outputs a 1280-dimensional feature vector. By adding your own classification layer, you can build a model tailored to classify architectural styles in images. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224, 224, 3), trainable=False),\n    tf.keras.layers.Dense(10, activation='softmax')  # Replace 10 with the number of architectural style classes\n])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "[None, 224, 224, 3]", "output_shape": "[None, 1280]"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "model = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=(224,224,3),\n                   trainable=False),\n    tf.keras.layers.Dense(10, activation='softmax')\n])", "performance": {"dataset": "ImageNet", "accuracy": "71.9%"}, "description": "This module uses the MobileNet v2 architecture for extracting image features. It takes an image input of shape (224, 224, 3) and outputs a 1280-dimensional feature vector."}}
{"code": "###Instruction: Provide me a pre-trained model to classify imported images.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained MobileNet V2 model from TensorFlow Hub, designed for image classification using the ImageNet dataset. The model has been pre-trained and can be used to classify imported images into various classes based on their content. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading pre-trained models", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": [{"name": "model_id", "type": "string", "description": "The ID of the pre-trained model to be loaded"}], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'\nmodel = hub.load(model_id)", "performance": {"dataset": "ImageNet", "accuracy": "Not specified"}, "description": "Load a pre-trained image classification model from TensorFlow Hub using the specified model ID."}}
{"code": "###Instruction: I'd like to automatically classify food images at a grocery store to add labels to the products.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: model = hub.load('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained MobileNetV2 model for image classification from TensorFlow Hub. The MobileNetV2 model is lightweight, efficient and suitable for mobile applications. Once the model is loaded, it can be used to classify images of food items in a grocery store, which can help in automatically adding labels to the products based on the images taken. <<<code>>>: import tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4')\n", "api_call": "hub.load('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading pre-trained models for image classification", "api_name": "mobilenet_v2", "api_call": "hub.load('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4')", "api_arguments": "URL of the pre-trained model", "python_environment_requirements": "tensorflow, tensorflow_hub", "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4')\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, 0)\npredictions = model(image_array)\n", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained MobileNetV2 model for image classification using TensorFlow Hub"}}
{"code": "###Instruction: Analyze a collection of images to help me recognize my dog's breed.\n###Output: <<<domain>>>: image-feature-vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224,224,3)), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained MobileNet V2 model from TensorFlow Hub for feature extraction. The model has been trained on the ImageNet dataset, providing feature extraction capabilities that can be used for recognizing dog breeds. You can use this feature vector model to analyze your images' features and then use a suitable classification algorithm to recognize the specific breed of your dog. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Create a Sequential model with a single MobileNet V2 KerasLayer for feature extraction\nmodel = tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224,224,3))])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction", "api_name": "imagenet-mobilenet_v2_100_224-feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"image_size": 224, "input_shape": [224, 224, 3], "output_shape": [1280]}, "python_environment_requirements": {"tensorflow": "2.x", "tensorflow_hub": "0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=(224,224,3))\n])\n\n# Load an image and preprocess it\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(224, 224))\nimage = tf.keras.preprocessing.image.img_to_array(image)\nimage = tf.expand_dims(image, 0)\n\n# Extract feature vector\nfeature_vector = model.predict(image)", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained image feature vector model using MobileNetV2 architecture and trained on ImageNet dataset. It can be used for feature extraction and fine-tuning on new classification tasks."}}
{"code": "###Instruction: Create a feature vector from an image using a pre-trained model for use in an image similarity search.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call utilizes the MobileNet V2 architecture trained on the ImageNet dataset to create a feature vector for an image. The feature vector can be used as input for training other models or for tasks like image similarity searches. To get the feature vector, you can add the Keras layer provided by TensorFlow Hub to your model architecture. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224,224,3), trainable=False),\n    tf.keras.layers.Dense(10, activation='softmax')\n])", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction from images", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "[None, 224, 224, 3]", "output_shape": "[None, 1280]"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "model = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=(224,224,3),\n                   trainable=False),\n    tf.keras.layers.Dense(10, activation='softmax')\n])", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "This API provides a feature vector for an image using the MobileNet V2 architecture trained on the ImageNet dataset. The feature vector can be used as input for training other models or for image similarity tasks."}}
{"code": "###Instruction: I have an app that allows users to take pictures of objects with their phones, and I want to know what those objects are.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads a pre-trained image classifier model, MobileNet V2, from TensorFlow Hub. This model has been trained on the ImageNet dataset and is optimized for performance on mobile and edge devices. It can classify images into one of many object categories, enabling you to identify the object in a user-taken picture. <<<code>>>: import tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Pre-trained model for image classification", "api_name": "imagenet_mobilenet_v2_100_224", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": {"model_url": "https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4"}, "python_environment_requirements": {"tensorflow": "2.x", "tensorflow_hub": "0.12.0"}, "example_code": "import tensorflow_hub as hub\nimport tensorflow as tf\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\ninput_image = tf.zeros([1, 224, 224, 3])\npredictions = model(input_image)", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "This model is a pre-trained image classifier using MobileNet V2 architecture on ImageNet dataset with 100% depth and 224x224 input size. It is optimized for performance on mobile and edge devices."}}
{"code": "###Instruction: What is the similarity between two sentences? First encode them as vectors, and then calculate the cosine similarity.\n###Input: {\"sentence1\": \"The quick brown fox jumps over the lazy dog.\", \"sentence2\": \"A sly red vixen quickly leaps above the dozing hound.\"}\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the Universal Sentence Encoder model, which encodes text into high-dimensional vectors. These vectors can be used for tasks like text classification, semantic similarity, and clustering. First, encode the two sentences as vectors using the model. Then, calculate the cosine similarity between the resulting vectors to determine their similarity. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nsentence1_vector = embed(['The quick brown fox jumps over the lazy dog.'])[0].numpy()\nsentence2_vector = embed(['A sly red vixen quickly leaps above the dozing hound.'])[0].numpy()\n\ncosine_similarity = np.dot(sentence1_vector, sentence2_vector) / (np.linalg.norm(sentence1_vector) * np.linalg.norm(sentence2_vector))\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world'])", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.803"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering and other natural language tasks. The model is trained and optimized for greater-than-word length text, such as sentences, phrases or short paragraphs."}}
{"code": "###Instruction: My CEO sent me an email, and he is asking me to analyze the emails' tone to see whether it is positive or negative. We need to get an embedding for this email before classifying the sentiment.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The Universal Sentence Encoder from TensorFlow Hub can be used to encode the text of an email into a high-dimensional vector. By loading the model and feeding it the email content as input, it will generate an embedding representing the text. This embedding can then be used to classify the sentiment of the email as either positive or negative. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\ntext = ['This is a sample text']\nembeddings = embed(text)\nprint(embeddings)", "performance": {"dataset": "SNLI", "accuracy": "86.9%"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for a wide range of tasks such as semantic similarity, text classification, clustering, and sentiment analysis."}}
{"code": "###Instruction: We need recommendations for similar restaurants. Calculate the embedding of restaurant descriptions to create a list of the most similar establishments.\n###Output: <<<domain>>>: Text preprocessing, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder model from TensorFlow Hub. The model is capable of encoding text into high-dimensional vectors, which can be used in various tasks, such as text classification, semantic similarity, clustering, and more. In this case, the embeddings of restaurant descriptions will be used to measure similarity and recommend establishments with similar characteristics. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text preprocessing", "framework": "TensorFlow Hub", "functionality": "Text preprocessing module", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello, world!', 'How are you?'])", "performance": {"dataset": "Multiple", "accuracy": "N/A"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: Convert a book summary into a high-dimensional vector for determining similarity to another book's summary.\n###Output: <<<domain>>>: Text preprocessing, <<<api_call>>>: embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: To convert the book summary into a high-dimensional vector, the API call loads the Universal Sentence Encoder model from TensorFlow Hub. The model encodes text into high-dimensional vectors, which can then be used for various natural language processing tasks, including finding similarities between two book summaries. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text preprocessing", "framework": "TensorFlow Hub", "functionality": "Text preprocessing", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['text to be encoded'])", "performance": {"dataset": "various", "accuracy": "not specified"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: Tell me how to convert post titles into numerical vectors so that I can find similar titles later on.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: To convert post titles into numerical vectors, you can use the Universal Sentence Encoder model from TensorFlow Hub. This model encodes text into high-dimensional vectors which can be utilized for finding similar titles based on semantic similarity. Once the model is loaded, simply pass the list of post titles to the model and it will return the corresponding embeddings. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n# Replace 'post_titles' with a list of your post titles\nembeddings = embed(post_titles)\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into a high-dimensional vector", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text: A list of strings to be embedded"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow_hub as hub; embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'); embeddings = embed(['Hello world!'])", "performance": {"dataset": "STSbenchmark", "accuracy": "Pearson correlation of 0.803"}, "description": "The Universal Sentence Encoder encodes text into a high-dimensional vector that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: We want to analyze security camera footage and determine if there are any people in the frame.\n###Output: <<<domain>>>: Image object detection, <<<api_call>>>: hub.load('https://tfhub.dev/google/openimages_v4/ssd_mobilenet_v2/1'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the SSD MobileNet V2 model from TensorFlow Hub. This model has been pre-trained for object detection on the Open Images v4 dataset. The detector can process the security camera footage to recognize objects in the frames, including people. The output will include the bounding boxes, class labels, and confidence scores for each detected object, from which you can filter and analyze the presence of people. <<<code>>>: import tensorflow_hub as hub\ndetector = hub.load('https://tfhub.dev/google/openimages_v4/ssd_mobilenet_v2/1')\nresult = detector(image, score_threshold=0.5)\n", "api_call": "hub.load('https://tfhub.dev/google/openimages_v4/ssd_mobilenet_v2/1')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image object detection", "framework": "TensorFlow Hub", "functionality": "Detect objects in images", "api_name": "ssd_mobilenet_v2", "api_call": "hub.load('https://tfhub.dev/google/openimages_v4/ssd_mobilenet_v2/1')", "api_arguments": "image, score_threshold", "python_environment_requirements": "Python 3, TensorFlow 2.x, TensorFlow Hub", "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\ndetector = hub.load('https://tfhub.dev/google/openimages_v4/ssd_mobilenet_v2/1')\nresult = detector(image, score_threshold=0.5)", "performance": {"dataset": "Open Images v4", "accuracy": "mAP@0.5IOU = 32.8%"}, "description": "A pre-trained SSD MobileNet V2 model for object detection in images, trained on the Open Images v4 dataset. Detects objects and outputs their bounding boxes and class labels with associated confidence scores."}}
{"code": "###Instruction: I took a picture of my park today. I want to know what kinds of objects I captured in the picture.\n###Output: <<<domain>>>: Image object detection, <<<api_call>>>: detector = hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the SSD MobileNet V2 object detection model from TensorFlow Hub. Once the model is loaded, it can be used to detect and localize various types of objects in your park picture. The model is pre-trained on a dataset with a variety of object classes, allowing for accurate object detection and localization within your image. <<<code>>>: import tensorflow_hub as hub\ndetector = hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')\n", "api_call": "hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image object detection", "framework": "TensorFlow Hub", "functionality": "Object detection and localization", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nmodel_id = 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'\ndetector = hub.load(model_id)\nresult = detector(image_tensor)", "performance": {"dataset": "COCO", "accuracy": "mAP@0.5IOU"}, "description": "A pre-trained object detection model that can detect and localize objects in an image using TensorFlow Hub."}}
{"code": "###Instruction: Our application needs to identify objects in an image. Extract them using pre-trained model.\n###Output: <<<domain>>>: Image object detection, <<<api_call>>>: hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads a pre-trained SSD Mobilenet V2 object detection model from TensorFlow Hub. The model is designed to detect multiple objects in an image and has been trained on the COCO dataset. Once the model is loaded, you can use it to identify and extract objects present in the image. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\ndetector = hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')\nresult = detector(image_tensor)\n", "api_call": "hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image object detection", "framework": "TensorFlow Hub", "functionality": "Object detection", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nmodel_id = 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'\ndetector = hub.load(model_id)\nresult = detector(image_tensor)", "performance": {"dataset": "COCO", "accuracy": "Not specified"}, "description": "A pre-trained object detection model that can detect multiple objects in an image. The model is based on the SSD Mobilenet V2 architecture and is trained on the COCO dataset."}}
{"code": "###Instruction: Compare the similarity of two customer reviews for a product and see if they are positive or negative.\n###Output: <<<domain>>>: text-embedding, <<<api_call>>>: embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder from TensorFlow Hub. This encoder is used to convert input text into high-dimensional vectors. Once this embedding model is loaded, you can pass the customer reviews in text format to the model for generating embeddings. These embeddings can be then used to compare their semantic similarity and determine if the reviews are positive or negative. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world!'])", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.803"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for a wide range of tasks such as semantic similarity, text classification, clustering, and other natural language processing tasks."}}
{"code": "###Instruction: I took a photo of my backyard and want to find similar images online. Please extract features from the photo so I can search for similar photos.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/inception_v3/feature_vector/5'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call constructs a Keras layer that loads a pre-trained model for extracting feature vectors from images using the Inception V3 architecture. The extracted feature vectors can be used to search for similar photos by measuring the similarity between the feature vectors of different images. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/inception_v3/feature_vector/5',\n                   input_shape=(299, 299, 3),\n                   trainable=False)\n])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/inception_v3/feature_vector/5')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction from images", "api_name": "image_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/inception_v3/feature_vector/5')", "api_arguments": "input_shape, input_tensor, trainable, output_shape", "python_environment_requirements": "tensorflow, tensorflow_hub", "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/inception_v3/feature_vector/5',\n                   input_shape=(299, 299, 3),\n                   trainable=False)\n])\n\nimage = tf.keras.preprocessing.image.load_img('path/to/your/image.jpg', target_size=(299, 299))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, 0)\n\nfeatures = model.predict(image_array)", "performance": {"dataset": "ImageNet", "accuracy": "78.1%"}, "description": "A pre-trained model that extracts feature vectors from images using Inception V3 architecture"}}
{"code": "###Instruction: I want to compare the meaning similarity of two sentences. Find a way to encode the sentences and calculate their similarity.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The Universal Sentence Encoder can be used to transform text into high-dimensional vectors. Once you have the sentence embeddings, you can calculate the cosine similarity between them, which will give you an indication of their semantic similarity. The higher the cosine similarity score, the more semantically similar the sentences are. This can be particularly useful for comparing the meaning similarity of sentences in natural language processing tasks. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow_hub as hub; embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'); embeddings = embed(['Hello world!'])", "performance": {"dataset": "STS Benchmark", "accuracy": "Pearson correlation coefficient of 0.803"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: My retail client wishes to recognize when a doorbell is rang in audio files of their store.\n###Output: <<<domain>>>: Audio event classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: Please note that the provided API call appears incorrect for an audio event classification task; however, assuming it were correct, loading the audio classification model from TensorFlow Hub will enable recognizing specific audio events in the audio files. Pass the audio file into the model to classify the events, and you can then detect if a doorbell ringing event is present in the analyzed audio files. <<<code>>>(Given the incorrect API call, it is not possible to provide accurate example code for this task.)", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Audio event classification", "framework": "TensorFlow Hub", "functionality": "Classify audio events", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "", "performance": {"dataset": "", "accuracy": ""}, "description": "A TensorFlow Hub model for classifying audio events."}}
{"code": "###Instruction: For a building project, we need to analyze pictures of different rocks and determine their structures. Obtain the feature vector of a rock image first.\n###Output: <<<domain>>>: image-feature-vector, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the pre-trained MobileNetV2 model from TensorFlow Hub, which has been designed for efficient on-device image classification and transfer learning. This model can be used for feature extraction from images. Once loaded, you can pass an image (224x224x3 image tensor) to the model to get back a 1280-dimensional feature vector representing the image. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Load the MobileNetV2 model for feature extraction\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')\n# Use the model to compute the feature vector for an image (assuming 'image_tensor' is a TensorFlow tensor representing your image)\nimage_tensor = tf.zeros([1, 224, 224, 3])  # Replace with your own image tensor\nfeatures = model(image_tensor)\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction", "api_name": "imagenet-mobilenet_v2_100_224-feature_vector", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_image": "A 224x224x3 image tensor", "output": "A 1280-dimensional feature vector"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.8.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')\nimage_tensor = tf.zeros([1, 224, 224, 3]) # Replace with your own image tensor\nfeatures = model(image_tensor)", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained image feature vector model based on MobileNetV2, designed for efficient on-device image classification and transfer learning. It takes a 224x224x3 image tensor as input and outputs a 1280-dimensional feature vector."}}
{"code": "###Instruction: I need to know what is in this photo I took. Can you tell me?\n###Input: {\"image\": \"path/to/image.jpg\"}\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained MobileNetV2 model fine-tuned on the ImageNet dataset. It can be used to classify images into 1000 different categories. Given the image path, this model can be fed with the preprocessed image, and it will return predictions for the correct category label.<<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4'\nmodel = hub.load(model_id)\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, 0)\npredictions = model(image_array)\nclass_names = imagenet_labels()\npredicted_class = class_names[np.argmax(predictions[0])]\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Pre-trained image classification model", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4'\nmodel = hub.load(model_id)\n\n# Load and preprocess image\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, 0)\n\n# Predict\npredictions = model(image_array)\n\n# Decode predictions\nclass_names = imagenet_labels()\npredicted_class = class_names[np.argmax(predictions[0])]", "performance": {"dataset": "ImageNet", "accuracy": "Top-1 Accuracy: 80.9%, Top-5 Accuracy: 95.2%"}, "description": "A pre-trained image classification model based on the MobileNetV2 architecture, fine-tuned on the ImageNet dataset. The model can be used to classify images into 1000 different categories."}}
{"code": "###Instruction: Identify objects in an image to let me know what objects are in the image.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v1_100_224/feature_vector/4', input_shape=(224, 224, 3), trainable=False), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call creates a KerasLayer using the MobileNet V1 model that has been pre-trained on the ImageNet dataset. It is capable of extracting features from input images of shape (224, 224, 3). These features can then be used to train a new classifier (such as a dense softmax layer) to identify objects present in the image. The layer created by this API call is specifically not trainable, to keep the pre-trained weights intact during transfer learning. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v1_100_224/feature_vector/4', input_shape=(224, 224, 3), trainable=False),\n    tf.keras.layers.Dense(10, activation='softmax')\n])\n\nmodel.summary()", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v1_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction from images", "api_name": "imagenet_mobilenet_v1_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v1_100_224/feature_vector/4')", "api_arguments": {"input_shape": "(224, 224, 3)", "output_shape": "(1024)", "trainable": "False"}, "python_environment_requirements": {"tensorflow": "2.0+", "tensorflow_hub": "0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v1_100_224/feature_vector/4', input_shape=(224, 224, 3), trainable=False),\n    tf.keras.layers.Dense(10, activation='softmax')\n])\n\nmodel.summary()", "performance": {"dataset": "ImageNet", "accuracy": "70.9%"}, "description": "A pre-trained image feature extraction model using MobileNet architecture trained on ImageNet dataset. It can be used for transfer learning and fine-tuning on new image classification tasks."}}
{"code": "###Instruction: My friend sent me an image of an animal, and I am not sure what kind of animal it is. Can you tell me what animal is in the image?\n###Input: \"<path_to_image>\"\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call will load the pre-trained Inception V3 model from TensorFlow Hub, which is designed for image classification. The model can be used to predict the class of an image, in this case, identifying the animal in the image based on a given path. To perform this, the image must be loaded and preprocessed before making predictions using the model. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v3/classification/5'\nmodel = hub.load(model_id)\nimage = tf.keras.preprocessing.image.load_img('<path_to_image>', target_size=(299, 299))\nimage = tf.keras.preprocessing.image.img_to_array(image)\nimage = tf.expand_dims(image, axis=0)\npredictions = model(image)", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Load and use pre-trained models for image classification", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v3/classification/5'\nmodel = hub.load(model_id)\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(299, 299))\nimage = tf.keras.preprocessing.image.img_to_array(image)\nimage = tf.expand_dims(image, axis=0)\npredictions = model(image)\n", "performance": {"dataset": "ImageNet", "accuracy": "N/A"}, "description": "Load and use a pre-trained image classification model from TensorFlow Hub to classify images."}}
{"code": "###Instruction: For an image classification task, we need a model capable of recognizing and differentiating between various object types. Please load a pre-trained model for this purpose.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call is used to load a pre-trained image classification model from TensorFlow Hub, specifically the Mobilenet V2 model, which is trained on the ImageNet dataset. With this model, you can classify images into one of the pre-defined categories, facilitating the recognition and differentiation of various object types. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nloaded_model = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading pre-trained models for image classification", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'\nloaded_model = hub.load(model_id)\n\n# Load an image\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_batch = tf.expand_dims(image_array, 0)\n\n# Run the model\npredictions = loaded_model(image_batch)\n", "performance": {"dataset": "ImageNet", "accuracy": "71.9%"}, "description": "This API allows users to load pre-trained models for image classification from TensorFlow Hub. The loaded models can be used to classify images into one of the pre-defined categories."}}
{"code": "###Instruction: In order to analyze customer feedback from my online store, I need a way to convert their feedback into a numeric format that can be processed by my algorithms.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the Universal Sentence Encoder. This model converts the input text into high-dimensional vectors, that can be used for various natural language processing tasks. In this case, you will be converting customer feedback into numeric values, which can then be analyzed by algorithms to gain insights. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow_hub as hub; embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'); embeddings = embed(['Hello world!']); print(embeddings)", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.803"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: I'm working on an app for smart parking stations, and I would like to detect and recognize the car plates from our CCTV footages.\n###Output: <<<domain>>>: image-object-detection, <<<api_call>>>: detector = hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the pre-trained Single Shot Detector (SSD) MobileNet V2 model from TensorFlow Hub, which has been trained on the COCO dataset. This model is suitable for object detection tasks, but to specialize in car plate recognition, additional fine-tuning or a specialized model may be required. Once the model is loaded, you can feed images with car plates extracted from the CCTV footages for detection. Detected objects with their bounding boxes, class labels, and associated scores will be returned. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'\ndetector = hub.load(model_id)\n# Assuming 'image' is a TensorFlow tensor of the CCTC footage\nresult = detector(image[tf.newaxis, ...])\n", "api_call": "hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image object detection", "framework": "TensorFlow Hub", "functionality": "Detect objects in images", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nmodel_id = 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'\ndetector = hub.load(model_id)\nimage = tf.image.decode_jpeg(tf.io.read_file('path/to/image.jpg'))\nresult = detector(image[tf.newaxis, ...])", "performance": {"dataset": "COCO", "accuracy": "mAP"}, "description": "This API allows you to detect objects in images using a pre-trained model from TensorFlow Hub. The model is based on the SSD MobileNet V2 architecture and has been trained on the COCO dataset."}}
{"code": "###Instruction: We need to build a car and bike image classifier. First, we need to extract features from the images to use for training the model.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call uses TensorFlow Hub's pre-trained MobileNetV2 model to extract image features from car and bike images. This model provides a powerful and efficient feature extraction mechanism as it is trained on the ImageNet dataset. The extracted feature vectors can then be used for training a classifier to identify car and bike images. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224, 224, 3), output_shape=(1280,))\n])\nfeatures = model.predict(images)\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction", "api_name": "imagenet-mobilenet_v2-feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "(224, 224, 3)", "output_shape": "(1280,)"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224, 224, 3), output_shape=(1280,))\n])\n\nfeatures = model.predict(images)", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained image feature vector model using MobileNetV2 architecture on ImageNet dataset. It can be used for feature extraction from images."}}
{"code": "###Instruction: I want to compare the semantic similarity between two sentences. Give me the embeddings using pre-trained models.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder (USE) model from TensorFlow Hub, which is a pre-trained model for generating text embeddings. The model can be used to create embeddings for the given sentences, which can then be compared for semantic similarity. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embed text using pre-trained models", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\ntext = ['This is a test sentence.']\nembeddings = embed(text)", "performance": {"dataset": "STS Benchmark", "accuracy": "Pearson correlation coefficient of 0.78"}, "description": "The Universal Sentence Encoder (USE) is a pre-trained model for generating embeddings of text. It is trained on a variety of data sources and can be used for tasks such as semantic similarity and classification."}}
{"code": "###Instruction: Sniff out the odd one among the following sentences: \"The party was amazing.\", \"Call a doctor.\", \"The conference was well organized.\"\n###Input: ['The party was amazing.', 'Call a doctor.', 'The conference was well organized.']\n###Output: 'Call a doctor.'", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text data", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello, world!', 'How are you?'])", "performance": {"dataset": "STS-Benchmark", "accuracy": "Pearson correlation of 0.803"}, "description": "The Universal Sentence Encoder encodes text data into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: We want to recommend similar fashion items based on a user's uploaded image. Extract image features and compare them with our fashion database.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call allows you to use TensorFlow Hub to load the pre-trained MobileNetV2 model as a Keras layer. The model has been trained on the ImageNet dataset and can be used for extracting feature vectors from images\u2014you can pass the user-uploaded image through the model, obtaining a feature vector for it. Once you have that feature vector, you can compare it with the feature vectors of items in your fashion database to find similar items. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=[224, 224, 3],\n                   output_shape=[1280],\n                   trainable=False),\n])\n\n# Get feature vector from user uploaded image\nfeature_vector = model.predict(user_uploaded_image)\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction from images", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "[None, 224, 224, 3]", "output_shape": "[None, 1280]"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=[224, 224, 3],\n                   output_shape=[1280],\n                   trainable=False),\n    tf.keras.layers.Dense(num_classes, activation='softmax')\n])\n\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "This API provides a pre-trained MobileNetV2 model for extracting feature vectors from images. The model is trained on the ImageNet dataset and can be used as a feature extractor for various image classification tasks."}}
{"code": "###Instruction: When creating a mobile application that uses image recognition, it should be able to determine what items are in the photo.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call adds a pre-trained MobileNetV2 model for image classification from TensorFlow Hub to your Keras model. The MobileNetV2 model has been trained on the ImageNet dataset and can recognize objects in an image with an input size of 224x224. You can use this model to classify objects in images as part of your mobile application's image recognition functionality. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nfrom PIL import Image\nimport numpy as np\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\n])\n\nimage = Image.open('path/to/your/image.jpg').resize((224, 224))\ninput_image = np.array(image) / 255.0\ninput_image = np.expand_dims(input_image, axis=0)\n\npredictions = model.predict(input_image)\npredicted_class = np.argmax(predictions[0])\nprint('Predicted class:', predicted_class)\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Image classification using pre-trained model", "api_name": "imagenet_mobilenet_v2_100_224_classification", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": {"url": "https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0", "numpy": ">=1.19.5", "PIL": ">=8.3.2"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nfrom PIL import Image\nimport numpy as np\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\n])\n\nimage = Image.open('path/to/your/image.jpg').resize((224, 224))\ninput_image = np.array(image) / 255.0\ninput_image = np.expand_dims(input_image, axis=0)\n\npredictions = model.predict(input_image)\npredicted_class = np.argmax(predictions[0])\nprint('Predicted class:', predicted_class)", "performance": {"dataset": "ImageNet", "accuracy": "71.8%"}, "description": "A pre-trained image classification model using MobileNetV2 architecture on ImageNet dataset with 100% depth and 224x224 input size."}}
{"code": "###Instruction: I have some images and I want to compare them efficiently. Extract the features of the images so I can perform similarity analysis.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call creates a Keras layer that uses the MobileNetV2 model, trained on the ImageNet dataset, to extract features from images. By extracting the feature vectors of the images, you can perform similarity analysis and compare different images more efficiently. The Keras layer can be incorporated into your image processing pipeline, as demonstrated in the example code. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=(224, 224, 3), trainable=False)\n])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction from images", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"handle": "https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.6.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                    input_shape=(224, 224, 3), trainable=False)\n])\n\nimage = tf.keras.preprocessing.image.load_img('path_to_your_image.jpg', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, 0)\n\nfeatures = model.predict(image_array)", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "This API provides a Keras layer that extracts features from images using the MobileNetV2 model trained on ImageNet dataset. It can be used for various tasks such as image classification, object detection, and transfer learning."}}
{"code": "###Instruction: Manage the camera in the smartphone to recognize multiple objects during a forest walk.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: model = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: To recognize multiple objects during a forest walk using the camera in the smartphone, the API call loads a pre-trained MobileNetV2 model from TensorFlow Hub. This model is trained on the ImageNet dataset for image classification. The MobileNetV2 architecture is designed for mobile devices, which makes it suitable for use during a forest walk. After loading the model, you can process the camera images and classify the objects within them using this model.<<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5')\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading pre-trained models for image classification", "api_name": "imagenet_mobilenet_v2_130_224_classification", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5')", "api_arguments": "URL of the pre-trained model", "python_environment_requirements": "TensorFlow, TensorFlow Hub", "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5')\n\n# Prepare an image for input to the model\nimage = tf.keras.preprocessing.image.load_img('path/to/your/image.jpg', target_size=(224, 224))\ninput_image = tf.keras.preprocessing.image.img_to_array(image)\ninput_image = tf.expand_dims(input_image, 0)\n\n# Predict the class of the image\npredictions = model(input_image)\npredicted_class_index = tf.argmax(predictions, axis=-1).numpy()[0]", "performance": {"dataset": "ImageNet", "accuracy": "Not specified"}, "description": "A pre-trained model for image classification using MobileNetV2 architecture and trained on ImageNet dataset"}}
{"code": "###Instruction: A tourist application wants to give real-time object recognition to help tourists when they take a picture of an object in the city.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: With this API call, you can load a pre-trained MobileNetV2 model for image classification from TensorFlow Hub. This model is specifically designed to classify a wide range of objects from images, and has been trained on the ImageNet dataset. When integrated into a tourist application, the model can identify and classify objects in real-time as tourists take photographs in the city. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Pre-trained model for image classification", "api_name": "imagenet_mobilenet_v2_100_224", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": {"url": "https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.6.0"}, "example_code": "", "performance": {"dataset": "ImageNet", "accuracy": "71.9%"}, "description": "A pre-trained MobileNetV2 model for image classification on the ImageNet dataset, with 100% depth and 224x224 input size."}}
{"code": "###Instruction: We want to help users identify the species of a bird in a given picture.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call provided loads the MobileNetV2 model for image classification from TensorFlow Hub. This model has been pre-trained on the ImageNet dataset and is useful for classifying images into categories. You can use it to identify bird species in a given picture by feeding the preprocessed image to the loaded model and extracting the predictions for different bird classes. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\n# Load the pre-trained MobileNetV2 model for image classification\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')\n\n# Load an image and preprocess it\nimage = tf.keras.preprocessing.image.load_img('path/to/your/image.jpg', target_size=(224, 224))\ninput_image = tf.keras.preprocessing.image.img_to_array(image)\ninput_image = tf.expand_dims(input_image, 0)\n\n# Make predictions\npredictions = model(input_image)\n\n# Get the top predicted class\npredicted_class = tf.argmax(predictions, axis=-1).numpy()[0]\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading a pre-trained model for image classification", "api_name": "imagenet_mobilenet_v2_130_224_classification", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')", "api_arguments": {"url": "https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')\n\n# Load an image and preprocess it\nimage = tf.keras.preprocessing.image.load_img('path/to/your/image.jpg', target_size=(224, 224))\ninput_image = tf.keras.preprocessing.image.img_to_array(image)\ninput_image = tf.expand_dims(input_image, 0)\n\n# Make predictions\npredictions = model(input_image)\n\n# Get the top predicted class\npredicted_class = tf.argmax(predictions, axis=-1).numpy()[0]", "performance": {"dataset": "ImageNet", "accuracy": "Top-1: 80.9%, Top-5: 95.2%"}, "description": "A pre-trained MobileNetV2 model for image classification on the ImageNet dataset."}}
{"code": "###Instruction: I want to analyze a list of customer reviews to gain insight into their sentiment.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the pre-trained Universal Sentence Encoder (USE) model from TensorFlow Hub. The USE is capable of converting text into high-dimensional vectors, which can be used for various natural language processing tasks, such as sentiment analysis. Once you have embedded the customer reviews, you can further analyze them by clustering or classifying them using different techniques to identify patterns and sentiments. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['The product is great!', 'The service was terrible.'])\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text using pre-trained models", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world!'])", "performance": {"dataset": "STS benchmark", "accuracy": "85.1%"}, "description": "A pre-trained text embedding model that can be used to convert text into high-dimensional vectors for various natural language processing tasks."}}
{"code": "###Instruction: Gather high-dimensional embeddings of some scientific abstracts to make a similarity-based network analysis.\n###Output: <<<domain>>>: Text-embedding, <<<api_call>>>: embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the Universal Sentence Encoder model from TensorFlow Hub. This model is designed to encode text (in this case, scientific abstracts) into high-dimensional vectors, also known as embeddings. These embeddings can then be used for various natural language processing tasks, including creating a network analysis based on similarity measures (e.g., cosine distance) between the abstracts. <<<code>>>: import tensorflow_hub as hub\n# Load the Universal Sentence Encoder\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello, world!', 'How are you?'])\nprint(embeddings)", "performance": {"dataset": "STS benchmark", "accuracy": "0.803"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering and other natural language tasks."}}
{"code": "###Instruction: Use a pre-trained model to find out traits that are similar to buildings in images.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=[224, 224, 3]), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call uses a pre-trained MobileNetV2 feature vector model to extract features from images. The model has been pre-trained on the ImageNet dataset and can be used to identify shared traits in images of buildings. Once the KerasLayer is created in the TensorFlow model, you can load and preprocess the images, feed them into the model, and obtain the associated feature vectors. These feature vectors can then be used to measure and compare the similarity of the buildings across images. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=[224, 224, 3], trainable=False)\n])\n\n# Load an image, preprocess it and obtain feature vectors\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(224, 224))\ninput_array = tf.keras.preprocessing.image.img_to_array(image)\ninput_array = tf.expand_dims(input_array, 0)\nfeatures = model.predict(input_array)\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Extract features from images", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "[None, 224, 224, 3]", "output_shape": "[None, 1280]", "trainable": "False"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.7.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                    input_shape=(224,224,3), trainable=False)\n])\n\n# Load an image and preprocess it\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(224, 224))\ninput_array = tf.keras.preprocessing.image.img_to_array(image)\ninput_array = tf.expand_dims(input_array, 0)\n\n# Get the feature vector\nfeatures = model.predict(input_array)", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained image feature vector model using MobileNetV2 architecture on ImageNet dataset. It can be used to extract features from images for various tasks like image classification, object detection, and image similarity."}}
{"code": "###Instruction: I need to measure the semantic similarity between pairs of sentences. Help me to get the embeddings of the sentences.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the Universal Sentence Encoder model from TensorFlow Hub. This model is designed to encode text, such as sentences, into high-dimensional vectors. Once the text is converted into embeddings, you can measure the semantic similarity between the vectors to determine the similarity between sentence pairs. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": "input_text", "python_environment_requirements": "tensorflow, tensorflow_hub", "example_code": "import tensorflow_hub as hub; embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'); embeddings = embed(['Hello world!'])", "performance": {"dataset": "STS-Benchmark", "accuracy": "Pearson correlation coefficient of 0.803"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors for use in natural language processing tasks such as sentiment analysis, translation, and text classification."}}
{"code": "###Instruction: I work in a post office, and need to classify bills and documents from a mixed package. Please extract image features so that we can use these features for classification.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the MobileNet V2 model from TensorFlow Hub, which has been pre-trained on the ImageNet dataset. This model can be used to extract feature vectors from images, and these feature vectors can then be utilized for the classification of bills and documents within the mixed package at your post office. You can integrate this pre-trained model into your project to extract the relevant features from the images of the documents. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Create a model with a KerasLayer for feature extraction\ninput_image = tf.keras.Input(shape=(224, 224, 3))\nfeatures = hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')(input_image)\nmodel = tf.keras.Model(inputs=input_image, outputs=features)\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction", "api_name": "feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"feature_vector_url": "URL of the pre-trained model", "input_image": "Input image tensor"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nfeature_vector_url = 'https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'\n\ninput_image = tf.keras.Input(shape=(224, 224, 3))\nfeatures = hub.KerasLayer(feature_vector_url)(input_image)\n\nmodel = tf.keras.Model(inputs=input_image, outputs=features)", "performance": {"dataset": "ImageNet", "accuracy": "Not specified"}, "description": "This API allows you to extract image feature vectors using TensorFlow Hub's pre-trained models. The feature vectors can be used in various applications, such as image classification, object detection, and image similarity."}}
{"code": "###Instruction: We are building an AI app that can help us determine what kind of food is in a picture.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained Inception V3 model from TensorFlow Hub that was trained on the ImageNet dataset. This model can be used for the classification task of identifying the type of food present in an image. Once you have the model, you can feed your images to it to get the predictions with class indices. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\n# Load the model\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v3/classification/5'\nmodel = hub.load(model_id)\n\n# Assuming 'image' is an input image compatible with the model's input shape\n# Make predictions\npredictions = model(image)\nclass_index = tf.argmax(predictions, axis=-1).numpy()[0]\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Pre-trained image classification model", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "api_arguments": {"model_id": "URL or path to the TensorFlow Hub model"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.6.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v3/classification/5'\nmodel = hub.load(model_id)\n\n# Load and preprocess an image\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(299, 299))\nimage = tf.keras.preprocessing.image.img_to_array(image)\nimage = tf.expand_dims(image, axis=0)\n\n# Make predictions\npredictions = model(image)\nclass_index = tf.argmax(predictions, axis=-1).numpy()[0]", "performance": {"dataset": "ImageNet", "accuracy": "Top-1: 77.9%, Top-5: 93.7%"}, "description": "A pre-trained image classification model using Inception V3 architecture, trained on ImageNet dataset."}}
{"code": "###Instruction: Categorize images captured from a drone in different landscapes like forests, rivers, and mountains.\n###Output: <<<domain>>>: image-classification, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4', input_shape=[224, 224, 3]), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained MobileNet V2 model from TensorFlow Hub for image classification on ImageNet dataset. This model has been trained to categorize images into different types of landscapes such as forests, rivers, and mountains. To use the model, create a TensorFlow Keras layer that takes an input shape of [224, 224, 3] (which is the standard input size for this model) and outputs 1001 classes. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4', input_shape=[224, 224, 3])\n])", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading pre-trained models for image classification", "api_name": "imagenet_mobilenet_v2_100_224_classification", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": {"handle": "https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4", "output_shape": [1001], "input_shape": [224, 224, 3], "trainable": false}, "python_environment_requirements": {"tensorflow": ">=2.0", "tensorflow_hub": ">=0.6.0"}, "example_code": "", "performance": {"dataset": "ImageNet", "accuracy": "71.8%"}, "description": "A pre-trained MobileNetV2 model for image classification on ImageNet dataset with 224x224 input size and 1001 output classes."}}
{"code": "###Instruction: I am planning to sort and label my photo collection. Help me identify different objects in my master album.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: model = hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: Use the TensorFlow Hub's API call to load a pre-trained image classification model based on the Inception V3 architecture. This model has been trained on the ImageNet dataset and can be used to predict the class of input images. With this model, you can identify different objects in your photo collection and automatically label them. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v3/classification/5'\nmodel = hub.load(model_id)\n\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(299, 299))\nimage = tf.keras.preprocessing.image.img_to_array(image)\nimage = tf.expand_dims(image, 0)\n\npredictions = model(image)\nprint(predictions)\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading pre-trained models", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v3/classification/5'\nmodel = hub.load(model_id)\n\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(299, 299))\nimage = tf.keras.preprocessing.image.img_to_array(image)\nimage = tf.expand_dims(image, 0)\n\npredictions = model(image)\nprint(predictions)", "performance": {"dataset": "ImageNet", "accuracy": "Not specified"}, "description": "Load a pre-trained image classification model from TensorFlow Hub and use it to predict the class of an input image."}}
{"code": "###Instruction: Determine the dominant object in an image by extracting features from the image.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call utilizes MobileNet_v2_100_224 architecture to extract features from an input image with the shape [224, 224, 3]. It outputs a feature vector with a shape of [1280]. These feature vectors can be used to classify the dominant object in the image or for other image analysis tasks. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=[224,224,3], trainable=False)])", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction", "api_name": "imagenet-mobilenet_v2_100_224-feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "[None, 224, 224, 3]", "output_shape": "[None, 1280]"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.8.0"}, "example_code": "model = tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=[224,224,3], trainable=False)])", "performance": {"dataset": "ImageNet", "accuracy": "71.8%"}, "description": "This module uses the MobileNet_v2_100_224 architecture to extract image features. It takes an input image of shape [224, 224, 3] and outputs a feature vector of shape [1280]."}}
{"code": "###Instruction: Estimate the similarity between two news headlines using pre-trained text embedding.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the Universal Sentence Encoder (USE) from TensorFlow Hub, which is a pre-trained model designed to convert text into high-dimensional vectors. By encoding the two news headlines with USE, you can then compute the similarity between the embeddings for each headline to estimate their semantic similarity. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n\nnews_headline1 = \"Headline 1\"\nnews_headline2 = \"Headline 2\"\n\nembedding1 = embed([news_headline1])\nembedding2 = embed([news_headline2])\n\ncosine_similarity = tf.keras.losses.CosineSimilarity(axis=-1)\nsimilarity = cosine_similarity(embedding1, embedding2).numpy()\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow_hub as hub; embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'); embeddings = embed(['Hello, world!'])", "performance": {"dataset": "STS Benchmark", "accuracy": "0.78 (Spearman correlation)"}, "description": "The Universal Sentence Encoder (USE) is a pre-trained model that encodes text into high-dimensional vectors. It is useful for various natural language processing tasks, such as text classification, semantic similarity, and clustering."}}
{"code": "###Instruction: I want to build a simple mobile app that identifies plants by analyzing photos of their leaves.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: model = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained image classification model using the MobileNetV2 architecture from TensorFlow Hub. The model is trained on the ImageNet dataset and can classify images into multiple classes. Using this model, you can analyze photos of plant leaves taken by your mobile app, and it can help you identify the specific plants based on their leaf images.<<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading pre-trained models", "api_name": "imagenet_mobilenet_v2_100_224_classification", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": {"model_url": "https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.6.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(224, 224))\nimage = tf.keras.preprocessing.image.img_to_array(image)\nimage = tf.expand_dims(image, 0)\npredictions = model(image)\n", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained image classification model using MobileNetV2 architecture, trained on ImageNet dataset, with 100% depth and 224x224 input size."}}
{"code": "###Instruction: I want to make a food identification app that can help me classify different dishes at a restaurant.\n###Output: <<<domain>>>: image-classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/5'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained image classification model from TensorFlow Hub, specifically the MobileNet V2 model, which has been trained on the ImageNet dataset. Once loaded, you can pass an image to the model to obtain predicted class labels for the input image. This can be utilized as the core of a food identification app to classify different dishes in a restaurant setting. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Load the pre-trained MobileNet V2 model for image classification\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/5')\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/5')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Image classification using pre-trained models", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/5')", "api_arguments": {"model_id": "The URL of the TensorFlow Hub model or the path to the model on disk"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/5'\nmodel = hub.load(model_id)\n\nimage = tf.keras.preprocessing.image.load_img('path/to/your/image.jpg', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, 0)\n\npredictions = model(image_array)\n", "performance": {"dataset": "ImageNet", "accuracy": "Varies depending on the model used"}, "description": "TensorFlow Hub provides a collection of pre-trained image classification models that can be easily loaded and used for various image classification tasks. These models are trained on the ImageNet dataset and can be fine-tuned for specific use cases."}}
{"code": "###Instruction: I want to know what is in this image I just took.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: model = hub.load('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained image classification model from TensorFlow Hub. The model is based on the MobileNet V2 architecture and is trained on the ImageNet dataset. By loading the model using the provided URL, you can classify images you take. Once the model is loaded, it can be used to identify the main object or subject in the image. <<<code>>>: import tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4')\n", "api_call": "hub.load('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4')", "api_arguments": {"model_id": "string"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.6.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4'\nmodel = hub.load(model_id)", "performance": {"dataset": "ImageNet", "accuracy": "71.9%"}, "description": "Load a pre-trained image classification model from TensorFlow Hub and use it to classify images."}}
{"code": "###Instruction: We need to classify images taken by our surveillance camera to detect unwanted activity.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads a pre-trained image classification model, MobileNet V2, from TensorFlow Hub. This model has been trained on the ImageNet dataset and is capable of classifying images into thousands of categories. Once loaded, this model can be used to process images of size 224x224 pixels from your surveillance camera, outputting classification scores to detect different activities. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'\nmodel = hub.load(model_id)\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Image classification model", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'\nmodel = hub.load(model_id)\n", "performance": {"dataset": "ImageNet", "accuracy": "Not specified"}, "description": "A pre-trained image classification model available on TensorFlow Hub, capable of classifying images into a large number of categories."}}
{"code": "###Instruction: We are working with an autonomous vehicle company, and they want to detect and classify objects in the environment while the vehicle is on the road.\n###Output: <<<domain>>>: image-object-detection, <<<api_call>>>: model = hub.load('https://tfhub.dev/tensorflow/faster_rcnn/resnet50_v1_640x640/1'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the pre-trained Faster R-CNN model with ResNet-50 backbone from TensorFlow Hub, which can be used for object detection and classification in images. The model is trained on the COCO 2017 dataset and has an accuracy of 37.1 mAP. Once the model is loaded, it takes an input tensor of shape [1, height, width, 3] and returns detections that include bounding boxes and class labels. In this case, the model can be used to detect and classify objects in images captured by an autonomous vehicle's camera. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Load the Faster R-CNN ResNet-50 model\nmodel = hub.load('https://tfhub.dev/tensorflow/faster_rcnn/resnet50_v1_640x640/1')\n# Use the model to detect objects in an image (assuming 'image' is a NumPy array representing your image)\nimage_tensor = tf.convert_to_tensor(image, dtype=tf.float32)\ndetections = model(image_tensor)\n", "api_call": "hub.load('https://tfhub.dev/tensorflow/faster_rcnn/resnet50_v1_640x640/1')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image object detection", "framework": "TensorFlow Hub", "functionality": "Detect objects in images", "api_name": "faster_rcnn_resnet50_v1_640x640", "api_call": "hub.load('https://tfhub.dev/tensorflow/faster_rcnn/resnet50_v1_640x640/1')", "api_arguments": {"image": "A tensor of shape [1, height, width, 3] containing a single image"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.6.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = hub.load('https://tfhub.dev/tensorflow/faster_rcnn/resnet50_v1_640x640/1')\nimage_tensor = tf.convert_to_tensor(image, dtype=tf.float32)\ndetections = model(image_tensor)", "performance": {"dataset": "COCO 2017", "accuracy": "37.1 mAP"}, "description": "A pre-trained Faster R-CNN model with ResNet-50 backbone for object detection in images"}}
{"code": "###Instruction: How do I know the breed of a random dog in a picture?\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: By using the pre-trained MobileNet V2 image classification model with TensorFlow Hub, you can identify various objects, including dog breeds, in images. First, load the model using the API call provided. Then, feed a pre-processed image to obtain class predictions. To get readable class names, use \"decode_predictions\" function on the output predictions. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\nimage = tf.keras.preprocessing.image.load_img('path/to/your/image.jpg', target_size=(224, 224))\ninput_array = tf.keras.preprocessing.image.img_to_array(image)\ninput_array = tf.expand_dims(input_array, 0)\ninput_array /= 255.0\npredictions = model(input_array)\nclass_names = tf.keras.applications.mobilenet_v2.decode_predictions(predictions.numpy())", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading a pre-trained model", "api_name": "imagenet_mobilenet_v2_100_224_classification", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": {"url": "https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4"}, "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\n\n# Load and preprocess an image\nimage = tf.keras.preprocessing.image.load_img('path/to/your/image.jpg', target_size=(224, 224))\ninput_array = tf.keras.preprocessing.image.img_to_array(image)\ninput_array = tf.expand_dims(input_array, 0)\ninput_array /= 255.0\n\n# Make predictions\npredictions = model(input_array)\n\n# Decode predictions to class names\nclass_names = tf.keras.applications.mobilenet_v2.decode_predictions(predictions.numpy())", "performance": {"dataset": "ImageNet", "accuracy": "71.8%"}, "description": "A pre-trained image classification model using MobileNetV2 architecture and trained on ImageNet dataset."}}
{"code": "###Instruction: I have a picture of my room and I want to identify all the objects present in it.\n###Output: <<<domain>>>: Image object detection, <<<api_call>>>: detector = hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads a pre-trained SSD Mobilenet V2 model from TensorFlow Hub for detecting objects in images. This model is designed for real-time object detection, as it can efficiently detect objects and their locations in an image. In this case, it can be used to identify objects present in the image of your room. <<<code>>>: import tensorflow_hub as hub\n# Load the SSD Mobilenet V2 model for object detection\ndetector = hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')\n", "api_call": "hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image object detection", "framework": "TensorFlow Hub", "functionality": "Detect objects in images", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')", "api_arguments": {"model_id": "A unique identifier for the pre-trained model"}, "python_environment_requirements": {"tensorflow": ">=2.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'\ndetector = hub.load(model_id)\n\nimage = tf.image.decode_jpeg(tf.io.read_file('path/to/image.jpg'))\nimage = tf.image.resize(image, (300, 300))\nimage = tf.expand_dims(image, 0)\n\nresults = detector(image)\n\nprint(results['detection_boxes'])\nprint(results['detection_classes'])\nprint(results['detection_scores'])", "performance": {"dataset": "COCO", "accuracy": "mAP (mean average precision)"}, "description": "A pre-trained model for detecting objects in images using TensorFlow Hub"}}
{"code": "###Instruction: I have a collection of movie descriptions and I want to find the resemblance between them.\n###Output: <<<domain>>>: text-embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder (USE) from TensorFlow Hub. The USE encodes text into high-dimensional vectors which can then be used for tasks like finding semantic similarity between text samples, such as movie descriptions. Once loaded, simply pass a list containing the movie descriptions as strings to the loaded model to obtain their embeddings: embeddings = embed(movie_descriptions). Then, you can use these embeddings to find the similarity between movie descriptions. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Load the Universal Sentence Encoder\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n# Use the model to get embeddings for movie descriptions (assuming 'movie_descriptions' is a list of strings)\nembeddings = embed(movie_descriptions)\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embed text data for machine learning tasks", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\ntext_input = ['This is a sample text.']\nembeddings = embed(text_input)", "performance": {"dataset": "STS benchmark", "accuracy": "85.1%"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks. The model is trained and optimized for greater-than-word length text, such as sentences, phrases, or short paragraphs."}}
{"code": "###Instruction: To find similar images in a database, we need to extract useful features to compare images.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained image feature vector model with the MobileNet V2 architecture from TensorFlow Hub. The model has been trained on the ImageNet dataset and has a 100% depth multiplier with 224x224 input image resolution. It can be used to extract useful features from images which can help you find similar images in your database by comparing their feature vectors. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=(224, 224, 3),\n                   trainable=False)\n])\n\n# Example input: a batch of images with shape [batch_size, 224, 224, 3].\nimages = tf.random.uniform((4, 224, 224, 3))\n\n# Extract features for the batch of images.\nfeatures = model(images)\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Extract image features", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "[None, 224, 224, 3]", "output_shape": "[None, 1280]"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=(224, 224, 3),\n                   trainable=False)\n])\n\n# Example input: a batch of images with shape [batch_size, 224, 224, 3].\nimages = tf.random.uniform((4, 224, 224, 3))\n\n# Extract features for the batch of images.\nfeatures = model(images)", "performance": {"dataset": "ImageNet", "accuracy": "71.9%"}, "description": "A pre-trained image feature vector model using MobileNet V2 architecture on ImageNet dataset, with 100% depth multiplier and 224x224 input image resolution. Useful for extracting features from images."}}
{"code": "###Instruction: Which API could be used to compare the semantic similarity between two given pieces of text?\n###Output: <<<domain>>>: Text embedding, <<<api_name>>>: universal-sentence-encoder, <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The Universal Sentence Encoder (USE) is a pre-trained model that you can use to compare the semantic similarity between two given pieces of text. It generates high-dimensional vector representations of text, which can be compared to determine the semantic similarity. The text can be sentences, phrases or short paragraphs. You can use it by loading the model from TensorFlow Hub with hub.load('https://tfhub.dev/google/universal-sentence-encoder/4').", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Create embeddings for text data", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": {"input": "List of strings (sentences)"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world!', 'Embedding with TensorFlow Hub'])", "performance": {"dataset": "STS Benchmark", "accuracy": "Pearson correlation coefficient of 0.803"}, "description": "The Universal Sentence Encoder (USE) is a pre-trained model that encodes text into high-dimensional vectors, which can be used for various natural language processing tasks."}}
{"code": "###Instruction: We have some cars pictures and want to classify them, give us the API call to get a pre-trained model.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the pre-trained image classification model using MobileNetV2 architecture from TensorFlow Hub, specifically designed for efficient operations on mobile and edge devices. The model has been trained on the ImageNet dataset and provides strong performance in both low-latency and small model size scenarios. <<<code>>>: import tensorflow as tf, tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading pre-trained models for image classification", "api_name": "imagenet_mobilenet_v2_130_224_classification", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')", "api_arguments": {"url": "https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.6.0"}, "example_code": "import tensorflow as tf, tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')\ninput_image = tf.zeros([1, 224, 224, 3])\noutput = model(input_image)", "performance": {"dataset": "ImageNet", "accuracy": "Top-1: 80.9%, Top-5: 95.5%"}, "description": "A pre-trained model for image classification using MobileNetV2 architecture, trained on ImageNet dataset. The model is optimized for low-latency and small model size, suitable for mobile and edge devices."}}
{"code": "###Instruction: We have received customer complaints about our products and want to group them into different categories to address them more effectively. Help us get embeddings for the complaint text data to enable clustering.\n###Output: <<<domain>>>: text-embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: To cluster customer complaints effectively, we can utilize the Universal Sentence Encoder model from TensorFlow Hub, which is designed to encode text into high-dimensional vectors. Once the complaint texts are transformed into these high-dimensional embeddings, you can employ clustering techniques like K-means, hierarchical clustering, or DBSCAN to group them into different categories. <<<code>>>: import tensorflow_hub as hub\n# Load the Universal Sentence Encoder model\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n# Assuming 'complaints' is a list of customer complaint sentences\n# Get embeddings for the complaints and convert them to numpy arrays\nembeddings = embed(complaints).numpy()\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embed text data for machine learning tasks", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": {"input": "List of sentences"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.11.0"}, "example_code": "import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nsentences = ['Hello, world!', 'Embeddings are fun!']\nembeddings = embed(sentences).numpy()", "performance": {"dataset": "STS Benchmark", "accuracy": "0.78"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering and other natural language tasks."}}
{"code": "###Instruction: Help me convert Reddit post comments into numerical vector format that can be easily understood by machine algorithms.\n###Output: <<<domain>>>: text-preprocessing, <<<api_call>>>: embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder from TensorFlow Hub, which is a model that converts text into high-dimensional vectors. These vectors can then be used for various natural language tasks like text classification, semantic similarity, clustering, etc. Once the model is loaded, you can use it to preprocess Reddit post comments (or any other text) into numerical vector representations that can be used for machine learning algorithms. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n# Assuming 'comments' is a list of Reddit post comments\nembeddings = embed(comments)\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text preprocessing", "framework": "TensorFlow Hub", "functionality": "Text preprocessing", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": {"input": "List of sentences"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.8.0"}, "example_code": "import tensorflow_hub as hub; embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'); embeddings = embed(['sample sentence'])", "performance": {"dataset": "Various datasets", "accuracy": "Not mentioned"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: Organize a digital library of photos and identify the ones with similar content by comparing their image features.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=[224, 224, 3]), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the MobileNetV2 model from TensorFlow Hub, pretrained on the ImageNet dataset, to extract feature vectors from images. The extracted features can be used for tasks like image classification, object detection, and image similarity. By comparing the feature vectors of multiple images in your digital library, you can identify those with similar content. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\n# Load the MobileNetV2 model for feature extraction\nmodel = tf.keras.Sequential([\n    hub.KerasLayer(\"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4\", input_shape=[224, 224, 3])\n])\n\n# Convert an image to a 224x224 array, expand its dimensions, and predict its features\nimage = tf.keras.preprocessing.image.load_img(\"path/to/image.jpg\", target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, 0)\n\nfeatures = model.predict(image_array)\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction from images", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "[224, 224, 3]", "output_shape": "[1280]"}, "python_environment_requirements": {"tensorflow": ">=2.0", "tensorflow_hub": ">=0.6.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=[224, 224, 3])\n])\n\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, 0)\n\nfeatures = model.predict(image_array)", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "This API extracts feature vectors from images using the MobileNetV2 model pretrained on the ImageNet dataset. It can be used for tasks like image classification, object detection, and image similarity."}}
{"code": "###Instruction: Given a collection of images, find the most likely object depicted in each image.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained MobileNet V2 model for image classification from TensorFlow Hub. Once loaded, the model can be used to classify images by predicting what object is most likely depicted in each image. The model is trained on the ImageNet dataset and can recognize a wide variety of objects. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel_id = 'https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4'\nmodel = hub.load(model_id)\n", "api_call": "hub.load('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading pre-trained models for image classification", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4'\nmodel = hub.load(model_id)\n\nimage = tf.keras.preprocessing.image.load_img('image.jpg', target_size=(224, 224))\ninput_array = tf.keras.preprocessing.image.img_to_array(image)\ninput_array = tf.expand_dims(input_array, 0)\n\npredictions = model(input_array)\n", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "Load a pre-trained model for image classification from TensorFlow Hub and use it to classify images."}}
{"code": "###Instruction: I am making an image recognition app, and I want to extract features from each image.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the MobileNet v2 model from TensorFlow Hub. This model is used for feature extraction from images. Given an image tensor as input, the model returns a feature vector tensor. These extracted features can be used for various purposes such as image recognition or classification tasks. <<<code>>>: import tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction from images", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input": "Image tensor", "output": "Feature vector tensor"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.6.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')\nimage = tf.zeros([1, 224, 224, 3])\nfeatures = model(image)", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "This module uses MobileNet v2 architecture for image feature extraction. It takes an image tensor as input and returns a feature vector tensor."}}
{"code": "###Instruction: Analyze whether the descriptions of two movies are similar by generating dense vector representations of the text and comparing them.\n###Output: <<<domain>>>: text-embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the Universal Sentence Encoder from TensorFlow Hub, which can convert text into high-dimensional vectors. These dense vector representations can be used for tasks such as text classification, semantic similarity, clustering, and other natural language tasks. In this case, the vectors will be used to compare the similarity between two movie descriptions. <<<code>>>: import tensorflow_hub as hub\n\n# Load the Universal Sentence Encoder model\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Convert text into a dense vector representation", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world!'])", "performance": {"dataset": "STS benchmark", "accuracy": "0.803"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks"}}
{"code": "###Instruction: We have a set of images that we want to classify into different categories. We need a pre-trained image classification model for this.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads a pre-trained image classification model, specifically the MobileNetV2 model, from TensorFlow Hub. This model is suitable for various tasks such as object recognition and fine-grained classification. Once loaded, the model can be used to classify your set of images into their respective categories.<<<code>>>: import tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5')\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Pre-trained image classification models", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5'\nmodel = hub.load(model_id)\nimage = tf.random.uniform((1, 224, 224, 3))\nprediction = model(image)", "performance": {"dataset": "ImageNet", "accuracy": "Not specified"}, "description": "Load pre-trained image classification models from TensorFlow Hub for various tasks such as object recognition, fine-grained classification, and more."}}
{"code": "###Instruction: Our team has an image classification project. First, we need to extract features from our images.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the pre-trained MobileNetV2 model as a KerasLayer from TensorFlow Hub to extract features from images. The input images should be of size 224x224 pixels with 3 channels (RGB). The output is a 1280-dimensional feature vector, and the model is trained on the ImageNet dataset. This can be used as a starting point for image classification projects as it provides features extracted from the images. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=(224, 224, 3),\n                   trainable=False),\n    tf.keras.layers.Dense(10, activation='softmax')\n])\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Extract image features", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "[batch_size, 224, 224, 3]", "output_shape": "[batch_size, 1280]"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=(224, 224, 3),\n                   trainable=False),\n    tf.keras.layers.Dense(10, activation='softmax')\n])\n\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])", "performance": {"dataset": "ImageNet", "accuracy": "71.9%"}, "description": "A pre-trained image feature vector model, MobileNetV2, for TensorFlow Hub that extracts features from images. The input images should be 224x224 pixels with 3 channels (RGB). The output is a 1280-dimensional feature vector. The model is trained on the ImageNet dataset."}}
{"code": "###Instruction: I want to cluster customer chat messages so that their related concerns are addressed in a more meaningful way.\n###Output: <<<domain>>>: Text-embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder from TensorFlow Hub that embeds text into 512-dimensional vectors. These vectors can then be used for various natural language tasks such as clustering, semantic similarity, text classification, etc. By embedding your customer chat messages, you can efficiently cluster them by their related concerns or other criteria of interest. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Load the Universal Sentence Encoder\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n# Embed text messages (assumes input_text is a list of strings)\nembeddings = embed(input_text)\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello, world!', 'How are you?'])\nprint(embeddings)", "performance": {"dataset": "STS benchmark", "accuracy": "pearson_correlation=0.803"}, "description": "A model that encodes text into 512-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks"}}
{"code": "###Instruction: I want to build a text classifier for articles that could also find articles with similar content. Can you suggest a way to encode the text of the articles?\n###Output: <<<domain>>>: text-embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The Universal Sentence Encoder can be used to encode the text of the articles into high-dimensional vectors, which can be utilized for text classification and finding semantically similar content. This model provides an efficient and effective approach to encode text for various natural language processing tasks, including classification, similarity, and clustering. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world!'])\nprint(embeddings)", "performance": {"dataset": "STS Benchmark", "accuracy": "Pearson correlation coefficient of 0.803"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: There is a need to segment images of a park area with trees and people, and distinguish the trees from people.\n###Output: <<<domain>>>: Image segmentation, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/tensorflow/deeplabv3/1', output_key='SemanticPredictions'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the DeepLabv3 model from TensorFlow Hub, which is an image segmentation model designed to assign semantic labels to every pixel of an input image. The model is based on the DeepLabv3 architecture and trained on the PASCAL VOC 2012 dataset. By using this API call, you can create a model that segments images of a park area with trees and people, and differentiates trees from people. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nimage = tf.keras.Input(shape=(None, None, 3), dtype=tf.uint8, name='image_input')\nsegmentation = hub.KerasLayer('https://tfhub.dev/tensorflow/deeplabv3/1', output_key='SemanticPredictions')(image)\nmodel = tf.keras.Model(inputs=image, outputs=segmentation)\n", "api_call": "hub.KerasLayer('https://tfhub.dev/tensorflow/deeplabv3/1', output_key='SemanticPredictions')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image segmentation", "framework": "TensorFlow Hub", "functionality": "Semantic image segmentation", "api_name": "deeplabv3", "api_call": "hub.KerasLayer('https://tfhub.dev/tensorflow/deeplabv3/1', output_key='SemanticPredictions')", "api_arguments": {"input": "A 3-channel image tensor", "output": "A tensor with semantic labels"}, "python_environment_requirements": {"tensorflow": ">=2.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nimage = tf.keras.Input(shape=(None, None, 3), dtype=tf.uint8, name='image_input')\nsegmentation = hub.KerasLayer('https://tfhub.dev/tensorflow/deeplabv3/1', output_key='SemanticPredictions')(image)\nmodel = tf.keras.Model(inputs=image, outputs=segmentation)", "performance": {"dataset": "PASCAL VOC 2012", "accuracy": "82.1% mean intersection-over-union (mIOU)"}, "description": "DeepLabv3 is an image segmentation model for TensorFlow Hub that assigns semantic labels to every pixel of an input image. It is based on the DeepLabv3 architecture and trained on the PASCAL VOC 2012 dataset."}}
{"code": "###Instruction: Our security firm needs an image analysis solution to detect cars and pedestrians from CCTV images.\n###Output: <<<domain>>>: image-object-detection, <<<api_call>>>: hub.load('https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the pre-trained Faster R-CNN model with Inception ResNet V2 backbone, which has been trained on the Open Images v4 dataset. This model is suitable for object detection in images. Once loaded, you can pass images to the detector to get back detected objects, including cars and pedestrians, along with their bounding boxes and class labels. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel_id = 'https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1'\ndetector = hub.load(model_id)\n# Assuming 'image' is a TensorFlow tensor representing your image\nresult = detector(image[np.newaxis, ...])\n", "api_call": "hub.load('https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image object detection", "framework": "TensorFlow Hub", "functionality": "Object detection in images", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nmodel_id = 'https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1'\ndetector = hub.load(model_id)\nimage = tf.image.decode_jpeg(tf.io.read_file('image.jpg'))\nresult = detector(image[np.newaxis, ...])", "performance": {"dataset": "OpenImages V4", "accuracy": "Not specified"}, "description": "Detect objects in an image using TensorFlow Hub and the Faster R-CNN model with Inception ResNet V2"}}
{"code": "###Instruction: Can you recommend an API that helps to convert a research article abstract into a high-dimensional vector which we can then use to find similar articles?\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The Universal Sentence Encoder is an API that encodes text into high-dimensional vectors. It's a suitable API to use for your task to convert research article abstracts into vectors. These vectors can be used to compute similarity measures and find other articles with similar content. The model has been trained on a variety of natural language processing tasks, making it appropriate for the task at hand. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "embeddings = embed(['Hello world'])", "performance": {"dataset": "STS Benchmark", "accuracy": "Mean Squared Error (MSE) of 0.30 on the development set"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering and other natural language tasks."}}
{"code": "###Instruction: I need to monitor a warehouse's inventory and identify objects kept in the storage area.\n###Output: <<<domain>>>: image-object-detection, <<<api_call>>>: hub.load('https://tfhub.dev/google/faster_rcnn/inception_resnet_v2/atrous/oid_v4/1'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the pre-trained Faster R-CNN model with an Inception-ResNet-v2 feature extractor, specifically trained on the Open Images Dataset v4. This model is used for object detection in images. After loading the model, you can pass an image tensor containing the input images of the storage area to detect the objects, their bounding boxes, and associated class labels along with confidence scores.<<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = hub.load('https://tfhub.dev/google/faster_rcnn/inception_resnet_v2/atrous/oid_v4/1')\nimage_tensor = tf.zeros([1, 640, 640, 3])  # Replace with your image tensor\noutput = model(image_tensor)", "api_call": "hub.load('https://tfhub.dev/google/faster_rcnn/inception_resnet_v2/atrous/oid_v4/1')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image object detection", "framework": "TensorFlow Hub", "functionality": "Detect objects in images", "api_name": "faster_rcnn_inception_resnet_v2_atrous_oid_v4", "api_call": "hub.load('https://tfhub.dev/google/faster_rcnn/inception_resnet_v2/atrous/oid_v4/1')", "api_arguments": {"image_tensor": "A tensor of shape [batch_size, height, width, 3] containing the input images."}, "python_environment_requirements": {"tensorflow": ">=2.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = hub.load('https://tfhub.dev/google/faster_rcnn/inception_resnet_v2/atrous/oid_v4/1')\nimage_tensor = tf.zeros([1, 640, 640, 3])\noutput = model(image_tensor)", "performance": {"dataset": "Open Images Dataset v4", "accuracy": "mAP@0.5IOU = 0.480"}, "description": "A pre-trained Faster R-CNN model with Inception-ResNet-v2 feature extractor for object detection on the Open Images Dataset v4."}}
{"code": "###Instruction: Create a feature extraction model to recognize 10 different types of images from a given dataset with sizes 224x224x3.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=[None, 224, 224, 3]), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the MobileNet V2 model from TensorFlow Hub, pre-trained for feature extraction with input images of size 224x224x3. Once loaded, it creates a KerasLayer, which can be added to a TensorFlow model. The output is a 1280-dimensional feature vector. You can then add a dense layer to the model to recognize 10 different types of images. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224, 224, 3), trainable=False), tf.keras.layers.Dense(10, activation='softmax')])", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction", "api_name": "imagenet-mobilenet_v2_100_224-feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "[None, 224, 224, 3]", "output_shape": "[None, 1280]"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.6.0"}, "example_code": "model = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                    input_shape=(224, 224, 3),\n                    trainable=False),\n    tf.keras.layers.Dense(10, activation='softmax')\n])", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A Keras layer that wraps a pre-trained MobileNetV2 model for feature extraction. It takes an input image of size 224x224x3 and outputs a 1280-dimensional feature vector."}}
{"code": "###Instruction: I need a quick way to classify images on my phone. Can you use a computationally efficient model to do this?\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained TensorFlow model for image classification from TensorFlow Hub using the MobileNetV2 architecture. MobileNetV2 is designed to be computationally efficient while maintaining a high level of accuracy, which makes it suitable for use on mobile devices. The model has been trained on the ImageNet dataset and achieves an accuracy of 71.0%. <<<code>>>: import tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Image classification using pre-trained models", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": {"model_id": "string"}, "python_environment_requirements": {"tensorflow": ">=2.0", "tensorflow_hub": ">=0.12"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'\nmodel = hub.load(model_id)\n\n# Load an image and preprocess it\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, 0)\n\n# Make a prediction\nprediction = model(image_array)\n\n# Decode the prediction\ndecoded_prediction = tf.keras.applications.mobilenet_v2.decode_predictions(prediction.numpy())", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "Pre-trained image classification model using MobileNetV2 architecture on the ImageNet dataset."}}
{"code": "###Instruction: Provide me with the facility to determine the similarity between two sentences using encoded text.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder model from TensorFlow Hub. The model is designed to convert text into high-dimensional vectors. When the model is loaded, it can be used to transform textual input into embeddings, which can then be used to calculate similarity between two sentences. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embed text data", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": "URL of the model", "python_environment_requirements": "tensorflow, tensorflow_hub", "example_code": "import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world!'])", "performance": {"dataset": "STS benchmark", "accuracy": "0.803"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: We want to recognize different types of dogs in images for an upcoming app. Help us with a model to get the image features.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: To recognize different types of dogs in images, you can use this API call to load the pre-trained MobileNetV2 model from TensorFlow Hub. This model takes an input image of shape (224, 224, 3) and outputs a 1280-dimensional feature vector, which can be used for image classification, object detection, and other computer vision tasks. By using this model as a feature extractor and training a classifier on top of it, you will be able to classify different types of dogs in images. <<<code>>>: import tensorflow_hub as hub\nimport tensorflow as tf\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=(224,224,3),\n                   trainable=False),\n    tf.keras.layers.Dense(10, activation='softmax')\n])\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction from images", "api_name": "mobilenet_v2_100_224", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "[None, 224, 224, 3]", "output_shape": "[None, 1280]"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow_hub as hub\nimport tensorflow as tf\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=(224,224,3),\n                   trainable=False),\n    tf.keras.layers.Dense(10, activation='softmax')\n])\n\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])", "performance": {"dataset": "ImageNet", "accuracy": "71.8%"}, "description": "A pre-trained MobileNetV2 model that takes an input image of shape (224, 224, 3) and outputs a 1280-dimensional feature vector. Useful for image classification, object detection, and other computer vision tasks."}}
{"code": "###Instruction: I am planning my garden, please help me segment plants in an image for better landscape planning.\n###Output: <<<domain>>>: Image segmentation, <<<api_call>>>: model = hub.load('https://tfhub.dev/tensorflow/lite-model/deeplabv3/1/default/1'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the pre-trained DeepLabV3 model from TensorFlow Hub, which is used for image segmentation tasks such as separating plants in an image for landscape planning purposes. Once loaded, the model can segment an input image tensor by detecting different objects, their boundaries, and assign separate labels to different regions of the image, making it easy to isolate plants and other objects for better landscape planning. <<<code>>>: import tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/tensorflow/lite-model/deeplabv3/1/default/1')\nsegmentation = model(image_tensor)\n", "api_call": "hub.load('https://tfhub.dev/tensorflow/lite-model/deeplabv3/1/default/1')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image segmentation", "framework": "TensorFlow Hub", "functionality": "Load and use pre-trained image segmentation models", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/tensorflow/lite-model/deeplabv3/1/default/1')", "api_arguments": ["model_id"], "python_environment_requirements": ["pip install tensorflow-hub"], "example_code": "import tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/tensorflow/lite-model/deeplabv3/1/default/1')\nsegmentation = model(image_tensor)", "performance": {"dataset": "PASCAL VOC 2012", "accuracy": "0.91"}, "description": "TensorFlow Hub provides pre-trained image segmentation models that can be loaded and used for various tasks such as semantic segmentation. The example code demonstrates how to load a DeepLabV3 model and perform segmentation on an input image tensor."}}
{"code": "###Instruction: Find out the type of birds in my backyard based on smartphone photos I took.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the pre-trained MobileNet V2 image classification model, which has been trained on the ImageNet dataset. By using the KerasLayer API call, you can create a model to classify the images from your smartphone photos. This will assist you in identifying the types of birds present in your backyard. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Create a model using the hub.KerasLayer\nmodel = tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Image classification model", "api_name": "imagenet_mobilenet_v2_100_224_classification", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": {"url": "https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\n])\n\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(224, 224))\ninput_array = tf.keras.preprocessing.image.img_to_array(image)\ninput_array = tf.expand_dims(input_array, 0)\n\npredictions = model.predict(input_array)\n", "performance": {"dataset": "ImageNet", "accuracy": "71.8%"}, "description": "A pre-trained image classification model using MobileNet V2 architecture and trained on ImageNet dataset."}}
{"code": "###Instruction: I'm working on a project that requires text clustering, and I need to convert a list of product reviews into vector representations in order to analyze the semantic similarities between them.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The Universal Sentence Encoder allows you to convert text into high-dimensional vectors, which can be used for text clustering, semantic similarity, and other natural language tasks. This API call loads the Universal Sentence Encoder model from TensorFlow Hub, which can then be used to generate embeddings for a list of input strings, such as product reviews. By utilizing these embeddings, you can analyze the semantic similarities between the reviews in your project. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n# Get the embeddings for the given list of product reviews\nembeddings = embed(['Product A is amazing!', 'I love using Product B'])\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into a high-dimensional vector", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": {"input": "A list of strings to be embedded"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world!', 'Embedding with universal-sentence-encoder'])", "performance": {"dataset": "Various", "accuracy": "N/A"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks. It is trained and optimized for greater-than-word length text, such as sentences, phrases, or short paragraphs."}}
{"code": "###Instruction: I found a bird on my trip outside, and I took a photo. Can you identify it?\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: model = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained MobileNet V2 model for image classification from TensorFlow Hub. The model is trained on the ImageNet dataset and can be used to classify images into various categories, including bird species. Once the model is loaded, you can use it to identify the bird species in the photo you took during your trip. <<<code>>>: import tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Pre-trained image classification models", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'\nmodel = hub.load(model_id)\nimage = tf.random.normal([1, 224, 224, 3])\npredictions = model(image)\n", "performance": {"dataset": "ImageNet", "accuracy": "Varies depending on the model"}, "description": "A collection of pre-trained image classification models available on TensorFlow Hub, which can be used to classify images into various categories."}}
{"code": "###Instruction: Figure out the category of my image by using a pre-trained Inception model.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the pre-trained Inception V3 model from TensorFlow Hub for image classification. Once loaded, the model can be used to recognize objects and understand scenes in the given image. To use the model, simply preprocess the input image to the required format (resize, normalization) and pass it through the model to get the category predictions. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v3/classification/5'\nmodel = hub.load(model_id)\nimage = tf.keras.preprocessing.image.load_img('image.jpg', target_size=(299, 299))\ninput_image = tf.keras.preprocessing.image.img_to_array(image)\ninput_image = tf.expand_dims(input_image, 0)\npredictions = model(input_image)", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading and using pre-trained models", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v3/classification/5'\nmodel = hub.load(model_id)\nimage = tf.keras.preprocessing.image.load_img('image.jpg', target_size=(299, 299))\ninput_image = tf.keras.preprocessing.image.img_to_array(image)\ninput_image = tf.expand_dims(input_image, 0)\npredictions = model(input_image)\n", "performance": {"dataset": "ImageNet", "accuracy": "Not provided"}, "description": "This API is used to load and use pre-trained image classification models from TensorFlow Hub for tasks like object recognition and scene understanding."}}
{"code": "###Instruction: Images have come from users, and we need to recognize their categories for better curation.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads a pre-trained MobileNet V2 model designed for image classification from TensorFlow Hub. This model has been trained on the ImageNet dataset and can recognize categories in images. The loaded model can be used for inference on images you receive from users, helping you automatically categorize the content for better curation. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel_id = 'https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'\nmodel = hub.load(model_id)\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading and using pre-trained models", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nmodel_id = 'https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'\nmodel = hub.load(model_id)\n", "performance": {"dataset": "ImageNet", "accuracy": "Not specified"}, "description": "Loads a pre-trained image classification model from TensorFlow Hub and uses it for inference."}}
{"code": "###Instruction: We have several support tickets in our system, find a way to cluster them to find the most occurring topics.\n###Output: <<<domain>>>: text-embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The Universal Sentence Encoder API call loads a model that transforms text data into high-dimensional vectors. These vectors can be used to cluster support tickets based on semantic similarity. By clustering semantically similar tickets, you can identify the most frequently occurring topics.<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text data for machine learning models", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": {"input": "List of sentences or phrases"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.8.0"}, "example_code": "import tensorflow_hub as hub; embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'); embeddings = embed(['Hello world', 'Embedding sentences with TensorFlow Hub'])", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.78"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks. The model is trained and optimized for greater-than-word length text, such as sentences, phrases or short paragraphs. It is trained on a variety of data sources and a variety of tasks with the aim of dynamically accommodating a wide variety of natural language understanding tasks."}}
{"code": "###Instruction: We need to create an image classifier using transfer learning. I want to get feature vectors from pre-trained models.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/feature_vector/1', trainable=False), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: By using this API call, you are integrating a pre-trained feature vector model from TensorFlow Hub into a Keras layer. This model is based on the ImageNet dataset and enables you to extract image features for transfer learning. These features can be used to classify images, detect objects, or segment them, among other tasks. By setting the 'trainable' parameter to 'False', the acquired feature vector model will be used, without any further fine-tuning. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\ninput = tf.keras.layers.Input(shape=(224, 224, 3))\nfeatures = hub.KerasLayer('https://tfhub.dev/google/imagenet/feature_vector/1', trainable=False)(input)\nmodel = tf.keras.Model(inputs=input, outputs=features)\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/feature_vector/1')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction", "api_name": "imagenet-feature-vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/feature_vector/1')", "api_arguments": {"url": "https://tfhub.dev/google/imagenet/feature_vector/1", "trainable": "False"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\ninput = tf.keras.layers.Input(shape=(224, 224, 3))\nfeatures = hub.KerasLayer('https://tfhub.dev/google/imagenet/feature_vector/1', trainable=False)(input)\nmodel = tf.keras.Model(inputs=input, outputs=features)", "performance": {"dataset": "ImageNet", "accuracy": "N/A"}, "description": "This API provides a pre-trained image feature vector model for extracting features from images using TensorFlow Hub. The model is based on the ImageNet dataset and can be used for various image-related tasks such as classification, detection, and segmentation."}}
{"code": "###Instruction: Can you help me to create fixed-sized vector representation for every input phrases in a dataframe?\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the Universal Sentence Encoder model from TensorFlow Hub. This model encodes text into fixed-size embedding vectors, which can be applied to the phrases in your dataframe. Using the model, each phrase in the dataframe will be transformed into a vector representation, which can then be used for various natural language processing tasks such as text classification or semantic similarity. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": {"input": "text"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.8.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world!'])", "performance": {"dataset": "STS benchmark", "accuracy": "0.803"}, "description": "The Universal Sentence Encoder encodes text into a fixed-size embedding vector. It is trained on a variety of data sources and can be used for multiple NLP tasks such as text classification, semantic similarity, and clustering."}}
{"code": "###Instruction: I need an API to help me classify pet images. I'd like to use the extracted features from these images to make better predictions.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/5'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call is for a pre-trained image feature vector using the MobileNetV2 architecture on the ImageNet dataset. You can leverage this model to extract features from pet images, which can then be used to train a classification model for better predictions. You may add a classification head on top of the feature vector and use your training data to fine-tune the model. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/5', input_shape=(224, 224, 3), trainable=False),\n    tf.keras.layers.Dense(10, activation='softmax')\n])\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/5')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Extracting feature vector from images", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/5')", "api_arguments": {"input_shape": "[224, 224, 3]", "output_shape": "[1280]"}, "python_environment_requirements": {"tensorflow": ">=2.0", "tensorflow_hub": ">=0.12"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/5',\n                   input_shape=(224, 224, 3),\n                   trainable=False),\n    tf.keras.layers.Dense(10, activation='softmax')\n])\n\nmodel.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\nmodel.fit(x_train, y_train, epochs=5)", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained image feature vector model using MobileNetV2 architecture on ImageNet dataset. It can be used for various image classification tasks by adding a classification head on top of the feature vector."}}
{"code": "###Instruction: Help me with identifying the object present in my new picture, using a ready-to-use model.\n###Output: <<<domain>>>: image-classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads a pre-trained MobileNetV2 image classification model from TensorFlow Hub. This model has been trained on the ImageNet dataset and can classify objects present in images. By using this model, you can identify the object present in your new picture. To perform the classification, load and preprocess your image, and then feed it to the model. The model will return the class predictions from which you can extract the predicted class. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')\n\n# Load and preprocess an image\nimage = tf.keras.preprocessing.image.load_img('path/to/your/image.jpg', target_size=(224, 224))\ninput_image = tf.keras.preprocessing.image.img_to_array(image)\ninput_image = tf.expand_dims(input_image, 0)\ninput_image = tf.keras.applications.mobilenet_v2.preprocess_input(input_image)\n\n# Predict the class of the image\npredictions = model(input_image)\npredicted_class = tf.argmax(predictions, axis=-1).numpy()[0]\n\nprint('Predicted class:', predicted_class)\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Pre-trained image classification models", "api_name": "imagenet-mobilenet_v2_130_224-classification", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')", "api_arguments": {"url": "https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')\n\n# Load and preprocess an image\nimage = tf.keras.preprocessing.image.load_img('path/to/your/image.jpg', target_size=(224, 224))\ninput_image = tf.keras.preprocessing.image.img_to_array(image)\ninput_image = tf.expand_dims(input_image, 0)\ninput_image = tf.keras.applications.mobilenet_v2.preprocess_input(input_image)\n\n# Predict the class of the image\npredictions = model(input_image)\npredicted_class = tf.argmax(predictions, axis=-1).numpy()[0]\n\nprint('Predicted class:', predicted_class)", "performance": {"dataset": "ImageNet", "accuracy": "85.4%"}, "description": "A pre-trained image classification model based on MobileNetV2 architecture with 130 depth multiplier and 224x224 input size, trained on ImageNet dataset."}}
{"code": "###Instruction: I want to analyze images of my coin collection and build a classifier to identify coins. Provide me with a method to extract image features.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4', output_shape=[1280]), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained MobileNetV2 model from TensorFlow Hub for extracting image feature vectors. The model returns a 1280-dimensional feature vector, which can be used for building a coin classifier. For this, you need to create a KerasLayer with the provided API call and then preprocess the input images accordingly.<<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\n# Create a model for feature extraction with MobileNetV2\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4', output_shape=[1280])\n])", "api_call": "hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4', output_shape=[1280])", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Extract feature vector from images", "api_name": "image_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4', output_shape=[1280])", "api_arguments": {"handle": "https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4", "output_shape": "[1280]"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.6.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4', output_shape=[1280]),\n    tf.keras.layers.Dense(1)\n])\n\nimage = tf.keras.preprocessing.image.load_img('path/to/your/image.jpg', target_size=(224, 224))\nimage = tf.keras.preprocessing.image.img_to_array(image)\nimage = tf.keras.applications.mobilenet_v2.preprocess_input(image)\nimage = tf.expand_dims(image, 0)\n\nfeature_vector = model.predict(image)\nprint(feature_vector)", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "This API allows you to extract a 1280-dimensional feature vector from an image using the MobileNetV2 architecture, which is pre-trained on the ImageNet dataset. The feature vector can be used for various tasks, such as image classification, object detection, and transfer learning."}}
{"code": "###Instruction: We are doing data pre-processing for a project and our aim is to understand if the given two product titles are semantically similar or not. We first need to convert these product titles into high-dimensional vectors.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: Loading the Universal Sentence Encoder (USE) model from TensorFlow Hub allows you to transform the input product titles into high-dimensional vectors, which are also known as embeddings. These embeddings, generated by the Universal Sentence Encoder, can help in finding the semantic similarity between different pieces of text. In this case, converting the product titles into embeddings will enable you to determine if they are semantically similar or not. <<<code>>>: import tensorflow_hub as hub\n# Load the Universal Sentence Encoder model\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": "input: List of text strings", "python_environment_requirements": "tensorflow, tensorflow_hub", "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world!', 'I am learning about text embedding'])", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.803"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: I'm working on a plant recognition app, and I want to classify a plant's image taken by users.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call uses TensorFlow Hub to load a pre-trained image classification model using the MobileNetV2 architecture. The model is trained on the ImageNet dataset with a depth of 100% and an input size of 224x224. By using this pre-trained model as a Keras layer, you can create a custom classification model to recognize plant images captured by users. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'),\n])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Image Classification", "api_name": "imagenet_mobilenet_v2_100_224_classification", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": "URL: https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4", "python_environment_requirements": "tensorflow, tensorflow_hub", "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'),\n])\n", "performance": {"dataset": "ImageNet", "accuracy": "71.8%"}, "description": "A pre-trained image classification model using MobileNetV2 architecture on ImageNet dataset with 100% depth and 224x224 input size."}}
{"code": "###Instruction: How can I calculate the similarity between two sentences based on their embeddings?\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: First, you'll need to load the Universal Sentence Encoder to create embeddings for your sentences. Then, compute the cosine similarity between the two generated embeddings to obtain a similarity score. The cosine similarity ranges from -1 (completely dissimilar) to 1 (identical), with higher values indicating greater similarity. <<<code>>>:\nimport tensorflow_hub as hub\nimport numpy as np\nfrom sklearn.metrics.pairwise import cosine_similarity\n\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nsentence1 = \"This is a sample sentence.\"\nsentence2 = \"This is another sample sentence.\"\n\nembeddings = embed([sentence1, sentence2])\nsimilarity_score = cosine_similarity(embeddings.numpy()[0].reshape(1, -1), embeddings.numpy()[1].reshape(1, -1))[0][0]\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embed text data", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\ntext = ['This is a sample text', 'Another sample text']\nembeddings = embed(text)", "performance": {"dataset": "STS", "accuracy": "Pearson correlation coefficient of 0.8"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks. The model is trained and optimized for greater-than-word length text, such as sentences, phrases, or short paragraphs."}}
{"code": "###Instruction: I have an image of my backyard. Identify if the BBQ grill is active.\n###Output: <<<domain>>>: Image object detection, <<<api_call>>>: detector = hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the SSD MobileNet V2 model from TensorFlow Hub, which is a pre-trained model for detecting objects in images. To check if the BBQ grill is active in the image of your backyard, the model can be used to analyze the picture and recognize specific objects, like the BBQ grill, possibly even identifying if it is active based on features like smoke or heat.<<<code>>>: import tensorflow_hub as hub\ndetector = hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')\n", "api_call": "hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image object detection", "framework": "TensorFlow Hub", "functionality": "Detect objects in images", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nmodel_id = 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'\ndetector = hub.load(model_id)\n\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg')\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\ninput_image = tf.expand_dims(image_array, 0)\n\nresult = detector(input_image)\n", "performance": {"dataset": "COCO", "accuracy": "Unknown"}, "description": "A pre-trained TensorFlow Hub model for detecting objects in images using the SSD MobileNet V2 architecture."}}
{"code": "###Instruction: I am building a phone app that recognizes food. We need a lightweight model to identify different types of food.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: model = tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4', input_shape=IMAGE_SHAPE+(3,))]), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call provided creates a TensorFlow Keras model using the MobileNetV2 pre-trained image classification model, available on TensorFlow Hub. The lightweight model is optimized for mobile devices, making it suitable for use in a phone app to identify different types of food. The model can classify images into 1000 different categories and has been trained on the ImageNet dataset. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nIMAGE_SHAPE = (224, 224)\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4', input_shape=IMAGE_SHAPE+(3,))\n])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Image classification using a pre-trained model", "api_name": "mobilenet_v2", "api_call": "hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4')", "api_arguments": {"model_url": "https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4", "input_shape": "IMAGE_SHAPE+(3,)"}, "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nIMAGE_SHAPE = (224, 224)\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4', input_shape=IMAGE_SHAPE+(3,))\n])\n\nimage = tf.keras.preprocessing.image.load_img('image.jpg', target_size=IMAGE_SHAPE)\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, 0)\n\nresult = model.predict(image_array)\n", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "MobileNetV2 is a pre-trained image classification model that can classify images into 1000 different categories. It is lightweight and optimized for mobile devices."}}
{"code": "###Instruction: We are interesting in analyzing text messages to recommend interesting articles to our users. For this, we need to create an embedding for each message.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the Universal Sentence Encoder model provided by TensorFlow Hub. This model takes the text as input and converts it into high-dimensional vectors or embeddings. By creating embeddings for each message, we can analyze their semantic similarity and recommend articles to users based on their interests. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into a high-dimensional vector", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text: A list of strings to be embedded"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow_hub as hub; embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'); embeddings = embed(['Hello world!'])", "performance": {"dataset": "STSbenchmark", "accuracy": "Pearson correlation of 0.803"}, "description": "The Universal Sentence Encoder encodes text into a high-dimensional vector that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: Could you help me to find a quick way to rate similarities between my blog posts?\n###Output: <<<domain>>>: Text classification, <<<api_call>>>: embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder from TensorFlow Hub. The encoder encodes text into high-dimensional vectors that can be used for various natural language tasks, such as text classification, semantic similarity, and clustering. In this case, you can use the Universal Sentence Encoder to create embeddings of your blog post content and then calculate the cosine similarity between the embeddings to determine the similarity between various blog posts. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text classification", "framework": "TensorFlow Hub", "functionality": "Loading", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": {"model_url": "https://tfhub.dev/google/universal-sentence-encoder/4"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.8.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello, world!'])\nprint(embeddings)", "performance": {"dataset": "STSbenchmark", "accuracy": "0.803"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering and other natural language tasks."}}
{"code": "###Instruction: I have a lot of vacation pictures and want to find those with similar content. Can you help me?\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: model = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained MobileNetV2 model for feature vector extraction. It can be used to extract feature vectors from your vacation pictures by resizing them to the required input size (224x224) and pre-processing them. The extracted feature vectors can then be compared to find pictures with similar content. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\n# Load the pre-trained MobileNetV2 model for feature extraction\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')\n\n# Load and preprocess an image\nimage = tf.keras.preprocessing.image.load_img('path/to/your/image.jpg', target_size=(224, 224))\ninput_image = tf.keras.preprocessing.image.img_to_array(image)\ninput_image = tf.expand_dims(input_image, 0)\n\n# Extract features from the image\nfeatures = model(input_image)", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature vector extraction", "api_name": "imagenet-mobilenet_v2_100_224-feature_vector", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"image_size": "224x224", "input_type": "float32", "output_type": "float32", "batch_size": "variable"}, "python_environment_requirements": {"tensorflow": "2.0", "tensorflow_hub": "0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')\n\n# Load and preprocess an image\nimage = tf.keras.preprocessing.image.load_img('path/to/your/image.jpg', target_size=(224, 224))\ninput_image = tf.keras.preprocessing.image.img_to_array(image)\ninput_image = tf.expand_dims(input_image, 0)\n\n# Extract features\nfeatures = model(input_image)", "performance": {"dataset": "ImageNet", "accuracy": "71.0"}, "description": "This API allows you to extract feature vectors from images using the MobileNetV2 model trained on ImageNet. The feature vectors can be used for various machine learning tasks such as image classification, object detection, and more."}}
{"code": "###Instruction: I am doing holiday gift shopping online, and I want to know what category a picture of a gift item belongs to.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: model = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads a pre-trained MobileNetV2 model from TensorFlow Hub, specifically designed for image classification. This model can be used to classify images into various categories. In this case, it can be utilized to identify the category of a gift item in a picture during your online holiday shopping. Once the model is loaded, it can be used with images to generate probable classifications. <<<code>>>: import tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading pre-trained model", "api_name": "imagenet_mobilenet_v2_100_224_classification", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": "URL of the pre-trained model", "python_environment_requirements": "TensorFlow, TensorFlow Hub", "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\nprint(model(tf.zeros([1, 224, 224, 3])))", "performance": {"dataset": "ImageNet", "accuracy": "Not specified"}, "description": "Load a pre-trained MobileNetV2 model for image classification from TensorFlow Hub"}}
{"code": "###Instruction: Can you find an efficient image classification model to use on my smartphone for recognizing food items in my fridge?\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: model = tf.keras.Sequential([hub.KerasLayer(handle='https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4', input_shape=(224, 224, 3), trainable=False)]), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained image classification model using the MobileNetV2 architecture from TensorFlow Hub. MobileNetV2 models are designed for efficient on-device performance with reduced computational and memory requirements, making them ideal for use on smartphones. The model is pre-trained on the ImageNet dataset and can be used to recognize various food items in your fridge. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\n# Load the pre-trained MobileNetV2 model for image classification\nmodel = tf.keras.Sequential([\n    hub.KerasLayer(handle='https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4', input_shape=(224, 224, 3), trainable=False)\n])", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Pre-trained models for image classification", "api_name": "imagenet_mobilenet_v2_130_224_classification", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')", "api_arguments": {"handle": "https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4", "trainable": "Optional, default is False"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.6.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer(\n        handle='https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4',\n        input_shape=(224, 224, 3),\n        trainable=False\n    )\n])\n\nimage = tf.keras.preprocessing.image.load_img('path_to_your_image.jpg', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, 0)\n\npredictions = model.predict(image_array)\n", "performance": {"dataset": "ImageNet", "accuracy": "80.3%"}, "description": "A pre-trained image classification model using the MobileNetV2 architecture, trained on the ImageNet dataset. It is designed for efficient on-device performance with reduced computational and memory requirements."}}
{"code": "###Instruction: Our art gallery is conducting an exhibition and we want to classify the images of paintings into different genres.\n\n###Output: <<<domain>>>: image-classification, <<<api_call>>>: model = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained image classification model from TensorFlow Hub, specifically the MobileNet V2 model trained on the ImageNet dataset. This model can be used to classify images into different classes, in this case, genre of paintings, by adapting it to your specific use case. Once the model is loaded, it will accept image inputs of size 224x224 pixels to generate class probabilities. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'\nmodel = hub.load(model_id)\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'\nmodel = hub.load(model_id)\n", "performance": {"dataset": "ImageNet", "accuracy": "Not provided"}, "description": "Load a pre-trained image classification model from TensorFlow Hub using the model id."}}
{"code": "###Instruction: We are setting up an AI system to help classify images from outdoor events into different categories based on their content.\n\n###Output: <<<domain>>>: image-classification, <<<api_call>>>: classifier = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the pre-trained MobileNet V2 model from TensorFlow Hub, which has been trained on the ImageNet dataset for image classification. Once loaded, you can pass an image to the classifier and receive a list of class probabilities. This would allow you to classify the input images based on their content and group them accordingly. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Load the MobileNet V2 model for image classification\nclassifier = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\n# Use the model to classify an image (assuming 'image' is a TensorFlow tensor representing your input image)\nresult = classifier(image)\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading pre-trained models for image classification", "api_name": "imagenet_mobilenet_v2_100_224_classification", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": {"url": "https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.6.0"}, "example_code": "", "performance": {"dataset": "ImageNet", "accuracy": "71.8%"}, "description": "A pre-trained image classification model using MobileNetV2 architecture on the ImageNet dataset."}}
{"code": "###Instruction: I am creating a shopping app and I want to suggest similar looking items from our database using item's image.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call is for a pre-trained image feature vector model built with the MobileNetV2 architecture and trained on the ImageNet dataset. When integrated into a Keras model, it accepts preprocessed images as input and returns 1280-dimensional feature vectors. These feature vectors can be used for similarity-based item recommendations in your shopping app. <<<code>>>: import tensorflow_hub as hub\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')\n])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Extract image feature vectors", "api_name": "imagenet-mobilenet_v2_100_224-feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input": "preprocessed image", "output": "feature vector"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')\n])\n\nimage = tf.keras.Input(shape=(224, 224, 3))\nfeature_vector = model(image)", "performance": {"dataset": "ImageNet", "accuracy": "71.9%"}, "description": "A pre-trained image feature vector model using MobileNetV2 architecture on ImageNet dataset. It takes a preprocessed image as input and returns a 1280-dimensional feature vector."}}
{"code": "###Instruction: I have an image and I want to recognize the object in this image, so I need to access a pre-trained image classification model.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained MobileNetV2 model for image classification from TensorFlow Hub. Once the model is loaded, you can use it to classify the object in the given image. The model has been trained on the ImageNet dataset and can effectively recognize a multitude of object classes. <<<code>>>: import tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading a pre-trained model for image classification", "api_name": "imagenet_mobilenet_v2_130_224_classification", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')", "api_arguments": "URL of the pre-trained model", "python_environment_requirements": "tensorflow, tensorflow_hub", "example_code": "", "performance": {"dataset": "ImageNet", "accuracy": "Not provided"}, "description": "Load a pre-trained MobileNetV2 model for image classification using TensorFlow Hub."}}
{"code": "###Instruction: I have taken some pictures of my dog, and I want to organize them in a way that those which are similar to each other are together.\n###Output: <<<domain>>>: image-feature-vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224, 224, 3), output_shape=(1280,)), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the pre-trained MobileNet V2 model from TensorFlow Hub, which has been trained on the ImageNet dataset. This model is used for feature extraction from images. Once loaded, it creates a KerasLayer with the model and specifies the input and output shapes. You can use this model to obtain feature vectors for your dog images, and then cluster or organize them based on the similarity of these feature vectors. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Create a model with a single KerasLayer for feature extraction\nmodel = tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224, 224, 3), output_shape=(1280,))])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction", "api_name": "imagenet-mobilenet_v2-feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "(224, 224, 3)", "output_shape": "(1280,)"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224, 224, 3), output_shape=(1280,))\n])\n\nfeatures = model.predict(images)", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained image feature vector model using MobileNetV2 architecture on ImageNet dataset. It can be used for feature extraction from images."}}
{"code": "###Instruction: We want to find the most similar questions from user inputs to give them the best answer.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder from TensorFlow Hub, which takes input text and embeds it into high-dimensional vectors. These vectors can then be used for various natural language tasks, such as finding similar questions. Once loaded, you can pass any text, like sentences, phrases or short paragraphs to the encoder and obtain the embeddings to compare with your existing data.<<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Load the Universal Sentence Encoder\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n# Obtain the embeddings for given text\nembeddings = embed(['sample text', 'another text'])", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": "input_text", "python_environment_requirements": "tensorflow, tensorflow_hub", "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello, world!', 'My name is John Doe.'])", "performance": {"dataset": "STS Benchmark", "accuracy": "0.803"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks. The model is trained and optimized for greater-than-word length text, such as sentences, phrases, or short paragraphs."}}
{"code": "###Instruction: I am working on a product recommendation system for a flower shop. Extract feature vectors from flower images to be used in the system.\n###Output: <<<domain>>>: image-feature-vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224, 224, 3)), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained MobileNet V2 model for feature extraction from TensorFlow Hub, which has been trained on the ImageNet dataset. The model, when used as a KerasLayer, takes an input shape of (224, 224, 3) and extracts features from the images. These feature vectors can be integrated into your product recommendation system for the flower shop. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\n# Create a Sequential model with the KerasLayer for feature extraction\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224, 224, 3), trainable=False),\n    # Add additional layers if needed for your specific use case\n    tf.keras.layers.Dense(5, activation='softmax')\n])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction from images", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": ["URL"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                    input_shape=(224, 224, 3),\n                    trainable=False),\n    tf.keras.layers.Dense(5, activation='softmax')\n])", "performance": {"dataset": "ImageNet", "accuracy": "71.9%"}, "description": "A pre-trained image feature vector model based on MobileNet V2 architecture for extracting features from images. The model is trained on ImageNet dataset and has an accuracy of 71.9%."}}
{"code": "###Instruction: Recommend a playlist to me based on the audio characteristics of this song clip I'm sending you.\n###Output: <<<domain>>>: Audio embedding, <<<api_call>>>: model = hub.load('https://tfhub.dev/google/yamnet/1'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained YAMNet model from TensorFlow Hub, which generates embeddings for audio signals. These embeddings capture the audio characteristics, allowing you to perform tasks like audio classification, similarity search etc. By comparing the embeddings of your song clip with a database of songs, we can recommend a playlist with similar audio characteristics. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/yamnet/1')\naudio_data = # Load your song clip as a tensor\nembeddings = model(audio_data)\n", "api_call": "hub.load('https://tfhub.dev/google/yamnet/1')", "provider": "TensorFlow Hub", "api_data": {"domain": "Audio embedding", "framework": "TensorFlow Hub", "functionality": "Generate embeddings for audio files", "api_name": "audio_embedding_model", "api_call": "hub.load('https://tfhub.dev/google/yamnet/1')", "api_arguments": {"audio_inputs": "Tensor of shape [batch_size, num_samples] containing audio signals"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = hub.load('https://tfhub.dev/google/yamnet/1')\n\n# Load an audio file\naudio_data = ... # Load audio data as a tensor\n\n# Generate embeddings\nembeddings = model(audio_data)", "performance": {"dataset": "YAMNet", "accuracy": "81.6% top-1 accuracy on AudioSet"}, "description": "This API allows you to generate embeddings for audio files using a pre-trained YAMNet model from TensorFlow Hub. The embeddings can be used for various tasks such as audio classification, similarity search, and more."}}
{"code": "###Instruction: We are building a car recognition system. We need to extract features from car images to feed them into the classifier.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/inception_v3/feature_vector/5'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the Inception V3 model from TensorFlow Hub, which is pre-trained on the ImageNet dataset. This model is used for extracting feature vectors from images. This feature extraction process is important for car recognition systems to create a dataset of car features and feed them into a classifier. <<<code>>>: import tensorflow_hub as hub\nimport tensorflow as tf\n\nmodel = tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/imagenet/inception_v3/feature_vector/5', input_shape=(299,299,3))])\n\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(299, 299))\nimage = tf.keras.preprocessing.image.img_to_array(image)\nimage = tf.expand_dims(image, 0)\n\nfeatures = model.predict(image)\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/inception_v3/feature_vector/5')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction", "api_name": "inception_v3", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/inception_v3/feature_vector/5')", "api_arguments": {"input": "image", "output": "feature_vector"}, "python_environment_requirements": {"tensorflow": ">=2.0", "tensorflow_hub": ">=0.12"}, "example_code": "import tensorflow_hub as hub\nimport tensorflow as tf\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/inception_v3/feature_vector/5',\n                   input_shape=(299,299,3))\n])\n\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(299, 299))\nimage = tf.keras.preprocessing.image.img_to_array(image)\nimage = tf.expand_dims(image, 0)\n\nfeatures = model.predict(image)", "performance": {"dataset": "ImageNet", "accuracy": "77.9%"}, "description": "Feature extraction from images using Inception V3 model trained on ImageNet dataset"}}
{"code": "###Instruction: Please help me with a system that studies product descriptions so that we can group products with similar features.\n###Output: <<<domain>>>: Text-embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder (USE) model from TensorFlow Hub. The USE encodes textual input into high-dimensional vectors that can be used for many natural language processing tasks, such as text classification, semantic similarity, clustering, etc. In this case, you can use the USE model to study and embed product descriptions, then group them based on the similarities between their embeddings. <<<code>>>: import tensorflow_hub as hub\n# Load the Universal Sentence Encoder\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n# Embed a list of product descriptions (assuming 'product_descriptions' is a list of strings)\nembeddings = embed(product_descriptions)\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": {"input": "List of sentences"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.8.0"}, "example_code": "import tensorflow_hub as hub; embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'); embeddings = embed(['Hello world', 'I am learning how to use the Universal Sentence Encoder'])", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.78"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks. The model is trained and optimized for greater-than-word length text, such as sentences, phrases, or short paragraphs."}}
{"code": "###Instruction: I need to find features in the images to perform image classification.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call wraps the MobileNetV2 model from TensorFlow Hub as a Keras layer. This model is trained on the ImageNet dataset and can be used to extract feature vectors from images. These feature vectors can then be utilized for tasks such as image classification, object detection, and transfer learning. To use the Keras layer, simply pass the input image with a shape of (224, 224, 3) to the model for feature extraction. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=(224, 224, 3), trainable=False)\n])\n# Load an image and preprocess it\nimage = tf.keras.preprocessing.image.load_img('path_to_your_image.jpg', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, 0)\n# Predict the feature vector\nfeatures = model.predict(image_array)\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction from images", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"handle": "https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.6.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                    input_shape=(224, 224, 3), trainable=False)\n])\n\nimage = tf.keras.preprocessing.image.load_img('path_to_your_image.jpg', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, 0)\n\nfeatures = model.predict(image_array)", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "This API provides a Keras layer that extracts features from images using the MobileNetV2 model trained on ImageNet dataset. It can be used for various tasks such as image classification, object detection, and transfer learning."}}
{"code": "###Instruction: We need to find similar news articles from a large corpus. Please embed them into high-dimensional vectors.\n###Output: <<<domain>>>: text-embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder model from TensorFlow Hub, which is designed to transform text data into high-dimensional vectors. These vectors can then be used for tasks such as text classification, semantic similarity, clustering, and other natural language tasks. By embedding your news articles into high-dimensional vectors using this model, you can compare and find similar articles more effectively. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Load the Universal Sentence Encoder model\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n# Example: you can pass a list of text strings (such as your news articles) to the model to generate embeddings\nembeddings = embed(['Hello world'])\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embed text data for machine learning", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": {"input": "Text data"}, "python_environment_requirements": {"tensorflow": ">=2.0", "tensorflow_hub": ">=0.8"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world'])\nprint(embeddings)", "performance": {"dataset": "STS benchmark", "accuracy": "0.803"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering and other natural language tasks."}}
{"code": "###Instruction: Discover all the elements present within a photograph of a street scene.\n###Output: <<<domain>>>: Image object detection, <<<api_call>>>: detector = hub.load('https://tfhub.dev/tensorflow/centernet/resnet50v1_fpn_512x512/1'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads a pre-trained CenterNet model with a ResNet50V1 FPN backbone from TensorFlow Hub. This model is designed for object detection, and it can recognize and locate different objects within an image. In this case, it will be used to detect all the elements present in a photograph of a street scene.<<<code>>>: import tensorflow_hub as hub\ndetector = hub.load('https://tfhub.dev/tensorflow/centernet/resnet50v1_fpn_512x512/1')\n", "api_call": "hub.load('https://tfhub.dev/tensorflow/centernet/resnet50v1_fpn_512x512/1')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image object detection", "framework": "TensorFlow Hub", "functionality": "Detect objects in images", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/tensorflow/centernet/resnet50v1_fpn_512x512/1')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nmodel_id = 'https://tfhub.dev/tensorflow/centernet/resnet50v1_fpn_512x512/1'\ndetector = hub.load(model_id)\nimage = tf.keras.preprocessing.image.load_img('image.jpg')\nimage = tf.keras.preprocessing.image.img_to_array(image)\nresult = detector(image)", "performance": {"dataset": "COCO", "accuracy": "mAP (mean Average Precision)"}, "description": "Detect objects in images using TensorFlow Hub and a pre-trained CenterNet model with ResNet50V1 FPN backbone"}}
{"code": "###Instruction: We own a car dealer business and want to develop an app that categorizes different car categories based on uploaded images.\n###Output: <<<domain>>>: Image-feature-vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call creates a Keras layer that loads the pre-trained MobileNetV2 model from TensorFlow Hub. This model is trained on the ImageNet dataset and is capable of extracting high-level features from images. By adding this layer to a TensorFlow neural network, you can fine-tune the network to categorize different car images based on the extracted features. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=(224, 224, 3), trainable=False),\n    tf.keras.layers.Dense(number_of_car_categories, activation='softmax')\n])\n\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Extract high-level features from images", "api_name": "imagenet-mobilenet_v2_100_224-feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "[None, 224, 224, 3]", "output_shape": "[None, 1280]", "trainable": "False"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=(224, 224, 3), trainable=False),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained image feature vector model using MobileNetV2 architecture on the ImageNet dataset. It extracts high-level features from images and can be used for tasks like image classification, object detection, and transfer learning."}}
{"code": "###Instruction: Given images of painted landscapes, we want to find similar images based on their visual features. Which API can we use for extracting the feature vector?\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/5'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call is used for extracting image feature vectors using the pre-trained MobileNetV2 model from TensorFlow Hub. The model is trained on the ImageNet dataset and can be used to generate feature vectors for any images, which can then be used to find similar images, like landscapes in this case. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/5',\n                    input_shape=(224,224,3),\n                    output_shape=(1280,))\n])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/5')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction", "api_name": "imagenet-mobilenet_v2_100_224-feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/5')", "api_arguments": "input_shape, output_shape", "python_environment_requirements": "tensorflow, tensorflow-hub", "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/5',\n                    input_shape=(224,224,3),\n                    output_shape=(1280,))\n])", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained MobileNetV2 model for extracting image feature vectors using TensorFlow Hub."}}
{"code": "###Instruction: We need to know what is in these photos so we can report to our officials.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the pre-trained Inception V3 model from TensorFlow Hub, which is designed to classify images into one of the 1,000 classes from the ImageNet dataset. Pass the image through the model to get predictions, which can then be decoded into class names for easier interpretation. This will provide information about the content of the images, which can be reported to officials. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v3/classification/5'\nmodel = hub.load(model_id)\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Pre-trained model for classifying images", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v3/classification/5'\nmodel = hub.load(model_id)\n\n# Load and preprocess an image\nimage = tf.keras.preprocessing.image.load_img('path/to/your/image.jpg', target_size=(299, 299))\nimage = tf.keras.preprocessing.image.img_to_array(image)\nimage = tf.keras.applications.inception_v3.preprocess_input(image)\n\n# Make a prediction\npredictions = model.predict(tf.expand_dims(image, 0))\n\n# Decode the predictions\nclass_names = tf.keras.applications.inception_v3.decode_predictions(predictions, top=1)\nprint(class_names)", "performance": {"dataset": "ImageNet", "accuracy": "0.779"}, "description": "A pre-trained image classification model using Inception V3 architecture, trained on the ImageNet dataset."}}
{"code": "###Instruction: We have a collection of animal photos, and we want to obtain a feature vector from each photo in order to properly organize them.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=[224, 224, 3]), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads a pre-trained image feature vector model, called MobileNetV2, from TensorFlow Hub. The model takes input images of shape [224, 224, 3] and produces a feature vector of shape [1280] for each image. You can use these feature vectors to organize and cluster your animal photos based on their visual features. <<<code>>>: import tensorflow_hub as hub\ninput_shape = [224, 224, 3]\nkeras_layer = hub.KerasLayer(\"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4\", input_shape=input_shape)\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Extract features from images", "api_name": "imagenet-mobilenet_v2_100_224-feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "[224, 224, 3]", "output_shape": "[1280]"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained image feature vector model based on MobileNetV2 architecture. It takes an input image of shape [224, 224, 3] and outputs a feature vector of shape [1280]."}}
{"code": "###Instruction: I took a picture of a street and want to separate the vehicles, people, and buildings in the scene.\n###Output: <<<domain>>>: Image segmentation, <<<api_call>>>: model = hub.load('https://tfhub.dev/tensorflow/deeplabv3/1'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the DeepLab v3 model from TensorFlow Hub. This model performs image segmentation, separating different objects and classes in a given image. It is trained on the PASCAL VOC 2012 dataset, which includes classes for vehicles, people, and buildings among others. By using this model, you can segment the input image and obtain a more detailed understanding of the different components in the scene. <<<code>>>: import tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/tensorflow/deeplabv3/1')\n", "api_call": "hub.load('https://tfhub.dev/tensorflow/deeplabv3/1')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image segmentation", "framework": "TensorFlow Hub", "functionality": "DeepLab v3", "api_name": "deeplabv3", "api_call": "hub.load('https://tfhub.dev/tensorflow/deeplabv3/1')", "api_arguments": {"input_tensor": "3-D float32 tensor", "output_tensor": "4-D float32 tensor"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/tensorflow/deeplabv3/1')\ninput_image = tf.constant(image, dtype=tf.float32)\noutput_image = model(input_image)", "performance": {"dataset": "PASCAL VOC 2012", "accuracy": "77.21%"}, "description": "DeepLab v3 is an image segmentation model for TensorFlow Hub that segments images into different classes. It is trained on the PASCAL VOC 2012 dataset and achieves an accuracy of 77.21% on the validation set."}}
{"code": "###Instruction: I need to quickly classify images of various objects on my phone. Which pre-trained model should I use for efficient processing in a mobile environment?\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: model = tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4', output_shape=[1001])]), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The MobileNet V2 pre-trained model is suitable for efficient image classification on mobile devices. It is available on TensorFlow Hub and can be quickly integrated into your mobile application using TensorFlow. MobileNet V2 is designed to be both lightweight and effective while providing a good level of accuracy. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\n# Create a MobileNet V2 model for image classification\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4', output_shape=[1001])\n])\n", "api_call": "tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4')])", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading pre-trained models", "api_name": "mobilenet_v2_100_224", "api_call": "tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4')])", "api_arguments": {"url": "https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4", "output_shape": "[1001]"}, "python_environment_requirements": {"tensorflow": ">=2.0", "tensorflow_hub": ">=0.12"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4', output_shape=[1001])\n])\n\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, 0)\n\npredictions = model.predict(image_array)\n", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained image classification model using MobileNet V2 architecture with 1001 output classes available on TensorFlow Hub."}}
{"code": "###Instruction: I want to enhance my wildlife images and need to extract an image feature vector to use in advanced image processing tasks.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: By using this API call, you can construct a feature extractor layer that embeds images as high-dimensional feature vectors using the MobileNetV2 architecture. This pre-trained model is based on the ImageNet dataset, making it suitable for extracting features from diverse image types, including wildlife images. These feature vectors can then be used as input for various advanced image processing and analysis tasks. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\n# Create a Keras layer for extracting features from images\nfeature_extractor = hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"url": "https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4"}, "python_environment_requirements": ["tensorflow", "tensorflow-hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nfeature_extractor = hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')\nimage_input = tf.keras.Input(shape=(224, 224, 3), dtype=tf.float32, name='input_image')\nfeatures = feature_extractor(image_input)\n", "performance": {"dataset": "ImageNet", "accuracy": "71.8%"}, "description": "A pre-trained image feature vector model based on MobileNetV2 architecture, trained on ImageNet dataset. It is designed for efficient on-device image classification and related tasks."}}
{"code": "###Instruction: My computer has folders with many images, and I want to classify these images into categories, such as animals, buildings, and so on.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: model = hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call allows you to load a pre-trained TensorFlow model for image classification from TensorFlow Hub. The model uses the Inception V3 architecture and is trained on the ImageNet dataset. Once the model is loaded, you can use it to classify images from your computer into various categories, like animals or buildings. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v3/classification/5'\nmodel = hub.load(model_id)", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading pre-trained models", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v3/classification/5'\nmodel = hub.load(model_id)", "performance": {"dataset": "ImageNet", "accuracy": "Not specified"}, "description": "Load a pre-trained image classification model from TensorFlow Hub using the model_id"}}
{"code": "###Instruction: Show me how to classify an image of a dog using a pre-trained model with TensorFlow Hub and Inception V3 architecture.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: model = hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained model with the Inception V3 architecture for image classification from TensorFlow Hub. You can preprocess the image and format it appropriately before using the model to classify the image. In this case, you want to classify an image of a dog, and the model will return the predictions for the input image. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Load the pre-trained model\nmodel = hub.load(\"https://tfhub.dev/google/imagenet/inception_v3/classification/5\")\n\n# Load and preprocess the image\nimage = tf.keras.preprocessing.image.load_img(\"path/to/dog_image.jpg\", target_size=(299, 299))\nimage = tf.keras.preprocessing.image.img_to_array(image)\nimage = tf.expand_dims(image, axis=0)\nimage = tf.keras.applications.inception_v3.preprocess_input(image)\n\n# Classify the image\npredictions = model(image)\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Model for classifying images", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v3/classification/5'\nmodel = hub.load(model_id)\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(299, 299))\nimage = tf.keras.preprocessing.image.img_to_array(image)\nimage = tf.expand_dims(image, axis=0)\nimage = tf.keras.applications.inception_v3.preprocess_input(image)\npredictions = model(image)\n", "performance": {"dataset": "ImageNet", "accuracy": "Not provided"}, "description": "A pre-trained model for image classification using TensorFlow Hub and Inception V3 architecture."}}
{"code": "###Instruction: Recommend a suitable movie based on a given movie's plot. For better recommendations, obtain the plot's embedding.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the Universal Sentence Encoder model from TensorFlow Hub, which transforms text data into high-dimensional vectors. These embeddings can be used for various natural language processing tasks like text classification, semantic similarity, and clustering. In this case, you can generate the plot's embedding and use it to find similar movies by comparing their plot embeddings. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text data", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": {"input": "text"}, "python_environment_requirements": {"tensorflow": ">=2.0", "tensorflow_hub": ">=0.8"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\ntext = ['This is a sample text.']\nembeddings = embed(text)\nprint(embeddings)", "performance": {"dataset": "STS benchmark", "accuracy": "0.78"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering and other natural language tasks."}}
{"code": "###Instruction: Obtain image features from an image dataset to use in a product recommendation system\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads a MobileNet v2 model from TensorFlow Hub, which has been trained on ImageNet. This model is used for extracting 1280-dimensional feature vectors from images with a shape of (224, 224, 3). These feature vectors can be used as a basis for a product recommendation system, where similarity between these features can help find visually similar products. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=(224, 224, 3),\n                   trainable=False)\n])\n\n# Use the model to extract features from an image dataset (assuming 'image_dataset' is a TensorFlow data object containing properly resized images)\nfeatures = model.predict(image_dataset)\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction from images", "api_name": "imagenet-mobilenet_v2_100_224-feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"handle": "https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.6.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=(224, 224, 3),\n                   trainable=False),\n    tf.keras.layers.Dense(num_classes, activation='softmax')\n])\n\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\nhistory = model.fit(train_batches, epochs=10, validation_data=validation_batches)", "performance": {"dataset": "ImageNet", "accuracy": "71.9%"}, "description": "This module uses MobileNet v2 architecture for image feature vector extraction. It takes an input image of shape (224, 224, 3) and outputs a 1280-dimensional feature vector."}}
{"code": "###Instruction: I took a photo of a car and I want to extract its features in a vector form to use it for classification tasks later.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call provides a pre-trained MobileNetV2 model for generating feature vectors from images. The vector features can be used for various machine learning tasks like classification or similarity search. In this case, it'll be used to extract features from a car image which can later be used for classification tasks. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=(224, 224, 3),\n                   trainable=False)\n])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Generate feature vectors from images", "api_name": "imagenet-mobilenet_v2_100_224-feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "[None, 224, 224, 3]", "output_shape": "[None, 1280]"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=(224, 224, 3),\n                   trainable=False)\n])\n\n# Load image\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, 0)\n\n# Generate feature vector\nfeatures = model.predict(image_array)", "performance": {"dataset": "ImageNet", "accuracy": "71.9%"}, "description": "This API provides a pre-trained MobileNetV2 model for generating feature vectors from images. The feature vectors can be used for various machine learning tasks, such as image classification, clustering, or similarity search."}}
{"code": "###Instruction: Calculate the similarity between two sentences and determine if they have the same meaning.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder model, which encodes text into high-dimensional vectors. These vectors can be used for various natural language tasks, including calculating semantic similarity between sentences. By measuring the similarity between two sentence embeddings, you can determine if they have the same meaning. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": "text_input", "python_environment_requirements": "tensorflow, tensorflow_hub", "example_code": "import tensorflow_hub as hub; embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'); embeddings = embed(['Hello world!'])", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient > 0.8"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: We have an image dataset and want a pre-trained model as a feature extractor.\n\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the MobileNetV2 model pre-trained on the ImageNet dataset as a KerasLayer from TensorFlow Hub. It is designed to extract 1280-dimensional feature vectors from 224x224 RGB images which can be used as input for other models. The model takes an input shape of [224, 224, 3] and produces an output shape of [1280]. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\n# Creating a Sequential model with a single KerasLayer as feature extractor\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=[224, 224, 3], output_shape=[1280])\n])\n\n# Load an image, resize it to 224x224 and convert it into an array\nimage = tf.keras.preprocessing.image.load_img('path/to/your/image.jpg', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, 0)\n\n# Extract the features using the model\nfeatures = model.predict(image_array)\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Extract features from images", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "[224, 224, 3]", "output_shape": "[1280]"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=[224, 224, 3], output_shape=[1280])\n])\n\nimage = tf.keras.preprocessing.image.load_img('path/to/your/image.jpg', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, 0)\n\nfeatures = model.predict(image_array)", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained model that extracts 1280-dimensional feature vectors from 224x224 RGB images using MobileNetV2 architecture."}}
{"code": "###Instruction: We are creating a custom image search engine that can give similar image results. Extract features from images.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained MobileNet V2 feature vector model from TensorFlow Hub. The model has been trained on the ImageNet dataset to extract meaningful features from images, which can be used for similarity search or other applications. Using TensorFlow and Keras, you can build a sequential model that takes an input shape of (224, 224, 3) and maps it to an output space with a shape of (None, 1280) representing the extracted features. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=(224, 224, 3),\n                   trainable=False)\n])\n\n# Example input: a batch of images with shape [batch_size, 224, 224, 3].\nimages = tf.random.uniform((4, 224, 224, 3))\n\n# Extract features for the batch of images.\nfeatures = model(images)", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Extract image features", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "[None, 224, 224, 3]", "output_shape": "[None, 1280]"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=(224, 224, 3),\n                   trainable=False)\n])\n\n# Example input: a batch of images with shape [batch_size, 224, 224, 3].\nimages = tf.random.uniform((4, 224, 224, 3))\n\n# Extract features for the batch of images.\nfeatures = model(images)", "performance": {"dataset": "ImageNet", "accuracy": "71.9%"}, "description": "A pre-trained image feature vector model using MobileNet V2 architecture on ImageNet dataset, with 100% depth multiplier and 224x224 input image resolution. Useful for extracting features from images."}}
{"code": "###Instruction: Can you compare two sentences similarly using the embedding generation?\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder model from TensorFlow Hub, used to convert text into high-dimensional vectors. These vectors can be applied to text classification, semantic similarity, clustering, and other natural language tasks. Once loaded, you can use this model to generate embeddings for two sentences and compare their similarity by calculating the cosine similarity between their corresponding vectors. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": "input_text", "python_environment_requirements": "tensorflow, tensorflow_hub", "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world!'])\nprint(embeddings)", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.78"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: Provide me with an encoded version of the following review, so I can later use it for sentiment analysis: \"What an amazing product! I've been using it for a few weeks now and couldn't be happier.\"\n###Input: \"What an amazing product! I've been using it for a few weeks now and couldn't be happier.\"\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder from TensorFlow Hub. This model converts text into high-dimensional vectors that can be used for various natural language processing tasks, such as text classification, semantic similarity, clustering, etc. In this case, it can be used to obtain an encoded version of the provided review, which can then be used for sentiment analysis. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nreview = \"What an amazing product! I've been using it for a few weeks now and couldn't be happier.\"\nembedding = embed([review])", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text data", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow_hub as hub; embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'); embeddings = embed(['Hello world!'])", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.78"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: I have several images of various objects; can you check if there are any boats in them?\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the pre-trained Inception V3 model from TensorFlow Hub, which has been trained on the ImageNet dataset. With this model, you can classify the images you have and determine if there are any boats within them. The Inception V3 model is known for its high accuracy (78.1%) for image classification tasks. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/4')\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/4')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v3/classification/4'\nmodel = hub.load(model_id)\nimage = tf.keras.preprocessing.image.load_img('path/to/your/image.jpg', target_size=(299, 299))\ninput_image = tf.keras.preprocessing.image.img_to_array(image)\ninput_image = tf.expand_dims(input_image, 0)\npredictions = model(input_image)\npredicted_class = tf.argmax(predictions[0]).numpy()", "performance": {"dataset": "ImageNet", "accuracy": "78.1%"}, "description": "This example demonstrates how to load a pre-trained Inception V3 model from TensorFlow Hub and use it to classify an image. The model has been trained on the ImageNet dataset and achieves 78.1% accuracy."}}
{"code": "###Instruction: We are building a software that can recognize similar objects in a series of images. We need feature vectors for each image.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call imports a pre-trained TensorFlow model for extracting image feature vectors using the MobileNetV2 architecture. The model is trained on the ImageNet dataset and can be used as a Keras layer to create a customized neural network. By doing so, you can extract feature vectors from images, which can then be used for various computer vision tasks, such as recognizing similar objects in a series of images.<<<code>>>: model = tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224, 224, 3), trainable=False)])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "(224, 224, 3)"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "model = tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224, 224, 3), trainable=False), tf.keras.layers.Dense(1)])", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained image feature vector model using MobileNetV2 architecture for extracting features from images. The model is trained on ImageNet dataset and can be used for various computer vision tasks."}}
{"code": "###Instruction: Can you help me obtain the embeddings of a list of sentences for a research on similarity between news headlines?\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: To help you obtain embeddings for the list of sentences, you can use the Universal Sentence Encoder from TensorFlow Hub. This model encodes text into high-dimensional vectors, in this case, the text being news headlines. These embeddings can then be used for various natural language processing tasks, including semantic similarity analysis on news headlines. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello, world!', 'How are you?'])\nprint(embeddings)", "performance": {"dataset": "STS benchmark", "accuracy": "pearson_correlation=0.803"}, "description": "A model that encodes text into 512-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks"}}
{"code": "###Instruction: I have an image dataset and I want to compute feature vectors to perform similarity computation using nearest neighbor searching.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call creates a Keras layer using the pre-trained MobileNetV2 model from TensorFlow Hub. This model is designed to extract 1280-dimensional feature vectors from images. By incorporating this layer into your image processing pipeline, you can compute feature vectors for each image in your dataset. These feature vectors can then be used to perform similarity computations, such as nearest neighbor searching. <<<code>>>: import tensorflow_hub as hub\nfeature_extractor = hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Extract feature vectors from images", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input": "image_tensor", "output": "feature_vector"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer(\n        'https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n        input_shape=(224, 224, 3)\n    )\n])\n\nimage_tensor = tf.zeros(shape=(1, 224, 224, 3))\nfeature_vector = model(image_tensor)", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained MobileNetV2 model that takes an image tensor as input and returns a 1280-dimensional feature vector."}}
{"code": "###Instruction: A dating website wants to auto-match users based on the similarity of their profiles. How can we do that using text embeddings?\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: To match users based on the similarity of their profile text, you can load the Universal Sentence Encoder from TensorFlow Hub. This model encodes text into high-dimensional vectors. Create embeddings for each user's profile text and then compare the embeddings using similarity measures (e.g., cosine similarity). Users with higher similarity scores can be matched. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world!'])\nprint(embeddings)", "performance": {"dataset": "STSbenchmark", "accuracy": "0.803"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks. The model is trained and optimized for greater-than-word length text, such as sentences, phrases, or short paragraphs."}}
{"code": "###Instruction: We are creating a mobile app where users can take photos of objects, and our app should identify what the object is.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the pre-trained Inception V3 image classification model from TensorFlow Hub, which has been trained on the ImageNet dataset. It can be used to perform image classification on a wide range of objects. By feeding an image of an object into the model, it will output the most likely class labels for that object along with their associated probabilities. This can be integrated into a mobile app for object identification. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Pre-trained model for image classification", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v3/classification/5'\nmodel = hub.load(model_id)\n\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(299, 299))\nimage = tf.keras.preprocessing.image.img_to_array(image)\nimage = tf.expand_dims(image, axis=0)\n\npredictions = model(image)\n", "performance": {"dataset": "ImageNet", "accuracy": "77.9%"}, "description": "A pre-trained model for image classification using Inception V3 architecture and trained on ImageNet dataset."}}
{"code": "###Instruction: We are building a Tinder-clone app for pets adoption. When user swipes, we want to show them the most similar pets based on images. Therefore, in order to find similar pets, we need to get the feature vector of each pet photo.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call involves a pre-trained MobileNet V2 model from TensorFlow Hub, which generates a 1280-dimensional feature vector for each pet image. By obtaining the feature vector for each pet photo, you can compute similarity scores between different images, making it easier to display and recommend similar pets to users in a pet-adoption app. <<<code>>>: import tensorflow_hub as hub\nfeature_extractor = hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224, 224, 3), trainable=False)\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction from images", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "[None, 224, 224, 3]", "output_shape": "[None, 1280]"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "model = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                    input_shape=(224,224,3),\n                    trainable=False),\n    tf.keras.layers.Dense(num_classes, activation='softmax')\n])\nmodel.compile(optimizer=tf.keras.optimizers.Adam(),\n              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])", "performance": {"dataset": "ImageNet", "accuracy": "71.9%"}, "description": "A pre-trained model that takes an image input and outputs a 1280-dimensional feature vector representing the image, which can be used for various tasks such as classification, clustering, and similarity search."}}
{"code": "###Instruction: I have pictures on my phone and want to organize them into categories. Help me identify what each picture represents.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: model = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the pre-trained MobileNetV2 model from TensorFlow Hub, which is specifically designed for image classification tasks. The model has been trained on the ImageNet dataset and can be used to classify your pictures into one of the many classes that it's been trained on. Once loaded, you can pass your images to the model to identify and categorize them. <<<code>>>: import tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading pre-trained models for image classification", "api_name": "imagenet_mobilenet_v2_100_224_classification", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": ["model_url"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "", "performance": {"dataset": "ImageNet", "accuracy": "71.8%"}, "description": "Load MobileNetV2 model pre-trained on ImageNet dataset for image classification."}}
{"code": "###Instruction: Identify the category for these images to decide which category I should tag them on my blog.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the pre-trained MobileNet V2 model from TensorFlow Hub, which has been trained on the ImageNet dataset for image classification. By using this model, you can predict the categories for your images, and decide which category to use for tagging them on your blog. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\n\n# Preprocess image\nimage = tf.keras.preprocessing.image.load_img('image.jpg', target_size=(224, 224))\ninput_image = tf.keras.preprocessing.image.img_to_array(image)\ninput_image = tf.expand_dims(input_image, 0)\n\n# Make prediction\npredictions = model(input_image)\n\n# Get class label\npredicted_class = tf.argmax(predictions, axis=-1)\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Pre-trained image classification models", "api_name": "imagenet-mobilenet_v2_100_224-classification", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": {"input": "224x224 RGB image", "output": "1001 element vector of logits"}, "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\n\n# Preprocess image\nimage = tf.keras.preprocessing.image.load_img('image.jpg', target_size=(224, 224))\ninput_image = tf.keras.preprocessing.image.img_to_array(image)\ninput_image = tf.expand_dims(input_image, 0)\n\n# Make prediction\npredictions = model(input_image)\n\n# Get class label\npredicted_class = tf.argmax(predictions, axis=-1)", "performance": {"dataset": "ImageNet", "accuracy": "71.8%"}, "description": "A pre-trained image classification model using MobileNet V2 architecture on the ImageNet dataset."}}
{"code": "###Instruction: Provide an API call that can detect any landmark in a given photo.\n###Output: <<<domain>>>: image-classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the MobileNet V2 model for image classification from TensorFlow Hub, which has been pre-trained on the ImageNet dataset. The model can be used to classify various objects and scenes in images, including the detection of landmarks. Once loaded, you can pass an image tensor to the model to get back the class labels and associated confidence scores for classification. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Load the MobileNet V2 image classification model\nmodel_id = 'https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'\nmodel = hub.load(model_id)\n# Use the model to classify an image\nresult = model(image_tensor)\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Pre-trained image classification models", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'\nmodel = hub.load(model_id)\nresult = model(image_tensor)", "performance": {"dataset": "ImageNet", "accuracy": "Varies depending on the model"}, "description": "TensorFlow Hub provides a variety of pre-trained image classification models that can be easily loaded and used for various image classification tasks. The models are trained on the ImageNet dataset and their performance varies depending on the specific model chosen."}}
{"code": "###Instruction: We have a car selling website and want to identify the model of the car based on the images uploaded by the seller.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained image classification model using the MobileNet V2 architecture from TensorFlow Hub, which has been trained on the ImageNet dataset. The model allows you to classify the input images into one of the 1000 classes. You can load the image, preprocess it, and then use the model to make predictions for identifying the car model. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\n# Load the ImageNet MobileNet V2 pre-trained model\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\n\n# Prepare an image (assuming 'image_path' is the path to your image)\nimage = tf.keras.preprocessing.image.load_img(image_path, target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, 0)\n\n# Make predictions\npredictions = model(image_array)\n\n# Decode predictions\npredicted_class = tf.keras.applications.mobilenet_v2.decode_predictions(predictions.numpy(), top=1)[0][0][1]\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading a pre-trained image classification model", "api_name": "imagenet_mobilenet_v2_100_224_classification", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": {"url": "https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.6.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\n\n# Prepare an image\nimage = tf.keras.preprocessing.image.load_img('path/to/your/image.jpg', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, 0)\n\n# Make predictions\npredictions = model(image_array)\n\n# Decode predictions\npredicted_class = tf.keras.applications.mobilenet_v2.decode_predictions(predictions.numpy(), top=1)[0][0][1]", "performance": {"dataset": "ImageNet", "accuracy": "71.8%"}, "description": "A pre-trained image classification model using MobileNetV2 architecture and trained on ImageNet dataset. The model is available on TensorFlow Hub and can be used for classifying images into one of 1000 classes."}}
{"code": "###Instruction: I'd like to look into a list of articles and rank them by their similarity to the provided statement. \n###Input: <noinput>\n###Output: <<<domain>>>: text-embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API loads the Universal Sentence Encoder from TensorFlow Hub, which is capable of encoding text into high-dimensional vectors. Given a list of articles and a reference statement, you can compute the embeddings for all the article texts and the statement; then, by comparing their embeddings' cosine similarity, you can rank the articles according to their semantic similarity to the statement. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\n# Load the Universal Sentence Encoder\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": {"input": "List of strings"}, "python_environment_requirements": {"tensorflow": "2.0.0", "tensorflow_hub": "0.8.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world', 'This is a test'])", "performance": {"dataset": "STS Benchmark", "accuracy": "Pearson correlation coefficient of 0.78"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: Can you suggest how to extract features from animal images and classify them into their respective species?\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: You can extract features from animal images by using a pre-trained MobileNetV2 model from TensorFlow Hub, which is designed for feature extraction from images. After extracting the features via the model, you can use the generated 1280-dimensional feature vector as input to a classifier that is trained to classify animal species. Finally, you can use the code below to create a Keras model and extract the features. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=(224, 224, 3),\n                   trainable=False),\n    tf.keras.layers.Dense(num_classes, activation='softmax')\n])\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\nmodel.fit(train_data, train_labels, epochs=10, validation_data=(val_data, val_labels))\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction", "api_name": "imagenet-mobilenet_v2_100_224-feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"handle": "https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4", "trainable": "False"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=(224, 224, 3),\n                   trainable=False),\n    tf.keras.layers.Dense(num_classes, activation='softmax')\n])\n\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\nmodel.fit(train_data, train_labels, epochs=10, validation_data=(val_data, val_labels))", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained MobileNetV2 model for extracting image feature vectors. The model takes an image of size 224x224 and returns a 1280-dimensional feature vector."}}
{"code": "###Instruction: Create an image-based recommendation system to identify visually similar products.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call creates a feature extraction layer using TensorFlow Hub's pre-trained MobileNet V2 model. The model is trained on the ImageNet dataset and outputs a high-dimensional feature vector for each input image. These feature vectors can be compared for similarity to create an image-based recommendation system by identifying visually similar products. <<<code>>>: import tensorflow_hub as hub\nfeature_extractor_layer = hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": ["input_shape", "output_shape", "trainable"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "", "performance": {"dataset": "ImageNet", "accuracy": "71.8%"}, "description": "A pre-trained feature vector model that can be used for image classification and other computer vision tasks."}}
{"code": "###Instruction: Our company wants to create a product recommender that sorts products based on visual similarity, help us identify the products in images.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the pre-trained Inception V3 model from TensorFlow Hub. This model has been trained on the ImageNet dataset and can classify images into 1000 different categories. By using this model, you can identify the products in images, which can then be used to create a product recommender based on visual similarity. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v3/classification/5'\nmodel = hub.load(model_id)\n\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(299, 299))\ninput_image = tf.keras.preprocessing.image.img_to_array(image)\ninput_image = tf.expand_dims(input_image, 0)\n\npredictions = model(input_image)\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Pre-trained image classification model", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "api_arguments": {"model_id": "string"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v3/classification/5'\nmodel = hub.load(model_id)\n\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(299, 299))\ninput_image = tf.keras.preprocessing.image.img_to_array(image)\ninput_image = tf.expand_dims(input_image, 0)\n\npredictions = model(input_image)\n", "performance": {"dataset": "ImageNet", "accuracy": "0.779"}, "description": "A pre-trained image classification model using Inception V3 architecture, trained on ImageNet dataset. The model can be used to classify images into 1000 different categories."}}
{"code": "###Instruction: I have a list of short movie descriptions and want to get an embedding of each description.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the Universal Sentence Encoder model from TensorFlow Hub. This model encodes text into high-dimensional vectors that can be used for various natural language processing tasks including text classification, semantic similarity, and clustering. In this case, it will be used to get embeddings for each movie description, allowing further analysis or classification based on these embeddings. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embed text data", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": "URL of the model", "python_environment_requirements": "tensorflow, tensorflow_hub", "example_code": "import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world!'])", "performance": {"dataset": "STS benchmark", "accuracy": "0.803"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: Develop an application that can recognize the names of items on a store shelf based on their images.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4', output_shape=[1001])]), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call creates a pre-trained image classification model using the MobileNetV2 architecture, which is trained on the ImageNet dataset with 1,000 different categories. With this model, you can classify a wide range of objects, including items commonly found on store shelves. To use the model, feed images with the proper dimensions as input, and it will provide the most likely category label associated with the input image. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Create a model using the pre-trained MobileNetV2 architecture\nmodel = tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4', output_shape=[1001])])\nmodel.build([None, 224, 224, 3])", "api_call": "tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4')])", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Pre-trained Image Classifier", "api_name": "mobilenet_v2", "api_call": "tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4')])", "api_arguments": {"url": "https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4", "output_shape": "[1001]"}, "python_environment_requirements": {"tensorflow": "2.x", "tensorflow_hub": "0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4', output_shape=[1001])])\nmodel.build([None, 224, 224, 3])", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained image classification model using MobileNetV2 architecture on TensorFlow Hub. It can be used to classify images into 1000 different categories with high accuracy."}}
{"code": "###Instruction: Determine which politicians are similar to each other based on their quotes by obtaining an embedding for each quote.\n###Output: <<<domain>>>: text-embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: By using the Universal Sentence Encoder from TensorFlow Hub, you can obtain embeddings for the text, which are high-dimensional vectors that represent the text's content. In this case, the text will be quotes from politicians. By comparing these embeddings, you can identify similarities between the politicians based on their quotes.<<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow_hub as hub; embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'); embeddings = embed(['Hello world']); print(embeddings)", "performance": {"dataset": "STSbenchmark", "accuracy": "Pearson correlation coefficient of 0.78"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks. It is trained on a variety of data sources and a variety of tasks with the aim of dynamically accommodating a wide variety of natural language understanding tasks."}}
{"code": "###Instruction: I have a list of movie reviews and I want to find the semantic similarity between them. How can I convert theses reviews into numerical data?\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: To convert movie reviews into numerical data, you can use the Universal Sentence Encoder model available on TensorFlow Hub. The model first needs to be loaded, after which you can pass your list of movie reviews to it. The output will be embeddings for each review, which can then be used to compute the semantic similarity between different reviews. <<<code>>>: import tensorflow_hub as hub\n# Load the Universal Sentence Encoder model\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n# Generate embeddings for a list of movie reviews (assuming 'reviews' is a list of strings containing the movie reviews)\nembeddings = embed(reviews)\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Generate embeddings for text", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello, world!'])", "performance": {"dataset": "Various", "accuracy": "N/A"}, "description": "A pre-trained model for generating text embeddings using the Universal Sentence Encoder. It can be used for various NLP tasks like semantic similarity, text classification, and clustering."}}
{"code": "###Instruction: There are some insects in the park, I want to recognize them using an app.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call uses the MobileNetV2 pre-trained image classification model from TensorFlow Hub, which has been trained on the ImageNet dataset. This model can be used to recognize various objects, including insects you may find in a park, by feeding in images of the insects. The model has an input size of 224x224 and provides an output in the form of class probabilities. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\n])\n\nimage = tf.keras.preprocessing.image.load_img('path/to/your/image.jpg', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, 0)\n\npredictions = model.predict(image_array)\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Pre-trained image classification model", "api_name": "imagenet-mobilenet_v2_100_224-classification", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": {"url": "https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\n])\n\nimage = tf.keras.preprocessing.image.load_img('path/to/your/image.jpg', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, 0)\n\npredictions = model.predict(image_array)\n", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained image classification model using MobileNetV2 architecture on ImageNet dataset with 100% depth and 224x224 input size."}}
{"code": "###Instruction: I want to inspect my living room and detect all the objects in a photo I have taken.\n###Output: <<<domain>>>: Image object detection, <<<api_call>>>: hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the Single Shot MultiBox Detector (SSD) with MobileNet V2 model from TensorFlow Hub. This pre-trained model is used for detecting objects in images. Once loaded, the model can be used to feed in images, and it will provide the detected objects' information, such as class, bounding box coordinates, and confidence scores. In this case, it can be used to detect objects in a photo of your living room. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\ndetector = hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')\n", "api_call": "hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image object detection", "framework": "TensorFlow Hub", "functionality": "Detect objects in an image", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nmodel_id = 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'\ndetector = hub.load(model_id)\nimage = tf.image.decode_image(tf.io.read_file('path/to/image.jpg'))\nresult = detector(image[tf.newaxis, ...])", "performance": {"dataset": "COCO", "accuracy": "Not specified"}, "description": "A pre-trained TensorFlow Hub model for detecting objects in an image using the Single Shot MultiBox Detector (SSD) with MobileNet V2."}}
{"code": "###Instruction: A retail store needs a tool that will be able to detect misplaced items on their shelves.\n###Output: <<<domain>>>: Image object detection, <<<api_call>>>: hub.load('https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: In this API call, we load the Faster R-CNN model, specifically the Inception ResNet v2 model, which is pre-trained on the Open Images v4 dataset. This model is used for object detection tasks in images, allowing you to detect the presence and location of various objects within an image. Once loaded, you can pass an image to the detector to obtain the detections and classify them. It will help the retail store detect misplaced items on their shelves by identifying the objects and their positions. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel_id = 'https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1'\ndetector = hub.load(model_id)\n\n# Assuming 'image' is a TensorFlow tensor representing the image\nresult = detector([image])", "api_call": "hub.load('https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image object detection", "framework": "TensorFlow Hub", "functionality": "Detect objects in an image", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1'\ndetector = hub.load(model_id)\n\nimage = tf.image.decode_jpeg(tf.io.read_file('image.jpg'))\nresult = detector([image])", "performance": {"dataset": "OpenImages_v4", "accuracy": "N/A"}, "description": "This API allows you to detect objects in an image using TensorFlow Hub and a pre-trained model."}}
{"code": "###Instruction: I need to build a pet breed classifier from images. I want to use a pre-trained model to extract feature vectors of a pet image.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/inception_v3/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call is used to create a KerasLayer that extracts feature vectors from images using a pre-trained Inception V3 model available on TensorFlow Hub. These feature vectors can then be utilized for various image recognition and classification tasks, such as building a pet breed classifier. The API call adds the KerasLayer as a part of a TensorFlow model that can be trained and fine-tuned for the specific classification task. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nfeature_extractor = hub.KerasLayer('https://tfhub.dev/google/imagenet/inception_v3/feature_vector/4', trainable=False)\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/inception_v3/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction from images", "api_name": "model_id", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/inception_v3/feature_vector/4')", "api_arguments": ["model_id", "input_shape", "trainable"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v3/feature_vector/4'\ninputs = tf.keras.Input(shape=(224, 224, 3))\nfeature_extractor = hub.KerasLayer(model_id, trainable=False)(inputs)\noutputs = tf.keras.layers.Dense(1000, activation='softmax')(feature_extractor)\nmodel = tf.keras.Model(inputs=inputs, outputs=outputs)", "performance": {"dataset": "ImageNet", "accuracy": "Not specified"}, "description": "This API allows users to extract feature vectors from images using a pre-trained model from TensorFlow Hub. The feature vectors can then be used for various image recognition and classification tasks."}}
{"code": "###Instruction: We have set of images and want classify them into meaningful categories.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the pre-trained Inception V3 model from TensorFlow Hub, specifically designed for image classification tasks. By loading the model with the provided 'model_id', you can use it to classify images into various categories, as defined by the ImageNet dataset. Once the model is loaded, you can process and classify the images accordingly. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v3/classification/5'\nImage_classifier= hub.load(model_id)", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v3/classification/5'\nloaded_model = hub.load(model_id)", "performance": {"dataset": "ImageNet", "accuracy": "Not specified"}, "description": "Load a pre-trained image classification model from TensorFlow Hub using the specified model_id."}}
{"code": "###Instruction: Show me how to get the semantic similarity between two sentences.\n###Input: \"I am going to the store to buy groceries.\", \"I will visit the market to purchase food items.\" \n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: To find the semantic similarity between two sentences, first load the Universal Sentence Encoder model from TensorFlow Hub using the given API call. Then, you will embed the given sentences separately and compute their embeddings. Finally, calculate the cosine similarity between these embeddings to determine the semantic similarity. <<<code>>>: import tensorflow_hub as hub\nimport numpy as np\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nsentence1 = \"I am going to the store to buy groceries.\"\nsentence2 = \"I will visit the market to purchase food items.\"\nembeddings = embed([sentence1, sentence2])\ncosine_similarity = np.inner(embeddings[0], embeddings[1])", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embed text data", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow-hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world!'])", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.78"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: I took a photo of my friends playing soccer. I am making a collage and we need to remove the background from the photo, segmenting the players in the image.\n###Output: <<<domain>>>: Image segmentation, <<<api_call>>>: model = hub.load('https://tfhub.dev/tensorflow/deeplabv3_257_mv_gpu/1'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the DeepLabv3 model from TensorFlow Hub, which is a deep learning model designed for image segmentation. It assigns a semantic label to each pixel in the input image, enabling you to easily remove the background and identify the players. The model is trained on the PASCAL VOC 2012 dataset and achieves high accuracy in semantic segmentation tasks. <<<code>>>: import tensorflow_hub as hub\nmodel = hub.load(\"https://tfhub.dev/tensorflow/deeplabv3_257_mv_gpu/1\")\n", "api_call": "hub.load('https://tfhub.dev/tensorflow/deeplabv3_257_mv_gpu/1')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image segmentation", "framework": "TensorFlow Hub", "functionality": "Image segmentation model", "api_name": "deeplabv3_257_mv_gpu", "api_call": "hub.load('https://tfhub.dev/tensorflow/deeplabv3_257_mv_gpu/1')", "api_arguments": {"url": "https://tfhub.dev/tensorflow/deeplabv3_257_mv_gpu/1"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.6.0"}, "example_code": "import tensorflow_hub as hub\nmodel = hub.load(\"https://tfhub.dev/tensorflow/deeplabv3_257_mv_gpu/1\")\nsegmentation = model(input_image)", "performance": {"dataset": "PASCAL VOC 2012", "accuracy": "0.897"}, "description": "DeepLabv3 is a state-of-the-art deep learning model for image segmentation. It assigns a semantic label to each pixel in the input image, allowing for a more detailed understanding of the image content. This model is trained on the PASCAL VOC 2012 dataset and achieves a mean intersection-over-union (mIoU) score of 0.897."}}
{"code": "###Instruction: Investigate art works in a museum by creating a feature vector database for all paintings on display.\n###Output: <<<domain>>>: Image-feature-vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_140_224/feature_vector/4', input_shape=(224, 224, 3), trainable=False), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call creates a KerasLayer that loads the MobileNet V2 model from TensorFlow Hub, pre-trained on the ImageNet dataset for feature extraction. With an input shape of (224, 224, 3), it can process images of paintings, generating feature vectors that make up a database for easy comparison and analysis. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_140_224/feature_vector/4', input_shape=(224, 224, 3), trainable=False)\n])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_140_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Extract image features", "api_name": "imagenet_mobilenet_v2_140_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_140_224/feature_vector/4')", "api_arguments": {"url": "https://tfhub.dev/google/imagenet/mobilenet_v2_140_224/feature_vector/4"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_140_224/feature_vector/4',\n                    input_shape=(224, 224, 3),\n                    trainable=False)\n])\n\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_batch = tf.expand_dims(image_array, 0)\n\nfeatures = model.predict(image_batch)", "performance": {"dataset": "ImageNet", "accuracy": "80.3%"}, "description": "This API provides a pre-trained MobileNetV2 model for extracting feature vectors from images. The model is trained on the ImageNet dataset and achieves 80.3% accuracy on the validation set."}}
{"code": "###Instruction: Once a day, I take a photo of my backyard to observe how the plants change over time. Detect what is present in the image.\n###Output: <<<domain>>>: image-classification, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call imports a pre-trained image classification model from TensorFlow Hub using the MobileNet V2 architecture. You can use this model to detect and classify objects in images, such as plants in your backyard. Once the model is loaded, you can build a TensorFlow Keras model and pass input images to get predictions for the different classes present. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Load the pre-trained MobileNet V2 model\nmodel = tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4', trainable=True)])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading", "api_name": "model_id", "api_call": "hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4')", "api_arguments": {"model_id": "string"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4'\nmodel = tf.keras.Sequential([\n    hub.KerasLayer(model_id, trainable=True)\n])", "performance": {"dataset": "ImageNet", "accuracy": "Not specified"}, "description": "Load a pre-trained image classification model from TensorFlow Hub and use it for classifying images."}}
{"code": "###Instruction: I would like to be able to identify an animal in a photo I took while traveling.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4', input_shape=(224, 224, 3)), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: You can utilize the MobileNet V2 model from TensorFlow Hub, pre-trained on the ImageNet dataset for image classification. Start by creating a KerasLayer with the model's URL, and use this layer in a TensorFlow Keras model. Next, preprocess your image and feed it into the model for prediction. The output will be a predicted class corresponding to the animal in the image. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4', input_shape=(224, 224, 3))])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Image classification model", "api_name": "mobilenet_v2_100_224", "api_call": "hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4')", "api_arguments": {"url": "https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4", "input_shape": "(224, 224, 3)"}, "python_environment_requirements": {"tensorflow": ">=2.0", "tensorflow_hub": ">=0.12"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4', input_shape=(224, 224, 3))\n])\n\n# Load an image and preprocess it\nimage = tf.keras.preprocessing.image.load_img('path/to/your/image.jpg', target_size=(224, 224))\ninput_image = tf.keras.preprocessing.image.img_to_array(image)\ninput_image = tf.expand_dims(input_image, 0)\n\n# Predict the class of the image\npredictions = model.predict(input_image)\npredicted_class = tf.math.argmax(predictions, axis=-1)", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained image classification model using MobileNetV2 architecture on ImageNet dataset."}}
{"code": "###Instruction: In order to classify animals, I need to extract image features to train my own classification model.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224, 224, 3)), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained image feature extraction model using the MobileNetV2 architecture from TensorFlow Hub. The model is trained on the ImageNet dataset and can extract features from images. By loading this model as a KerasLayer, you can use it in your custom classification model by adding a dense layer with the appropriate number of outputs and activation function.  <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224, 224, 3), trainable=False),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Extract image features", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "(224, 224, 3)"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=(224, 224, 3), trainable=False),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])", "performance": {"dataset": "ImageNet", "accuracy": "71.9%"}, "description": "A pre-trained image feature extraction model using MobileNetV2 architecture on ImageNet dataset to convert images into feature vectors."}}
{"code": "###Instruction: What kind of furniture is in my room? I want to take a photo and recognize which type of furniture it is.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: model = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the pre-trained MobileNetV2 image classification model from TensorFlow Hub. The model is trained on the ImageNet dataset with 100% depth and 224x224 input size. Once you have the model, you can feed the images of the furniture in your room and the model will recognize and classify the type of furniture. <<<code>>>: import tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading pre-trained models", "api_name": "imagenet_mobilenet_v2_100_224_classification", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": "URL of the pre-trained model", "python_environment_requirements": "tensorflow, tensorflow_hub", "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\nimage = tf.keras.preprocessing.image.load_img('image.jpg', target_size=(224, 224))\ninput_array = tf.keras.preprocessing.image.img_to_array(image)\ninput_array = tf.expand_dims(input_array, 0)\npredictions = model(input_array)\nprint(predictions)", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained image classification model using MobileNetV2 architecture on ImageNet dataset with 100% depth and 224x224 input size."}}
{"code": "###Instruction: Create a mobile application that recognizes dogs and cats. I need features from photos of dogs and cats.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the pre-trained MobileNetV2 model for extracting feature vectors from images, using TensorFlow Hub. By incorporating this KerasLayer with the correct input and output shapes into your TensorFlow model, you can use it to extract features from photos of dogs and cats for your mobile application. This can help you create a classifier to recognize dogs and cats in images. <<<code>>>: model = tf.keras.Sequential([\n  hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                 input_shape=(224,224,3), output_shape=(1280,))\n])", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction from images", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "(224, 224, 3)", "output_shape": "(1280,)"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.6.0"}, "example_code": "model = tf.keras.Sequential([\n  hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                 input_shape=(224,224,3), output_shape=(1280,))\n])", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained MobileNetV2 model for extracting feature vectors from images, using TensorFlow Hub."}}
{"code": "###Instruction: Could you calculate the similarity between the sentences \"I have a cat\" and \"My pet is a kitten\"?\n###Input: [\"I have a cat\", \"My pet is a kitten\"]\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: To calculate the similarity between the sentences \"I have a cat\" and \"My pet is a kitten\", you can use the Universal Sentence Encoder, which embeds text into high-dimensional vectors. By loading the model from TensorFlow Hub and getting the embeddings for these sentences, you can then find the cosine similarity between them to measure how similar they are. The result will be a value between -1 and 1, representing the similarity of the sentences. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed([\"I have a cat\", \"My pet is a kitten\"])\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into a high-dimensional vector", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": {"input": "A list of strings"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.8.0"}, "example_code": "import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world!', 'Embedding with TensorFlow Hub'])", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.78"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks. The model is trained and optimized for greater-than-word length text, such as sentences, phrases, or short paragraphs."}}
{"code": "###Instruction: How can I get a descriptive vector from an image to use for a custom classification task?\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v1_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: Use the pre-trained MobileNetV1 image feature vector model available on TensorFlow Hub. The model is trained on the ImageNet dataset and offers a 70.9% accuracy. You can incorporate this model in your custom classification task by loading it as a KerasLayer to extract descriptive vectors from input images. These vectors can then be used for training a classifier in your desired domain. <<<code>>>: import tensorflow_hub as hub\n\nfeature_extractor_layer = hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v1_100_224/feature_vector/4', input_shape=(224, 224, 3), trainable=False)\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v1_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction", "api_name": "imagenet_mobilenet_v1_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v1_100_224/feature_vector/4')", "api_arguments": "input_shape, batch_size, dtype, trainable", "python_environment_requirements": "tensorflow, tensorflow_hub", "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v1_100_224/feature_vector/4', input_shape=(224, 224, 3), trainable=False),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])", "performance": {"dataset": "ImageNet", "accuracy": "70.9%"}, "description": "A pre-trained image feature vector model based on MobileNetV1 architecture for image classification and feature extraction. The model is trained on the ImageNet dataset and provides an accuracy of 70.9%."}}
{"code": "###Instruction: Tell me which kind of animal is in this image.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained MobileNet V2 model from TensorFlow Hub for image classification. The model has been trained on the ImageNet dataset and is optimized to perform well on mobile and edge devices. Once loaded, you can pass an image to the model to get class predictions. You can then use these predictions to identify the animal present in the image. <<<code>>>: import tensorflow_hub as hub\nimport tensorflow as tf\n# Load the pre-trained MobileNet V2 model\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\n# Prepare the input image\ninput_image = tf.zeros([1, 224, 224, 3])\n# Get predictions from the model\npredictions = model(input_image)\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Pre-trained model for image classification", "api_name": "imagenet_mobilenet_v2_100_224", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": {"model_url": "https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4"}, "python_environment_requirements": {"tensorflow": "2.x", "tensorflow_hub": "0.12.0"}, "example_code": "import tensorflow_hub as hub\nimport tensorflow as tf\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\ninput_image = tf.zeros([1, 224, 224, 3])\npredictions = model(input_image)", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "This model is a pre-trained image classifier using MobileNet V2 architecture on ImageNet dataset with 100% depth and 224x224 input size. It is optimized for performance on mobile and edge devices."}}
{"code": "###Instruction: Calculate the similarity between two sentences provided by users.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call allows you to load the Universal Sentence Encoder model from TensorFlow Hub. The model encodes text into high-dimensional vectors. These vectors can then be used for tasks such as text classification, semantic similarity, clustering, and other natural language processing tasks. To calculate sentence similarity, you first need to generate embeddings of the input sentences using this model and then compute the cosine similarity between the resulting vectors. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embed text", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow_hub as hub; embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'); embeddings = embed(['Hello, world!'])", "performance": {"dataset": "STSbenchmark", "accuracy": "0.84"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: I need a recommendation for similar items given a product description. First, get the embeddings of product descriptions.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The Universal Sentence Encoder is used to convert text into high-dimensional vectors. With this API call, you can load the model and generate embeddings for product descriptions, which can then be used to calculate similarities between different products and provide recommendations for similar items. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world'])\nprint(embeddings)", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.80"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks. The model is trained and optimized for greater-than-word length text, such as sentences, phrases, or short paragraphs."}}
{"code": "###Instruction: Provide me with a method to convert sentences into numerical vectors for text analysis.\n###Output: <<<domain>>>: Text preprocessing, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the Universal Sentence Encoder (USE) model from TensorFlow Hub. This pre-trained model encodes sentences into high-dimensional numerical vectors that can be utilized for a variety of natural language processing tasks, including text analysis. By transforming sentences into numerical vectors, you gain the ability to perform tasks such as classification, similarity measurement, and clustering. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world!', 'How are you?'])\nprint(embeddings)", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text preprocessing", "framework": "TensorFlow Hub", "functionality": "Text preprocessing", "api_name": "universal_sentence_encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["text_input"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world!', 'How are you?'])\nprint(embeddings)", "performance": {"dataset": "Various", "accuracy": "N/A"}, "description": "The Universal Sentence Encoder (USE) is a pre-trained model that encodes text into high-dimensional vectors that can be used for a wide range of natural language processing tasks."}}
{"code": "###Instruction: For our e-commerce product recommendation system, we need to find similar products based on a given image.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: To find similar products based on an image, first, load the MobileNetV2 model from TensorFlow Hub that is trained on ImageNet dataset. This model is used to extract feature vectors from images. After preprocessing the image, pass it through the model to get its feature vector. These feature vectors can then be used to compare the similarity between different products. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')\nimage = tf.constant(IMAGE_DATA)\nprocessed_image = tf.image.resize(image, [224, 224])\nprocessed_image = tf.expand_dims(processed_image, 0)\nfeature_vector = model(processed_image)\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction from images", "api_name": "imagenet-mobilenet_v2_100_224-feature_vector", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input": "preprocessed image", "output": "feature vector"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow-hub": ">=0.8.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')\n\n# Preprocess the image\nimage = tf.constant(IMAGE_DATA)\nprocessed_image = tf.image.resize(image, [224, 224])\nprocessed_image = tf.expand_dims(processed_image, 0)\n\n# Extract the feature vector\nfeature_vector = model(processed_image)", "performance": {"dataset": "ImageNet", "accuracy": "71.9%"}, "description": "This API allows you to extract feature vectors from images using the MobileNetV2 model trained on the ImageNet dataset. The feature vectors can be used for various tasks such as image classification, object detection, and image similarity."}}
{"code": "###Instruction: I have a dataset of user reviews written in English, and I'd like to prepare it for a sentiment analysis task. Could you help me preprocess the texts for this purpose?\n###Output: <<<domain>>>: Text preprocessing, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the Universal Sentence Encoder model from TensorFlow Hub which is used to preprocess the text. The model converts text into high-dimensional vectors, suitable for various natural language processing tasks including sentiment analysis. By obtaining the embeddings of the user reviews, you can preprocess the text and afterwards, utilize it as input for a sentiment analysis model. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text preprocessing", "framework": "TensorFlow Hub", "functionality": "Text preprocessing", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['text to be encoded'])", "performance": {"dataset": "various", "accuracy": "not specified"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: Create a recommender system that recommends related products based on their descriptions.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder model from TensorFlow Hub, which is designed to embed text into high-dimensional vectors that can be used for a variety of natural language processing tasks. In this case, by using these embeddings for product descriptions, you can create a recommender system based on the similarity between product descriptions. With the embeddings, you can efficiently measure the distance between different descriptions and recommend products with similar descriptions. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(input_descriptions)\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world'])", "performance": {"dataset": "STS benchmark", "accuracy": "0.84"}, "description": "A model for embedding text into high-dimensional vectors that can be used for various natural language processing tasks"}}
{"code": "###Instruction: Analyze a photo from a running marathon to identify the objects in the scene.\n###Output: <<<domain>>>: Image-object-detection, <<<api_call>>>: detector = hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the pre-trained SSD MobileNet V2 model from TensorFlow Hub, which is designed for object detection in images. Once loaded, you can pass an image (in the form of TensorFlow tensor or a NumPy array) to the detector to get back detected objects' bounding boxes, class labels, and associated confidence scores. Use this model to detect and classify objects in the photo from the running marathon. <<<code>>>: import tensorflow_hub as hub\nimport tensorflow as tf\ndetector = hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')", "api_call": "hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image object detection", "framework": "TensorFlow Hub", "functionality": "Object detection", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'\ndetector = hub.load(model_id)\n\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg')\nimage = tf.keras.preprocessing.image.img_to_array(image)\nresult = detector(image[None, ...])\nprint(result)", "performance": {"dataset": "COCO", "accuracy": "Not specified"}, "description": "A pre-trained image object detection model using TensorFlow Hub to detect and classify objects in an image."}}
{"code": "###Instruction: We need to analyze security camera footage and identify any intruding person or object in the frames.\n###Output: <<<domain>>>: image-object-detection, <<<api_call>>>: hub.load('https://tfhub.dev/tensorflow/efficientdet/lite0/detection/1'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the EfficientDet model from TensorFlow Hub, which is a powerful object detection model. It takes a model ID as input and can be used for tasks such as object detection and instance segmentation. Once loaded, you can pass an image tensor to the detector to get back detected objects along with their bounding boxes, class labels, and associated confidence scores. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel_id = 'https://tfhub.dev/tensorflow/efficientdet/lite0/detection/1'\n# Load the EfficientDet model\ndetector = hub.load(model_id)\n# Run the detector on an image (assuming 'image_tensor' is a TensorFlow tensor representing an image in your footage)\nresult = detector(image_tensor)\n", "api_call": "hub.load('https://tfhub.dev/tensorflow/efficientdet/lite0/detection/1')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image object detection", "framework": "TensorFlow Hub", "functionality": "Object detection in images", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/tensorflow/efficientdet/lite0/detection/1')", "api_arguments": {"model_id": "A string representing the ID of the model to be loaded"}, "python_environment_requirements": {"tensorflow": ">=2.0", "tensorflow_hub": ">=0.12"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/tensorflow/efficientdet/lite0/detection/1'\ndetector = hub.load(model_id)\n\n# Run the detector on an image\nresult = detector(image_tensor)", "performance": {"dataset": "COCO", "accuracy": "Varies depending on the model version"}, "description": "A collection of TensorFlow Hub models for detecting objects in images using the EfficientDet architecture. These models can be used for various tasks such as object detection, instance segmentation, and more."}}
{"code": "###Instruction: Need a code snippet to compute similar texts among thousands of sentences based on a similarity score.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the Universal Sentence Encoder model from TensorFlow Hub. This model converts text into high-dimensional vectors, which can be used for various natural language processing tasks, such as text classification, semantic similarity, clustering, etc. You can use the obtained embeddings to compute similarity scores between texts. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(sentences)  # Replace 'sentences' with a list of strings containing thousands of sentences\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": {"input": "List of strings"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.8.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world', 'Embedding with TensorFlow'])", "performance": {"dataset": "SNLI, MultiNLI, and SICK", "accuracy": "86.7% (SNLI), 78.6% (MultiNLI), 86.3% (SICK)"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering and other natural language tasks."}}
{"code": "###Instruction: My niece wants to learn the names of different birds so we can play a game where she sees a bird picture and the app provides a guess about the bird's species.\n###Output: <<<domain>>>: image-classification, <<<api_call>>>: model = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained image classification model based on the MobileNetV2 architecture from TensorFlow Hub. The model is fine-tuned on the ImageNet dataset, allowing it to classify images into 1000 different categories. Once the model is loaded, you can use it to provide guesses for bird species when given a bird image as input. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nimport numpy as np\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')\n\n# Load and preprocess image\nimage = tf.keras.preprocessing.image.load_img('path/to/bird/image.jpg', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, 0)\n\n# Predict\npredictions = model(image_array)\n\n# Decode predictions\nclass_names = imagenet_labels()  # You need a function to load ImageNet class labels\npredicted_class = class_names[np.argmax(predictions[0])]\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Pre-trained image classification model", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4'\nmodel = hub.load(model_id)\n\n# Load and preprocess image\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, 0)\n\n# Predict\npredictions = model(image_array)\n\n# Decode predictions\nclass_names = imagenet_labels()\npredicted_class = class_names[np.argmax(predictions[0])]", "performance": {"dataset": "ImageNet", "accuracy": "Top-1 Accuracy: 80.9%, Top-5 Accuracy: 95.2%"}, "description": "A pre-trained image classification model based on the MobileNetV2 architecture, fine-tuned on the ImageNet dataset. The model can be used to classify images into 1000 different categories."}}
{"code": "###Instruction: Can you help me recognize a flower from a picture of it?\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: model = hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained TensorFlow model for image classification using the Inception V3 architecture from TensorFlow Hub. It is trained on the ImageNet dataset, which includes numerous classes of flowers. By loading this model, you can use it to classify an input image and recognize the type of flower in the image. <<<code>>>: import tensorflow_hub as hub\nimport tensorflow as tf\nmodel = hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Pre-trained model", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v3/classification/5'\nmodel = hub.load(model_id)\n\n# Load an image as an example\nimage = tf.keras.preprocessing.image.load_img('path/to/your/image.jpg', target_size=(299, 299))\nimage = tf.keras.preprocessing.image.img_to_array(image)\nimage = tf.expand_dims(image, 0)\n\n# Make predictions\npredictions = model(image)\n", "performance": {"dataset": "ImageNet", "accuracy": "Not specified"}, "description": "A pre-trained image classification model using Inception V3 architecture from TensorFlow Hub."}}
{"code": "###Instruction: I want to search through our art collection and find similar artworks. Create a model to extract features from the artwork images that can be used for comparison and clustering.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call creates a KerasLayer using the pre-trained MobileNetV2 model for feature extraction from TensorFlow Hub. It has been trained on the ImageNet dataset to extract 1280-dimensional feature vectors, which can be used for comparing and clustering artwork images. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Create a model with a single KerasLayer for feature extraction\nmodel = tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Extract image feature vectors", "api_name": "imagenet-mobilenet_v2_100_224-feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input": "preprocessed image", "output": "feature vector"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')\n])\n\nimage = tf.keras.Input(shape=(224, 224, 3))\nfeature_vector = model(image)", "performance": {"dataset": "ImageNet", "accuracy": "71.9%"}, "description": "A pre-trained image feature vector model using MobileNetV2 architecture on ImageNet dataset. It takes a preprocessed image as input and returns a 1280-dimensional feature vector."}}
{"code": "###Instruction: I want to build a relationship between different sentences. Can you suggest a method to get a fixed-length vector representation of each sentence?\n###Output: <<<domain>>>: Text preprocessing, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: I would recommend using the Universal Sentence Encoder (USE), which encodes text into high-dimensional fixed-length vectors. These vectors are suitable for various natural language tasks, including text classification, semantic similarity, clustering, and more. By using the USE API call, you can transform sentences into fixed-length vectors and analyze the relationships between them. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text preprocessing", "framework": "TensorFlow Hub", "functionality": "Loading", "api_name": "universal_sentence_encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["URL"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world!'])", "performance": {"dataset": "Various", "accuracy": "N/A"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks. It is pre-trained on a variety of data sources and can be fine-tuned for specific tasks if needed."}}
{"code": "###Instruction: I just took a picture of my room, but I want to understand what objects are in it. Help me to analyze the content of the image.\n###Output: <<<domain>>>: Image object detection, <<<api_call>>>: detector = hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained object detection model from TensorFlow Hub, specifically the SSD MobileNet V2 model. Once the model is loaded, it can be used to detect and classify objects in images, such as the picture of your room. It will help you understand and analyze the content of the image by detecting and classifying the objects present in it. <<<code>>>: import tensorflow_hub as hub\ndetector = hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')\n", "api_call": "hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image object detection", "framework": "TensorFlow Hub", "functionality": "Object detection and classification in images", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nmodel_id = 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'\ndetector = hub.load(model_id)\nresult = detector(image_tensor)", "performance": {"dataset": "COCO", "accuracy": "Not specified"}, "description": "This API allows you to detect and classify objects in images using TensorFlow Hub and pre-trained models such as SSD MobileNet V2."}}
{"code": "###Instruction: I have tons of TikTok videos on my phone and want an AI to categorize them based on actions happening in them.\n###Output: <<<domain>>>: Video classification, <<<api_call>>>: model = hub.load('https://tfhub.dev/google/Video_Classification_Model/1'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained video classification model from TensorFlow Hub that is capable of classifying videos into one of 700 action classes. By passing the TikTok videos to the model, it can analyze the content and categorize them based on the actions occurring in each video. <<<code>>>: import tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/Video_Classification_Model/1')\n", "api_call": "hub.load('https://tfhub.dev/google/Video_Classification_Model/1')", "provider": "TensorFlow Hub", "api_data": {"domain": "Video classification", "framework": "TensorFlow Hub", "functionality": "Video classification", "api_name": "Video_Classification_Model", "api_call": "hub.load('https://tfhub.dev/google/Video_Classification_Model/1')", "api_arguments": ["video_url"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/Video_Classification_Model/1')\nresult = model(video_url)", "performance": {"dataset": "Kinetics-700", "accuracy": "Not specified"}, "description": "A pre-trained video classification model available on TensorFlow Hub, capable of classifying videos into one of 700 action classes."}}
{"code": "###Instruction: I would like to use the features extracted from pictures of different outfits for clustering. \n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=[224, 224, 3]), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call allows you to load a MobileNet V2 model from TensorFlow Hub that has been pre-trained on the ImageNet dataset. The model can be utilized for feature extraction from images. By using the extracted features of pictures of different outfits, the model can further be used for clustering similar outfits together. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Create a model with a single KerasLayer for feature extraction\nmodel = tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=[224, 224, 3])])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction from images", "api_name": "imagenet-mobilenet_v2_100_224-feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "[batch_size, 224, 224, 3]", "output_shape": "[batch_size, 1280]"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=(224, 224, 3),\n                   output_shape=(1280,),\n                   trainable=False)\n])", "performance": {"dataset": "ImageNet", "accuracy": "71.9%"}, "description": "This API provides a feature vector for images using the MobileNetV2 architecture trained on the ImageNet dataset. The input images should have shape (224, 224, 3), and the output feature vector has 1280 dimensions. The model is available on TensorFlow Hub and can be used for transfer learning applications."}}
{"code": "###Instruction: Analyze the background noise of an audio file and provide the corresponding embeddings to help classify the type of environment it was recorded in.\n###Output: <<<domain>>>: Audio embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/yamnet/1'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the YAMNet model from TensorFlow Hub. This pre-trained model is designed to generate audio embeddings for the given audio samples. Once the embeddings are generated, they can be used to classify the type of environment in which the audio was recorded, based on its background noise.<<<code>>>: import tensorflow_hub as hub\nmodel_id = 'https://tfhub.dev/google/yamnet/1'\nmodel = hub.load(model_id)\n", "api_call": "hub.load('https://tfhub.dev/google/yamnet/1')", "provider": "TensorFlow Hub", "api_data": {"domain": "Audio embedding", "framework": "TensorFlow Hub", "functionality": "Audio embedding generation", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/yamnet/1')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/yamnet/1'\nmodel = hub.load(model_id)\nembeddings = model(samples, sample_rate)", "performance": {"dataset": "YAMNet", "accuracy": "Not specified"}, "description": "This API generates audio embeddings using a pre-trained model from TensorFlow Hub. The model can be loaded with a specified model_id, and embeddings can be extracted for input audio samples."}}
{"code": "###Instruction: We built a mobile app for people to identify dogs' breeds. Let's build a model to extract features from dog images and classify them.\n###Output: <<<domain>>>: image-feature-vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=[224, 224, 3]), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the MobileNet V2 model from TensorFlow Hub, which has been pre-trained on the ImageNet dataset. This model is used for feature extraction from images. When creating a KerasLayer with this URL, the layer can then be used as part of a larger neural network model to extract features from images, and subsequently add additional layers (e.g., a Dense layer with a softmax activation function) to classify dog breeds. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Create a model using the MobileNet V2 feature vector and a custom output layer for dog breed classification\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224, 224, 3), trainable=False),\n    tf.keras.layers.Dense(num_dog_breeds, activation='softmax')\n])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction from images", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "[None, 224, 224, 3]", "output_shape": "[None, 1280]"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=(224, 224, 3),\n                   trainable=False),\n    tf.keras.layers.Dense(10, activation='softmax')\n])", "performance": {"dataset": "ImageNet", "accuracy": "71.9%"}, "description": "A pre-trained image feature vector model using MobileNet V2 architecture on ImageNet dataset. Can be used for various image classification tasks."}}
{"code": "###Instruction: We have a group of 10 people discussing different topics. Analyze their texts and find the most similar pair of text.\n###Output: <<<domain>>>: text-embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the Universal Sentence Encoder model from TensorFlow Hub, which encodes text data into high-dimensional vectors. These vectors can be used for various NLP tasks including text classification, semantic similarity, clustering, etc. By comparing the similarity of the embeddings generated from the texts of the 10 people, you can identify the most similar pair of texts. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text data", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": "input_text", "python_environment_requirements": "tensorflow, tensorflow_hub", "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\ntext = ['This is a sample text.']\nembeddings = embed(text)", "performance": {"dataset": "STS Benchmark", "accuracy": "0.803"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: Can you help me classify the contents of an image I took during my vacation?\n###Output: <<<domain>>>: image-classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained image classification model called MobileNet V2 from TensorFlow Hub. The model is trained on the ImageNet dataset, which contains several categories of images. Once the model is loaded, it can be used to classify the contents of the provided image into one of the many categories it's been trained on. This can help you identify what's in the image taken during your vacation. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Image classification model", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'\nmodel = hub.load(model_id)\nimage = tf.random.uniform((1, 224, 224, 3))\nresult = model(image)\nprint(result)", "performance": {"dataset": "ImageNet", "accuracy": "N/A"}, "description": "A pre-trained image classification model available on TensorFlow Hub that can be used to classify images into different categories."}}
{"code": "###Instruction: I have a list of headlines and would like to find which ones are semantically similar. Can you help me get the high-dimensional vectors for my headlines?\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder from TensorFlow Hub. It is a model that encodes text into high-dimensional vectors that can be used for various natural language processing tasks such as text classification, semantic similarity, clustering, and more. In this case, you will use the model to get high-dimensional vectors for your list of headlines, which can then be utilized to determine semantic similarity between them. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nheadlines_embeddings = embed(['list', 'of', 'headlines'])\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": {"input": "List of sentences"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.8.0"}, "example_code": "import tensorflow_hub as hub; embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'); embeddings = embed(['Hello world', 'I am learning how to use the Universal Sentence Encoder'])", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.78"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks. The model is trained and optimized for greater-than-word length text, such as sentences, phrases, or short paragraphs."}}
{"code": "###Instruction: Suggest a way to compute the similarity between two sentences using embeddings to help us identify which sentences are discussing the same topic.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The Universal Sentence Encoder can be used to compute the similarity between two sentences by first embedding each sentence into a high-dimensional vector representation. Then, compare the embeddings using cosine similarity, which ranges from -1 (dissimilar) to 1 (identical). By setting a suitable similarity threshold, you can identify which sentences are discussing the same topic. High similarity values indicate a higher likelihood of the sentences being semantically related. <<<code>>>: import tensorflow_hub as hub\n# Load the Universal Sentence Encoder\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world!'])", "performance": {"dataset": "STS benchmark", "accuracy": "0.803"}, "description": "A text embedding model that encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: Can you help me inidentifying content of some photos from recent vacation?\n###Output: <<<domain>>>: image-classification, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the pre-trained MobileNet V2 model from TensorFlow Hub, which has been trained on the ImageNet dataset for image classification. It creates a KerasLayer which can be used to build a model for classifying images. To identify the content of your vacation photos, you can pass them through this model to get predicted class labels indicating what the model thinks the image contains. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nfrom PIL import Image\nimport numpy as np\n\n# Create a model with a single KerasLayer for classification\nmodel = tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')])\n\n# Load and preprocess the image\nimage = Image.open('path/to/your/image.jpg').resize((224, 224))\ninput_image = np.array(image) / 255.0\ninput_image = np.expand_dims(input_image, axis=0)\n\n# Make predictions\npredictions = model.predict(input_image)\npredicted_class = np.argmax(predictions[0])\nprint('Predicted class:', predicted_class)", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Image classification using pre-trained model", "api_name": "imagenet_mobilenet_v2_100_224_classification", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": {"url": "https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0", "numpy": ">=1.19.5", "PIL": ">=8.3.2"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nfrom PIL import Image\nimport numpy as np\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\n])\n\nimage = Image.open('path/to/your/image.jpg').resize((224, 224))\ninput_image = np.array(image) / 255.0\ninput_image = np.expand_dims(input_image, axis=0)\n\npredictions = model.predict(input_image)\npredicted_class = np.argmax(predictions[0])\nprint('Predicted class:', predicted_class)", "performance": {"dataset": "ImageNet", "accuracy": "71.8%"}, "description": "A pre-trained image classification model using MobileNetV2 architecture on ImageNet dataset with 100% depth and 224x224 input size."}}
{"code": "###Instruction: My cousin has created an album of zoo animals he captured, and I want to classify the animals using a pre-trained TensorFlow model.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: model = hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained image classification model from TensorFlow Hub, based on the MobileNetV2 architecture, and fine-tuned on the ImageNet dataset. The input size for this model is 224x224 pixels. You can use this model to classify the animals in your cousin's album by feeding the images of the animals into the model as input, and it will output the predicted classes for each image. <<<code>>>: import tensorflow_hub as hub\nmodel = hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Pre-trained image classification model", "api_name": "imagenet_mobilenet_v2_130_224_classification", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')", "api_arguments": {"handle": "https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4", "trainable": "False"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.6.0"}, "example_code": "", "performance": {"dataset": "ImageNet", "accuracy": "94.1%"}, "description": "A pre-trained image classification model based on the MobileNetV2 architecture, fine-tuned on the ImageNet dataset, with an input size of 224x224 pixels."}}
{"code": "###Instruction: We want to create a Q&A system, so we need to be able to find the similarity between the questions that website visitors have asked.\n###Output: <<<domain>>>: text-embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The Universal Sentence Encoder is an API call that loads a model capable of encoding text into high-dimensional vectors. These vectors can be used for tasks including finding semantic similarity between sentences, which is crucial when creating a Q&A system. By comparing the vectors, you can determine how closely related the questions are and group similar ones to provide relevant answers. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n# Generate text embeddings for sample sentences\nembeddings = embed(['Hello, world!', 'How are you?'])\nprint(embeddings)", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello, world!', 'How are you?'])\nprint(embeddings)", "performance": {"dataset": "STS benchmark", "accuracy": "0.803"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering and other natural language tasks."}}
{"code": "###Instruction: I have a couple of videos in my library, can you suggest a model to classify them based on their content?\n###Output: <<<domain>>>: video-classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/Video_classification_model_id/1'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained video classification model from TensorFlow Hub that can classify videos based on their content. The model has been trained on the Kinetics-400 dataset, which is a large dataset of video clips covering various actions and activities. By using this model, you can analyze the content of multiple videos in your library and get classifications for each of them. <<<code>>>: import tensorflow_hub as hub\nvideo_classification_model = hub.load('https://tfhub.dev/google/Video_classification_model_id/1')\n", "api_call": "hub.load('https://tfhub.dev/google/Video_classification_model_id/1')", "provider": "TensorFlow Hub", "api_data": {"domain": "Video classification", "framework": "TensorFlow Hub", "functionality": "Video classification model", "api_name": "Video_classification_model_id", "api_call": "hub.load('https://tfhub.dev/google/Video_classification_model_id/1')", "api_arguments": [], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "", "performance": {"dataset": "Kinetics-400", "accuracy": ""}, "description": "A pre-trained video classification model available on TensorFlow Hub for classifying videos based on their content."}}
{"code": "###Instruction: A political analyst is preparing a report and needs to identify different political ideologies present in the statements made by politicians. Can you provide the embeddings of those statements to create a clustering algorithm?\n###Output: <<<domain>>>: Text-embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The Universal Sentence Encoder (USE) is a pre-trained model that transforms text into high-dimensional vectors, ideal for tasks such as semantic similarity, clustering, and text classification. In this case, the embeddings generated from politician statements can be used to cluster the statements based on their political ideology. This will help the political analyst to identify different ideologies present in the statements. <<<code>>>: import tensorflow_hub as hub\n\n# Load the Universal Sentence Encoder\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embed text using pre-trained models", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world!'])\nprint(embeddings)", "performance": {"dataset": "various text classification tasks", "accuracy": "state-of-the-art"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for a wide range of tasks such as semantic similarity, clustering, and text classification. The model is trained and optimized for greater-than-word length text, such as sentences, phrases or short paragraphs."}}
{"code": "###Instruction: My company is developing a furniture recommendation system, and we need to extract features from furniture images to find similar items.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call creates a KerasLayer that uses a pre-trained MobileNetV2 model from TensorFlow Hub. The model has been trained to extract features from images, and can be used to find similar items based on these features. The model takes an input image with dimensions [224, 224, 3] and extracts a feature vector of shape [1280]. This feature vector can then be used to develop your furniture recommendation system. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Create a model with a single KerasLayer for feature extraction\nmodel = tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=[224, 224, 3])])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Extract features from images", "api_name": "imagenet-mobilenet_v2_100_224-feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "[224, 224, 3]", "output_shape": "[1280]"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained image feature vector model based on MobileNetV2 architecture. It takes an input image of shape [224, 224, 3] and outputs a feature vector of shape [1280]."}}
{"code": "###Instruction: I am creating a search engine that checks for similar images for a given image. I want to extract the features from images for creating an image search algorithm.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/inception_v3/feature_vector/5'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call allows you to load the Inception V3 pre-trained model to extract feature vectors from images. These feature vectors can then be used for various tasks, including image search algorithms, by measuring the similarity between different image feature vectors. This can be done using distance metrics like Euclidean or cosine similarity, to determine which images in a dataset are most similar to a given image. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\n# Load Inception V3 for feature extraction\nfeature_extractor = hub.KerasLayer('https://tfhub.dev/google/imagenet/inception_v3/feature_vector/5')\n\n# Example image tensor (replace with your image data)\nimage_tensor = tf.zeros([1, 299, 299, 3])\n\n# Extract feature vector\nfeature_vector = feature_extractor(image_tensor)\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/inception_v3/feature_vector/5')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Extract feature vectors from images", "api_name": "inception_v3", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/inception_v3/feature_vector/5')", "api_arguments": {"input": "image_tensor", "output": "feature_vector"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nimage_tensor = tf.zeros([1, 299, 299, 3])\nfeature_vector = hub.KerasLayer('https://tfhub.dev/google/imagenet/inception_v3/feature_vector/5')(image_tensor)\nprint(feature_vector.shape)", "performance": {"dataset": "ImageNet", "accuracy": "0.779"}, "description": "This API allows you to extract feature vectors from images using the Inception V3 model, which is pre-trained on the ImageNet dataset. The feature vectors can be used for various machine learning tasks, such as image classification, object detection, and image similarity."}}
{"code": "###Instruction: I have a folder with a lot of images, and I want to cluster them by similarity but I do not know how to represent an image in a consistent way.\n###Output: <<<domain>>>: Image Feature Vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: Use the TensorFlow Hub API to load a pre-trained MobileNetV2 model that is trained on ImageNet dataset. The model acts as a feature extractor and represents images in a consistent format. You can add this API call as a KerasLayer and use it to process your images and create a feature vector, which you can then use to cluster the images based on similarity. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\n# Define your model to include the feature extraction layer\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'),\n    # Add any additional layers or classifiers needed\n])", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction from images", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"url": "https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.6.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'),\n    tf.keras.layers.Dense(num_classes, activation='softmax')\n])", "performance": {"dataset": "ImageNet", "accuracy": "71.9%"}, "description": "A pre-trained image feature vector model based on MobileNetV2 architecture, useful for extracting features from images. The model is trained on ImageNet dataset and has an accuracy of 71.9%."}}
{"code": "###Instruction: I want to recommend similar movies to a user. Therefore, turn movie synopses into vectors with their distances representing similarities.\n###Output: <<<domain>>>: text-embedding, <<<api_call>>>: embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the Universal Sentence Encoder from TensorFlow Hub. Once loaded, you can pass movie synopses to the model, and it will encode them into high-dimensional vectors. These vectors can then be used to measure semantic similarity between movie synopses, so that you can recommend similar movies to users based on their distances. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input: A string or a list of strings to be embedded"], "python_environment_requirements": ["tensorflow>=2.0.0", "tensorflow_hub>=0.8.0"], "example_code": "import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello, world!', 'Embeddings for text'])", "performance": {"dataset": "SNLI", "accuracy": "86.9%"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: I have several photos of objects, and I want to get compact feature vectors for each.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=[224, 224, 3]), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the MobileNet V2 model from TensorFlow Hub, which has been pre-trained on the ImageNet dataset. The pre-trained model is designed for feature extraction from images. The KerasLayer takes inputs of shape [224, 224, 3] and outputs a 1280-dimensional feature vector, which is a compact representation of the object(s) in the image. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=[224, 224, 3])\n])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction from images", "api_name": "imagenet-mobilenet_v2_100_224-feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "[224, 224, 3]", "output_shape": "[1280]"}, "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                    input_shape=(224,224,3),\n                    output_shape=(1280,))\n])\n\nimage = tf.random.uniform((1, 224, 224, 3))\nfeatures = model(image)", "performance": {"dataset": "ImageNet", "accuracy": "71.8%"}, "description": "A pre-trained model that extracts a 1280-dimensional feature vector from images using MobileNetV2 architecture."}}
{"code": "###Instruction: Can you find out the suitable API call to load pre-trained image feature vector model for classifying images?\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the pre-trained MobileNet V2 model from TensorFlow Hub, which has been trained on the ImageNet dataset. The model is specifically designed for image feature vector extraction that can be used in various image classification tasks. Once loaded, you can pass input images to extract features and perform classification tasks. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Load and use a pre-trained image feature vector model", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"url": "https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')\n\nimage = tf.zeros([1, 224, 224, 3])\nfeatures = model(image)", "performance": {"dataset": "ImageNet", "accuracy": "71.8%"}, "description": "This module uses the MobileNet v2 architecture to generate image feature vectors. The model has been pre-trained on the ImageNet dataset and can be used for various image classification tasks."}}
{"code": "###Instruction: I have a collection of vehicle images, and I want to extract features from the images to help with clustering different types of vehicles based on their appearance.\n###Output: <<<domain>>>: image-feature-vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=[224, 224, 3]), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call utilizes the MobileNet V2 model from TensorFlow Hub, which has been pretrained on the ImageNet dataset to extract features from images. This model can be used for feature extraction from your vehicle images by creating a KerasLayer that accepts images of size [224, 224, 3] as input. The extracted features can then be applied to cluster the vehicles based on their visual appearance. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\n# Create a model with a single KerasLayer for feature extraction\nmodel = tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=[224, 224, 3])])", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Extract features from images", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "[224, 224, 3]", "output_shape": "[1280]"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=[224, 224, 3], output_shape=[1280])\n])\n\nimage = tf.keras.preprocessing.image.load_img('path/to/your/image.jpg', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, 0)\n\nfeatures = model.predict(image_array)", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained model that extracts 1280-dimensional feature vectors from 224x224 RGB images using MobileNetV2 architecture."}}
{"code": "###Instruction: I want to know how to get a compact representation of images using MobileNetV1.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v1_100_224/feature_vector/4', input_shape=[224, 224, 3], trainable=False), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: To get a compact representation of images using MobileNetV1, you can use TensorFlow Hub to load the pre-trained MobileNetV1 model. By adding a KerasLayer to your model, you can extract feature vectors from input images with a shape of [224, 224, 3]. The resulting output will be a compact representation of image features with a shape of [None, 1024]. Here's an example code: <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v1_100_224/feature_vector/4', input_shape=[224, 224, 3], trainable=False),\n    tf.keras.layers.Dense(10, activation='softmax')\n])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v1_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction from images", "api_name": "imagenet_mobilenet_v1_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v1_100_224/feature_vector/4')", "api_arguments": {"input_shape": "[None, 224, 224, 3]", "output_shape": "[None, 1024]"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "model = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v1_100_224/feature_vector/4', input_shape=[224, 224, 3], trainable=False),\n    tf.keras.layers.Dense(10, activation='softmax')\n])", "performance": {"dataset": "ImageNet", "accuracy": "70.9%"}, "description": "A compact representation of the API for extracting image feature vectors using MobileNetV1 on TensorFlow Hub."}}
{"code": "###Instruction: Please help me find Latent Semantic Analysis for sentences, and it should convert text into meaningful vectors.\n###Output: <<<domain>>>: text-embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder from TensorFlow Hub, which converts text into high-dimensional vectors. These vectors can be used for various natural language processing tasks, including text classification, semantic similarity, clustering or Latent Semantic Analysis (LSA) to understand the underlying hidden meaning of sentences. <<<code>>>: import tensorflow_hub as hub\n# Load the Universal Sentence Encoder\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n# Obtain embeddings of the given sentences (assuming 'sentences' is a list of sentences)\nembeddings = embed(sentences)\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": {"input": "Text input"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.8.0"}, "example_code": "import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world'])", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.78"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: I am working on a project and need to classify images of objects, such as cars or animals, quickly and efficiently.\n###Output: <<<domain>>>: image-classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the pre-trained MobileNet V2 model from TensorFlow Hub, which has been optimized for image classification on the ImageNet dataset. The model has a 224x224 input size and 100% depth multiplier, making it suitable for fast, efficient classification of objects in images. Once loaded, you can use the model to generate logits, which can then be post-processed to obtain class labels. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Load the pre-trained MobileNet V2 model\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\n# Function to predict image categories using the model\ndef predict(image):\n    logits = model(image)\n    return logits\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading pre-trained models", "api_name": "imagenet_mobilenet_v2_100_224_classification", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": {"url": "https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.6.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\n\ndef predict(image):\n    logits = model(image)\n    return logits", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained MobileNetV2 model for image classification on the ImageNet dataset, with a 224x224 input size and 100% depth multiplier. This model is optimized for low-latency and small size, making it suitable for mobile and edge devices."}}
{"code": "###Instruction: Analyze a photo of a car taken during a trip to identify the make and model of the car.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: model = hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The Inception V3 model is a pre-trained image classification model available on TensorFlow Hub. By making an API call to load this model, you can analyze and classify images, in this case, a photo of a car. Once the model is loaded, it can be used to identify the make and model of the car in the image. <<<code>>>: import tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v3/classification/5'\nmodel = hub.load(model_id)", "performance": {"dataset": "ImageNet", "accuracy": "Not provided"}, "description": "Load a pre-trained image classification model from TensorFlow Hub using the provided model_id."}}
{"code": "###Instruction: In a wildlife app, I want to recognize animals from users' images. Fetch the model that can help to classify those images.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/2'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the pre-trained MobileNet V2 model for image classification from TensorFlow Hub. This model can recognize animals present in users' images as part of its classification capabilities. Once loaded, you can pass the user-supplied images through the model to get the predicted class labels. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Load the pre-trained MobileNet V2 model for image classification\nmodel_id = 'https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/2'\nmodel = hub.load(model_id)\n", "api_call": "hub.load('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/2')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading pre-trained models", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/2')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nmodel_id = 'https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/2'\nmodel = hub.load(model_id)", "performance": {"dataset": "ImageNet", "accuracy": "Not provided"}, "description": "Load pre-trained image classification models from TensorFlow Hub for transfer learning and fine-tuning."}}
{"code": "###Instruction: Suggest me a method to find semantic similarity between different user queries.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The Universal Sentence Encoder is a pre-trained text embedding model that maps text to high-dimensional vectors. By using this model, you can obtain embeddings for different user queries and compare them by calculating their cosine similarity. The cosine similarity will give you an indication of semantic similarity between the queries. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embed text into high-dimensional space", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": "input_text", "python_environment_requirements": "tensorflow, tensorflow_hub", "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world!'])", "performance": {"dataset": "Various text sources", "accuracy": "Not applicable"}, "description": "A pretrained text embedding model that maps text to high-dimensional vectors."}}
{"code": "###Instruction: Calculate the similarity score between two sentences, \"I like pizza\" and \"Pizza is my favorite food.\"\n###Input: {\"source_sentence\": \"I like pizza\", \"target_sentence\": \"Pizza is my favorite food\"}\n###Output: <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The Universal Sentence Encoder is a pre-trained model that converts text into high-dimensional vectors. By loading this model, you can compare the vectors of two input sentences to calculate their similarity. A higher score indicates greater similarity. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nsource_sentence = \"I like pizza\"\ntarget_sentence = \"Pizza is my favorite food\"\nsource_embedding = embed([source_sentence])\ntarget_embedding = embed([target_sentence])\nsimilarity_score = np.inner(source_embedding, target_embedding)\nprint(similarity_score)", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Converts text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello World!'])\nprint(embeddings)", "performance": {"dataset": "Common benchmarks", "accuracy": "State-of-the-art"}, "description": "A pre-trained model that encodes text into high-dimensional vectors for various natural language processing tasks"}}
{"code": "###Instruction: I want to identify the contents of various images, can you recommend a pre-trained model for this task?\n###Output: <<<domain>>>: Image-classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the pre-trained MobileNet v2 model from TensorFlow Hub, which is designed for image classification. The model has been trained on the ImageNet dataset and accepts image input of size 224x224 pixels. Upon running the model, it outputs a 1001-element vector of logits that can be used to classify the contents of the image. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading pre-trained model", "api_name": "imagenet_mobilenet_v2_130_224_classification", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')", "api_arguments": {"url": "https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.11.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')", "performance": {"dataset": "ImageNet", "accuracy": "0.919"}, "description": "This module uses the MobileNet v2 architecture for image classification, pre-trained on the ImageNet dataset. The model accepts image input of size 224x224 pixels and outputs a 1001-element vector of logits."}}
{"code": "###Instruction: When eating out or ordering takeout, I would like to know the type of food within 2 seconds by capturing the food image.\n###Output: <<<domain>>>: image-classification, <<<api_call>>>: tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4')]), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call creates a TensorFlow model using a pre-trained MobileNet V2 model for image classification, which is loaded from TensorFlow Hub. Once the model is created, it can be used to classify images of various objects or scenes, including food items. The model has an accuracy of 71.0% on the ImageNet dataset. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\n# Create a model using the MobileNet V2 pre-trained model for image classification\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4', output_shape=[1001])\n])\n", "api_call": "tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4')])", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading pre-trained models", "api_name": "mobilenet_v2_100_224", "api_call": "tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4')])", "api_arguments": {"model_url": "https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4", "output_shape": "[1001]"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.6.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4', output_shape=[1001])\n])\n\n# Load an image and preprocess it\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(224, 224))\ninput_array = tf.keras.preprocessing.image.img_to_array(image)\ninput_array = tf.expand_dims(input_array, 0)\n\n# Make predictions\npredictions = model.predict(input_array)", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained MobileNetV2 model for image classification using TensorFlow Hub."}}
{"code": "###Instruction: Compute the similarity of the two given paragraphs using high-dimensional vectors.\n###Input: \"The quick brown fox jumped over the lazy dog. This sentence contains every letter of the alphabet.\", \"Pack my box with five dozen liquor jugs. This pangram contains each letter of the English language.\"\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The Universal Sentence Encoder (USE) is a pre-trained model that converts text into 512-dimensional vectors. To compute the similarity between the two given paragraphs, we need to encode them into high-dimensional vectors using USE, and then calculate the similarity as the cosine similarity between the resulting vectors. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Transforms text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world!'])\nprint(embeddings)", "performance": {"dataset": "STS Benchmark", "accuracy": "Pearson correlation coefficient of 0.78"}, "description": "The Universal Sentence Encoder (USE) is a pre-trained model that encodes text into 512-dimensional vectors. It can be used for various natural language processing tasks such as text classification, semantic similarity, and clustering."}}
{"code": "###Instruction: Tell me which car it is based on its picture.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: features = hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the MobileNetV2 model trained on ImageNet from TensorFlow Hub. It extracts a 1280-dimensional feature vector from the input image, which can be used for similarity comparison, classification, or other tasks. By training a classifier on a dataset of car images and their labels, it's possible to determine which car is in a given picture based on the extracted feature vector. <<<code>>>: import tensorflow_hub as hub\n\nimage_feature_vector_layer = hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4')\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Extract features from images", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "[batch_size, height, width, 3]", "output_shape": "[batch_size, 1280]"}, "python_environment_requirements": {"tensorflow": ">=2.0", "tensorflow_hub": ">=0.12"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=(224, 224, 3),\n                   trainable=False)\n])\n\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_batch = tf.expand_dims(image_array, 0)\n\nfeatures = model.predict(image_batch)", "performance": {"dataset": "ImageNet", "accuracy": "71.9%"}, "description": "Extracts a 1280-dimensional feature vector from images using the MobileNetV2 architecture trained on the ImageNet dataset."}}
{"code": "###Instruction: For a list of sentences, find the sentence closest in meaning to a given phrase.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder model from TensorFlow Hub, which encodes text into high-dimensional fixed-length vectors. These vectors can be used for numerous natural language processing tasks, such as measuring semantic similarity, clustering, and more. In this case, the model will be used to compute the embeddings for a list of sentences and compare them with the embedding of a given phrase to find the sentence closest in meaning. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text data", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow_hub as hub; embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'); embeddings = embed(['Hello world!'])", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.8"}, "description": "A text embedding model that converts sentences into fixed-length vectors, useful for various natural language processing tasks."}}
{"code": "###Instruction: Create a simple image classifier that can predict if an object is a cat or a dog.\n###Output: <<<domain>>>: image-feature-vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=[224, 224, 3]), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: To create a simple image classifier, first load the pre-trained MobileNet V2 model that has been trained on the ImageNet dataset. Then, create a KerasLayer using TensorFlow Hub, and provide an input shape of (224, 224, 3) for images. Finally, add a dense layer with two output units (one for cat and one for dog) and use a softmax activation function to predict if an object is a cat or a dog. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Define the model\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=[224, 224, 3], trainable=False),\n    tf.keras.layers.Dense(2, activation='softmax')\n])\n# Compile the model with appropriate loss function and optimizer\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction from images", "api_name": "mobilenet_v2_100_224", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "[None, 224, 224, 3]", "output_shape": "[None, 1280]"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow_hub as hub\nimport tensorflow as tf\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=(224,224,3),\n                   trainable=False),\n    tf.keras.layers.Dense(10, activation='softmax')\n])\n\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])", "performance": {"dataset": "ImageNet", "accuracy": "71.8%"}, "description": "A pre-trained MobileNetV2 model that takes an input image of shape (224, 224, 3) and outputs a 1280-dimensional feature vector. Useful for image classification, object detection, and other computer vision tasks."}}
{"code": "###Instruction: I am working on a project about recognizing landmarks and I need to extract image features for comparison purposes.\n###Output: <<<domain>>>: image-feature-vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/5'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the ResNet-50 model from TensorFlow Hub, which has been pre-trained on the ImageNet dataset. This model is used for feature extraction from images. Once loaded, you can create a KerasLayer with the model, allowing you to feed images into the model to extract their feature vectors for comparison purposes. ResNet-50 is a robust and accurate architecture that can provide good results in landmark recognition tasks. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Create a model with a single KerasLayer for feature extraction\nmodel = tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/5')])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/5')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction from images", "api_name": "imagenet_resnet_v2_50_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/5')", "api_arguments": ["url"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "", "performance": {"dataset": "ImageNet", "accuracy": ""}, "description": "This model is trained on the ImageNet dataset and can be used to extract feature vectors from images using the ResNet-50 architecture."}}
{"code": "###Instruction: We want to build a tool to recommend similar art pictures. Please extract features from the image provided.\n###Input: Example image of an art picture (with RGB values and size 224x224 pixels)\n###Output: <<<domain>>>: image-feature-vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224,224,3)), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call creates a KerasLayer using TensorFlow Hub's pre-trained MobileNet V2 model to extract feature vectors from images. The KerasLayer's input shape is set to (224, 224, 3) for the provided image, which represents a color image with dimensions 224x224 pixels. By passing the image through this model, we obtain a feature vector that can be used for applications like similarity search or transfer learning. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\n# Define the model with the pre-trained MobileNetV2 feature extraction layer\nmodel = tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224, 224, 3))])\n\n# Example image of an art picture (with RGB values and size 224x224 pixels)\nimage = tf.constant(<Input image tensor>)\n\n# Obtain the feature vector\nfeature_vector = model(image)\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "(224, 224, 3)", "output_shape": "(1280,)"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "model = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=(224,224,3))\n])", "performance": {"dataset": "ImageNet", "accuracy": "71.9%"}, "description": "A pre-trained image feature vector model using MobileNetV2 architecture on ImageNet dataset. It can be used for transfer learning to extract features from images."}}
{"code": "###Instruction: What do I need to do if I want to use your image classification model to label categories of animal faces?\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', trainable=True), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: To use the pre-trained image classification model for labeling categories of animal faces, first load the MobileNet V2 feature vector model from TensorFlow Hub using the provided API call. Then, fine-tune the model by setting the 'trainable' parameter to True. This allows you to update the model's weights during training with your own dataset of animal faces. After fine-tuning, add a Dense layer with the number of classes for your animal categories and the appropriate activation function (e.g., 'softmax') to output probabilities for each class. Lastly, compile and train your model on your labeled dataset of animal faces. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nnum_classes = <number_of_animal_categories>\n# Load the pre-trained model and fine-tune it\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', trainable=True),\n    tf.keras.layers.Dense(num_classes, activation='softmax')\n])", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction from images", "api_name": "imagenet-mobilenet_v2_100_224-feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"handle": "https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4", "trainable": "Optional: Set to True if you want to fine-tune the model"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "model = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   trainable=False),\n    tf.keras.layers.Dense(num_classes, activation='softmax')\n])", "performance": {"dataset": "ImageNet", "accuracy": "71.0% top-1 accuracy"}, "description": "A pre-trained image feature vector model based on MobileNetV2 architecture, trained on ImageNet dataset, for extracting features from images."}}
{"code": "###Instruction: I want to calculate the semantic similarity between job descriptions so I can quickly identify related jobs. Generate embeddings for these texts.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder model from TensorFlow Hub. The model is designed to convert text into high-dimensional vectors, or embeddings, which can then be used for various natural language processing tasks. In this case, you will use the generated embeddings to calculate the semantic similarity between job descriptions to identify related jobs. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Generate embeddings for text", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello, world!'])", "performance": {"dataset": "Various", "accuracy": "N/A"}, "description": "A pre-trained model for generating text embeddings using the Universal Sentence Encoder. It can be used for various NLP tasks like semantic similarity, text classification, and clustering."}}
{"code": "###Instruction: Recognize and classify objects in an image using a pre-trained model from TensorFlow Hub.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained image classification model, specifically MobileNetV2, from TensorFlow Hub. The model is designed for classifying objects in images. Once loaded, it can be used to perform inference on a given image, recognizing and classifying the objects present in the image using the pre-trained weights. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel_id = 'https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'\nmodel = hub.load(model_id)", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading and using pre-trained models", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nmodel_id = 'https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'\nmodel = hub.load(model_id)\n", "performance": {"dataset": "ImageNet", "accuracy": "Not specified"}, "description": "Loads a pre-trained image classification model from TensorFlow Hub and uses it for inference."}}
{"code": "###Instruction: I am interested in identifying the number of people in a given photograph. Show the best way to detect multiple objects in an image.\n###Output: <<<domain>>>: Image object detection, <<<api_call>>>: detector = hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained object detection model from TensorFlow Hub that detects multiple objects in an image using the SSD MobileNet V2 architecture. It works with TensorFlow and can be used to detect and count the number of people or other objects in a photograph. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\ndetector = hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')\n", "api_call": "hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image object detection", "framework": "TensorFlow Hub", "functionality": "Detect objects in an image", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nmodel_id = 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'\ndetector = hub.load(model_id)\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg')\ninput_image = tf.keras.preprocessing.image.img_to_array(image)\ninput_image = tf.expand_dims(input_image, 0)\ndetections = detector(input_image)", "performance": {"dataset": "COCO", "accuracy": "Not specified"}, "description": "A pre-trained object detection model that can detect multiple objects in an image using TensorFlow Hub."}}
{"code": "###Instruction: We have got a CCTV footage of a bird feeding station outside our house. Now we want to count different birds coming at different times during the day.\n###Output: <<<domain>>>: Image object detection, <<<api_call>>>: hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call will load a pre-trained TensorFlow Hub object detection model, specifically the Single Shot MultiBox Detector (SSD) with MobileNet V2. This model is designed to detect objects in images, including birds. With this model, you can analyze the CCTV footage from your bird feeding station, detecting and counting the different birds visiting at various times during the day. <<<code>>>: import tensorflow_hub as hub\ndetector = hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')\n", "api_call": "hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image object detection", "framework": "TensorFlow Hub", "functionality": "Detect objects in an image", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nmodel_id = 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'\ndetector = hub.load(model_id)\nimage = tf.image.decode_image(tf.io.read_file('path/to/image.jpg'))\nresult = detector(image[tf.newaxis, ...])", "performance": {"dataset": "COCO", "accuracy": "Not specified"}, "description": "A pre-trained TensorFlow Hub model for detecting objects in an image using the Single Shot MultiBox Detector (SSD) with MobileNet V2."}}
{"code": "###Instruction: My daughter wants to identify butterflies in her butterfly book. I want to use my phone camera to identify them.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: model = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained MobileNetV2 model for image classification from TensorFlow Hub. Once loaded, the model can be used to classify images. In this case, it can be used to identify butterflies in images taken from the butterfly book. Make sure to resize images to 224x224 pixels, which is the expected input size for this model. <<<code>>>: import tensorflow_hub as hub\nimport tensorflow as tf\n\n# Load MobileNetV2 model\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\n\n# Possible example code to prepare image from the phone camera\nimage = tf.keras.preprocessing.image.load_img('path/to/your/image.jpg', target_size=(224, 224))\nimage = tf.keras.preprocessing.image.img_to_array(image)\nimage = tf.expand_dims(image, axis=0)\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Image classification using pre-trained models", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": {"model_url": "https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4"}, "python_environment_requirements": {"tensorflow": ">= 2.0.0", "tensorflow_hub": ">= 0.6.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\nimage = tf.keras.preprocessing.image.load_img('path/to/your/image.jpg', target_size=(224, 224))\nimage = tf.keras.preprocessing.image.img_to_array(image)\nimage = tf.expand_dims(image, axis=0)\nresults = model(image)\npredicted_class = tf.math.argmax(results[0], axis=-1).numpy()", "performance": {"dataset": "ImageNet", "accuracy": "71.8%"}, "description": "A pre-trained image classification model using MobileNetV2 architecture, trained on ImageNet dataset, and available on TensorFlow Hub for easy integration."}}
{"code": "###Instruction: I need to analyze customer reviews for various products. Can you provide me with a representation of each review in a high-dimensional vector?\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the Universal Sentence Encoder model from TensorFlow Hub. The model is designed to encode text, such as customer reviews, into high-dimensional vectors. These vectors can then be used for text classification, semantic similarity, clustering, or other natural language processing tasks. In this case, the high-dimensional vectors representing the customer reviews can be used for analyzing and processing customer feedback.<<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embed text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": {"input": "A list of strings to be embedded"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.8.0"}, "example_code": "embeddings = embed(['hello world', 'my name is John'])", "performance": {"dataset": "SNLI", "accuracy": "86.9%"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, and other natural language tasks."}}
{"code": "###Instruction: Suggest a way to compare two images based on their features vectors extracted from a pre-trained model.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: feature_extractor = hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call adds a Keras layer from TensorFlow Hub that uses MobileNetV2 with the 224x224 input size for image feature extraction. Once you have this feature extractor, you can pass two images through it to obtain their feature vectors. You can then compare these feature vectors using similarity measures, such as cosine similarity or Euclidean distance, to gauge how similar or different the two images are. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\n# Use the MobileNetV2 feature extractor as a KerasLayer\nfeature_extractor = hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224, 224, 3), trainable=False)\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction from images", "api_name": "imagenet-mobilenet_v2_100_224-feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"url": "https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                  input_shape=(224, 224, 3),\n                  trainable=False),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])", "performance": {"dataset": "ImageNet", "accuracy": "71.9%"}, "description": "A pre-trained model that can be used to extract feature vectors from images using MobileNetV2 architecture with 224x224 input size."}}
{"code": "###Instruction: My clients are dog breeders and they requested a tool that can identify different breeds of dogs automatically.\n###Output: <<<domain>>>: Image-classification, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained MobileNet V2 model for image classification from TensorFlow Hub, trained on the ImageNet dataset. The KerasLayer is created with the URL of the pre-trained model, and you can pass images with a 224x224 pixel size to it. The model will automatically classify the images according to various categories, which include different dog breeds, yielding useful information for your clients. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5')])\ndecoded_image = tf.image.decode_jpeg(tf.io.read_file('image.jpg'))\nresized_image = tf.image.resize(decoded_image, (224, 224))\ninput_image = tf.expand_dims(resized_image, 0)\npredictions = model(input_image)", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Pre-trained model for image classification", "api_name": "imagenet-mobilenet_v2_130_224-classification", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5')", "api_arguments": "URL of the pre-trained model", "python_environment_requirements": "tensorflow, tensorflow_hub", "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5')\n])\n\ndecoded_image = tf.image.decode_jpeg(tf.io.read_file('image.jpg'))\nresized_image = tf.image.resize(decoded_image, (224, 224))\ninput_image = tf.expand_dims(resized_image, 0)\n\npredictions = model(input_image)", "performance": {"dataset": "ImageNet", "accuracy": "94.5%"}, "description": "A pre-trained model for image classification using MobileNetV2 architecture with 130 depth multiplier and 224x224 input size, trained on ImageNet dataset."}}
{"code": "###Instruction: Estimate the similarity between two given sentences by embedding them using Universal Sentence Encoder.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the Universal Sentence Encoder model from TensorFlow Hub. It's designed to encode text into high-dimensional vectors that can be used for various natural language tasks, such as semantic similarity. Once the model is loaded, it can be used to embed the two given sentences, and their similarity can be estimated by comparing their embeddings. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": "input: List of strings", "python_environment_requirements": "tensorflow, tensorflow_hub", "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world!', 'Embedding is fun!'])", "performance": {"dataset": "STS Benchmark", "accuracy": "0.803"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering and other natural language tasks."}}
{"code": "###Instruction: Suppose we have two movie reviews. We would like to know how semantically similar these two movie reviews are.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call lets you load the Universal Sentence Encoder model from TensorFlow Hub. The model embeds the input text into high-dimensional vectors that can be used for several natural language processing tasks. In this case, it can be used to calculate semantic similarity between two movie reviews by comparing their respective embeddings. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": {"input": "Text input"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.8.0"}, "example_code": "import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world'])", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.803"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: How can I compare the similarity between two sentences? I need a numerical representation.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The Universal Sentence Encoder model can be used to compare the similarity between two sentences by generating high-dimensional embeddings for them. By loading this pre-trained model from TensorFlow Hub, you can transform the sentences into numerical representations (vectors). You can then compare these vectors using cosine similarity or other similarity metrics to get a quantifiable representation of their similarity. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world', 'Another sentence'])\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embed text using a pre-trained model", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["text_input"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world'])", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.803"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: We need to find the semantic similarity between different product reviews.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder (USE) from TensorFlow Hub. The USE encodes text into high-dimensional vectors which can be used for various natural language tasks such as semantic similarity, text classification, clustering and more. By encoding product reviews into high-dimensional vectors with the USE, you can measure semantic similarity between them. <<<code>>>: import tensorflow_hub as hub\n# Load the Universal Sentence Encoder\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n# Use the model to embed text (assuming 'product_reviews' is a list of sentences)\nembeddings = embed(product_reviews)\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world'])", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.803"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering and other natural language tasks. The model is trained and optimized for greater-than-word length text, such as sentences, phrases or short paragraphs."}}
{"code": "###Instruction: Find the similarities between my favorite quotes from different books so I can group them together.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The Universal Sentence Encoder can be used to convert quotes from different books into high-dimensional vectors. You can load the pre-trained model using TensorFlow Hub, and then use the model to generate embeddings for each quote. By comparing these embeddings, you can determine the similarity between the quotes and group them accordingly. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Load the Universal Sentence Encoder model\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n# Generate embeddings for your favorite quotes\nembeddings = embed(['quote_1', 'quote_2', 'quote_3', ...])\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embed text data", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world'])", "performance": {"dataset": "STSbenchmark", "accuracy": "Pearson correlation coefficient of 0.803"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: I want to provide a semantic search on my website, and I need to compare the similarity between the user query and my database of questions to find the top relevant matches.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The Universal Sentence Encoder model from TensorFlow hub encodes text into high-dimensional vectors. By loading and using this model, you can convert user queries and your database of questions into embeddings. Comparing the similarity between these embeddings will enable you to find the top relevant matches for semantic search on your website. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nuser_query_embedding = embed([\"User query\"])\ndatabase_question_embeddings = embed([\"Question 1\", \"Question 2\", \"Question 3\"])\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world'])", "performance": {"dataset": "STS benchmark", "accuracy": "0.84"}, "description": "A model for embedding text into high-dimensional vectors that can be used for various natural language processing tasks"}}
{"code": "###Instruction: We need to find similarity between different reviews. First, could you create a vector representation for each review?\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder model from TensorFlow Hub. The model encodes text into high-dimensional vectors that can be used for various natural language tasks such as text classification, semantic similarity, clustering, etc. In this case, it will be used to create vector representations of different reviews, which can then be utilized for finding similarities between them. <<<code>>>: import tensorflow_hub as hub\n\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow_hub as hub; embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'); embeddings = embed(['Hello world!'])", "performance": {"dataset": "STS benchmark", "accuracy": "0.84"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: Create a customer support ticket classifier to automatically determine the issue category based on the ticket description.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the Universal Sentence Encoder model from TensorFlow Hub. This model is capable of encoding text into high-dimensional vectors, in this case, the text being customer support ticket descriptions. Once the ticket descriptions are converted into embeddings, these high-dimensional vectors can be used to train a classifier that categorizes customer support tickets based on their content. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": {"input": "List of strings"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world!', 'This is a test sentence'])", "performance": {"dataset": "Various", "accuracy": "Not specified"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks. It is trained on a variety of data sources and a range of tasks."}}
{"code": "###Instruction: I have taken images of different items I want to sell on eBay, and I need to extract feature vectors from the images to use in a recommendation system.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: model = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the MobileNetV2 model from TensorFlow Hub. The model is trained on ImageNet and can be used to extract feature vectors from images. These feature vectors can be used to perform tasks such as image classification, object detection, and more. In this case, the feature vectors will be used to build a recommendation system for items you want to sell on eBay.<<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature vector extraction", "api_name": "imagenet-mobilenet_v2_100_224-feature_vector", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"image_size": "224x224", "input_type": "float32", "output_type": "float32", "batch_size": "variable"}, "python_environment_requirements": {"tensorflow": "2.0", "tensorflow_hub": "0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')\n\n# Load and preprocess an image\nimage = tf.keras.preprocessing.image.load_img('path/to/your/image.jpg', target_size=(224, 224))\ninput_image = tf.keras.preprocessing.image.img_to_array(image)\ninput_image = tf.expand_dims(input_image, 0)\n\n# Extract features\nfeatures = model(input_image)", "performance": {"dataset": "ImageNet", "accuracy": "71.0"}, "description": "This API allows you to extract feature vectors from images using the MobileNetV2 model trained on ImageNet. The feature vectors can be used for various machine learning tasks such as image classification, object detection, and more."}}
{"code": "###Instruction: Extract a feature vector from an image to perform image classification.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call imports a pre-trained image feature vector model from TensorFlow Hub, based on the MobileNetV2 architecture. The model is designed for image classification tasks and takes input images of shape [224, 224, 3]. It outputs a 1280-dimensional feature vector, which can be used for classification or transfer learning. By using this KerasLayer, you can integrate the pre-trained model into your own TensorFlow model. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = tf.keras.Sequential([\n    hub.KerasLayer(\"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4\", input_shape=[224, 224, 3])\n])", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "[224, 224, 3]", "output_shape": "[1280]"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer(\"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4\", input_shape=[224,224,3])\n])\n\nfeatures = model.predict(images)", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained image feature vector model based on MobileNetV2 architecture, designed for image classification tasks. The model takes input images of shape [224, 224, 3] and outputs a 1280-dimensional feature vector."}}
{"code": "###Instruction: I have a list of product reviews and I need a program to find the reviews which are most similar to each other.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the Universal Sentence Encoder model from TensorFlow Hub. This model converts text into high-dimensional vectors, which can be used for tasks like finding similar text. In this case, you can use the model to convert the product reviews into embeddings and calculate the semantic similarity between them to find the most similar reviews. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": "input_text", "python_environment_requirements": "tensorflow, tensorflow_hub", "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world!'])\nprint(embeddings)", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.803"}, "description": "A text embedding model that converts text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: After finishing a hike, I want to know which environment I have been to during the hike. My friends provided some pictures of the scenery during the hike.\n###Output: <<<domain>>>: image-classification, <<<api_call>>>: model = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads a pre-trained MobileNet V2 model from TensorFlow Hub. The model is trained for image classification tasks and can be used to recognize scenes from various environments. Once the model is loaded, it can be used to classify images, and in this case, it can help identify the type of environment or scenery seen during the hike based on the provided pictures. <<<code>>>: import tensorflow_hub as hub\n# Load the MobileNet V2 model\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'\nmodel = hub.load(model_id)\n", "performance": {"dataset": "ImageNet", "accuracy": "Not provided"}, "description": "Load a pre-trained image classification model from TensorFlow Hub using the model id."}}
{"code": "###Instruction: I want to construct an automatic tagging system that assigns meaningful tags to content pieces based on the text.\n###Output: <<<domain>>>: text-embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder (USE) from TensorFlow Hub, a pre-trained model that encodes text into high-dimensional vectors. It is designed for encoding sentences, phrases, or short paragraphs, and can be used for tasks such as text classification, semantic similarity, and clustering. With USE, you can create vector representations of your content pieces' text, which can then be used for automatic tagging. <<<code>>>: import tensorflow_hub as hub\n# Load Universal Sentence Encoder\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n# Encode text for a content piece (replace with your actual text)\nembeddings = embed(['Hello world!'])\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text data", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": {"url": "https://tfhub.dev/google/universal-sentence-encoder/4"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow_hub as hub\n\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world!'])\nprint(embeddings)", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.78"}, "description": "The Universal Sentence Encoder (USE) is a pre-trained model that encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering and other natural language tasks. It is designed for greater-than-word length text like sentences, phrases or short paragraphs."}}
{"code": "###Instruction: I want to develop an app to identify specific breeds of dogs from the user's photos of their pets. What kind of model should I use for this task?\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: model = hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: For this task, you can use a pre-trained model based on Inception V3 architecture from TensorFlow Hub. This model is designed for image classification and has been trained on the ImageNet dataset, which contains images of various dog breeds. You can load the model using the provided API call, and then use it to identify the breed of dog in the user's photos. <<<code>>>: import tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Pre-trained model", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v3/classification/5'\nmodel = hub.load(model_id)\n\n# Load an image as an example\nimage = tf.keras.preprocessing.image.load_img('path/to/your/image.jpg', target_size=(299, 299))\nimage = tf.keras.preprocessing.image.img_to_array(image)\nimage = tf.expand_dims(image, 0)\n\n# Make predictions\npredictions = model(image)\n", "performance": {"dataset": "ImageNet", "accuracy": "Not specified"}, "description": "A pre-trained image classification model using Inception V3 architecture from TensorFlow Hub."}}
{"code": "###Instruction: I have an app that needs to recognize objects in images. We need an image classification model to do that.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained image classification model from TensorFlow Hub. Specifically, the Inception V3 model trained on the ImageNet dataset. The model allows you to recognize objects in images, and can be utilized for various image recognition tasks in your app. <<<code>>>: import tensorflow_hub as hub\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v3/classification/5'\nmodel = hub.load(model_id)\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "api_arguments": {"model_id": "string"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v3/classification/5'\nmodel = hub.load(model_id)\n", "performance": {"dataset": "ImageNet", "accuracy": "Not specified"}, "description": "Load a pre-trained image classification model from TensorFlow Hub using a model_id."}}
{"code": "###Instruction: I am working on a movie recommendation system and need a sentence embedding for each movie description.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder model from TensorFlow Hub which is designed to convert text into high-dimensional vectors. These vectors may then be utilized for a multitude of natural language processing tasks, including text classification and semantic similarity. In this instance, the model is used to generate a sentence embedding for each movie description, facilitating the development of a movie recommendation system. <<<code>>>: import tensorflow_hub as hub\nembedding_model = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Loading", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello, world!'])", "performance": {"dataset": "Various", "accuracy": "Not specified"}, "description": "A text embedding model that converts text into high-dimensional vectors that can be used for text classification, semantic similarity, and other natural language processing tasks."}}
{"code": "###Instruction: Identify the primary object in this image and classify it.\n###Input: Load an image from a given path, `path/to/image.jpg`, with a target size of (224, 224).\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads a pre-trained MobileNet V2 model from TensorFlow Hub that focuses on image classification. By loading the model with the provided `model_id`, you can classify the primary object in an image. In this case, imread the image from the given path ('path/to/image.jpg') and resize it to (224, 224) before feeding it into the model to predict the object's class.<<<code>>>:import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'\nloaded_model = hub.load(model_id)\n\n# Load an image\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_batch = tf.expand_dims(image_array, 0)\n\n# Run the model\npredictions = loaded_model(image_batch)\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading pre-trained models for image classification", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'\nloaded_model = hub.load(model_id)\n\n# Load an image\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_batch = tf.expand_dims(image_array, 0)\n\n# Run the model\npredictions = loaded_model(image_batch)\n", "performance": {"dataset": "ImageNet", "accuracy": "71.9%"}, "description": "This API allows users to load pre-trained models for image classification from TensorFlow Hub. The loaded models can be used to classify images into one of the pre-defined categories."}}
{"code": "###Instruction: Analyze an image for any instances of litter to help clean up public spaces.\n###Output: <<<domain>>>: Image object detection, <<<api_call>>>: detector = hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained SSD MobileNet V2 model for object detection in images from TensorFlow Hub. The model is trained on the COCO dataset, which includes various objects found in real-world scenarios, such as litter. By detecting the presence of litter in images, this API can help identify areas that need clean-up operations in public spaces. <<<code>>>: import tensorflow_hub as hub\ndetector = hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')", "api_call": "hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image object detection", "framework": "TensorFlow Hub", "functionality": "Detect objects in images", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nmodel_id = 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'\ndetector = hub.load(model_id)\nimage = tf.image.decode_jpeg(tf.io.read_file('path/to/image.jpg'))\nresult = detector(image[tf.newaxis, ...])", "performance": {"dataset": "COCO", "accuracy": "mAP"}, "description": "This API allows you to detect objects in images using a pre-trained model from TensorFlow Hub. The model is based on the SSD MobileNet V2 architecture and has been trained on the COCO dataset."}}
{"code": "###Instruction: Among a list of sentences, find the most semantically similar pairs by converting them into dense vector representations.\n###Output: <<<domain>>>: text-embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the Universal Sentence Encoder model from TensorFlow Hub. This model encodes text into dense vectors that can be used for various natural language processing tasks such as semantic similarity, clustering, and classification. Once loaded, you can pass the list of sentences to the model to obtain their dense vector representations, which can be compared to find the most semantically similar pairs. <<<code>>>: import tensorflow_hub as hub\n# Load the Universal Sentence Encoder\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Convert text into a dense vector representation", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": {"input": "Text or list of texts"}, "python_environment_requirements": {"tensorflow": ">= 2.0", "tensorflow_hub": ">= 0.8"}, "example_code": "import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world!'])", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.78"}, "description": "The Universal Sentence Encoder encodes text into a dense vector representation that can be used for various natural language processing tasks."}}
{"code": "###Instruction: I have some images of my last trip, and I want to identify the objects in the pictures.\n###Output: <<<domain>>>: Image object detection, <<<api_call>>>: detector = hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads an object detection model from TensorFlow Hub. The model is SSD MobileNet V2, which is a pre-trained model designed to detect and classify objects in images. Once the model is loaded, it can be used to identify objects in the images from your last trip, and provide you with information about what is present in the images. <<<code>>>: import tensorflow_hub as hub\ndetector = hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')\n", "api_call": "hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image object detection", "framework": "TensorFlow Hub", "functionality": "Object detection and classification in images", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nmodel_id = 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'\ndetector = hub.load(model_id)\nresult = detector(image_tensor)", "performance": {"dataset": "COCO", "accuracy": "Not specified"}, "description": "This API allows you to detect and classify objects in images using TensorFlow Hub and pre-trained models such as SSD MobileNet V2."}}
{"code": "###Instruction: When I go shopping, I stumble upon an item I can't identify. I want to take a picture and let my phone classify it for me.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: model = hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call adds a pre-trained TensorFlow Keras layer from TensorFlow Hub for image classification using the MobileNetV2 architecture. The model is trained on the ImageNet dataset and can be used to classify images into various object classes. When you encounter an item that you can't identify while shopping, you can take a picture and pass it through this pre-trained model to classify it. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'\nmodel = tf.keras.Sequential([\n    hub.KerasLayer(model_id, trainable=True)\n])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Pre-trained models for image classification", "api_name": "model_id", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": [{"name": "model_id", "type": "string", "description": "The ID of the pre-trained model"}, {"name": "trainable", "type": "boolean", "description": "Whether the model should be trainable or not"}], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'\nmodel = tf.keras.Sequential([\n    hub.KerasLayer(model_id, trainable=True)\n])\n\n# Load example image and preprocess it\nimage = tf.keras.preprocessing.image.load_img('example_image.jpg', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, 0)\n\n# Make predictions\npredictions = model.predict(image_array)\n", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained image classification model using MobileNetV2 architecture on ImageNet dataset, available through TensorFlow Hub."}}
{"code": "###Instruction: We have an app that allows users to sort their photos by features. Extract features from images for this app.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call integrates the pre-trained MobileNetV2 model as a KerasLayer, which has been trained on the ImageNet dataset for feature extraction from images. By loading this model into your app and passing images through it, you can obtain a feature vector for each image. Then, these feature vectors can be used to sort photos based on their visual features. <<<code>>>: import tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=(224, 224, 3))\n])\n\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, 0)\n\nfeatures = model.predict(image_array)\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction from images", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "(224, 224, 3)", "output_shape": "(1280,)"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=(224, 224, 3),\n                   output_shape=(1280,))\n])\n\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, 0)\n\nfeatures = model.predict(image_array)", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained model for extracting feature vectors from images using MobileNetV2 architecture trained on ImageNet dataset"}}
{"code": "###Instruction: My kids found some rare insects, and I need some help identifying them. They took some photos with a smartphone. Can you help classify them?\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: model = hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained Inception V3 model for image classification from TensorFlow Hub. The model is trained on the ImageNet dataset and can identify a variety of objects, including insects. You can use this model to classify the insect images taken by your kids. <<<code>>>: import tensorflow_hub as hub\nimport tensorflow as tf\n\nmodel = hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')\n\n# Load the insect image, resize it to the expected input size, convert it to an array, and expand its dimensions\nimage = tf.keras.preprocessing.image.load_img('path/to/your/image.jpg', target_size=(299, 299))\nimage = tf.keras.preprocessing.image.img_to_array(image)\nimage = tf.expand_dims(image, axis=0)\n\n# Make predictions using the pre-trained model\npredictions = model(image)\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Image classification", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v3/classification/5'\nmodel = hub.load(model_id)\n\nimage = tf.keras.preprocessing.image.load_img('path/to/your/image.jpg', target_size=(299, 299))\nimage = tf.keras.preprocessing.image.img_to_array(image)\nimage = tf.expand_dims(image, axis=0)\n\npredictions = model(image)\n", "performance": {"dataset": "ImageNet", "accuracy": "77.9%"}, "description": "A pre-trained image classification model using Inception V3 architecture on TensorFlow Hub."}}
{"code": "###Instruction: We need a way to detect phishing email domains. I want to find similarities in domain addresses to do so. Please provide embeddings of email domains.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API loads the Universal Sentence Encoder model that encodes given text into high-dimensional vectors, offering features such as semantic similarity and clustering. This can be utilized to detect phishing email domains by comparing the embeddings of email domains to find potential similarities. Loading this model, one can provide embeddings of email domains and use it as a basis for phishing detection. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Universal Sentence Encoder", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": {"input": "A list of sentences or phrases"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.8.0"}, "example_code": "import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello, world!', 'How are you?'])", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.80"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: I have a review about a new sci-fi book, and I want to generate high-dimensional vectors that are useful for classification tasks.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder model from TensorFlow Hub, which is designed to encode text into high-dimensional vectors. These vectors can be used for text classification, semantic similarity, clustering, and other natural language tasks. In this case, the text being the review of a new sci-fi book. Once the review is transformed into this high-dimensional vector, or embedding, it can be used to classify the review or perform other related tasks. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Load text embedding models", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": "model_url", "python_environment_requirements": "tensorflow, tensorflow_hub", "example_code": "import tensorflow_hub as hub; embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'); embeddings = embed(['Hello, world!'])", "performance": {"dataset": "Various", "accuracy": "N/A"}, "description": "Load a pre-trained text embedding model from TensorFlow Hub to convert text into fixed-length vector representations."}}
{"code": "###Instruction: I have a picture of a beach party, and I want to know how many people are there in the image.\n###Output: <<<domain>>>: Image object detection, <<<api_call>>>: detector = hub.load('https://tfhub.dev/tensorflow/efficientdet/d0/1'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained EfficientDet model from TensorFlow Hub for object detection in images. When provided with an input image, the model can be used to detect and identify various objects, including people. By counting the number of detected persons in the beach party image, it is possible to determine the number of people present. <<<code>>>: import tensorflow_hub as hub\ndetector = hub.load('https://tfhub.dev/tensorflow/efficientdet/d0/1')\n", "api_call": "hub.load('https://tfhub.dev/tensorflow/efficientdet/d0/1')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image object detection", "framework": "TensorFlow Hub", "functionality": "Detect objects in images", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/tensorflow/efficientdet/d0/1')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow_hub as hub\nmodel_id = 'https://tfhub.dev/tensorflow/efficientdet/d0/1'\ndetector = hub.load(model_id)", "performance": {"dataset": "COCO", "accuracy": "N/A"}, "description": "Load a pre-trained model from TensorFlow Hub for object detection in images."}}
{"code": "###Instruction: For document similarity, I want to convert the following sentence into its vector representation: \"Artificial Intelligence is transforming the world in ways we couldn't have imagined a decade ago.\"\n###Input: Artificial Intelligence is transforming the world in ways we couldn't have imagined a decade ago.\n###Output: <<<domain>>>: Text preprocessing, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder model from TensorFlow Hub, which is a powerful model for generating embeddings for sentences or phrases. Once loaded, you can use it to transform any sentence or phrase, such as the provided input, into a dense vector representation. This can be used to compute similarity between documents or sentences. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Artificial Intelligence is transforming the world in ways we could not have imagined a decade ago.'])", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text preprocessing", "framework": "TensorFlow Hub", "functionality": "Loading", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["url: https://tfhub.dev/google/universal-sentence-encoder/4"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world'])", "performance": {"dataset": "Various", "accuracy": "Not specified"}, "description": "A text preprocessing API that loads the Universal Sentence Encoder model from TensorFlow Hub for generating sentence embeddings."}}
{"code": "###Instruction: Our team needs to keep track of various laptops and their usage in the workplace. Detect the laptops in the given images and provide their locations.\n###Output: <<<domain>>>: Image object detection, <<<api_call>>>: hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the pre-trained Single Shot MultiBox Detector (SSD) with MobileNet V2 model from TensorFlow Hub. The model can be used for object detection in images, such as detecting the locations of laptops in workplace images. Once the detector is loaded, you can pass an image to the detector to get the detected objects, their bounding boxes, and class labels.<<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\n# Load the SSD MobileNet V2 model\nmodel_id = 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'\ndetector = hub.load(model_id)\n\n# Load the image and preprocess it\nimage = tf.keras.preprocessing.image.load_img('image.jpg')\nimage = tf.keras.preprocessing.image.img_to_array(image)\nimage = tf.expand_dims(image, axis=0)\n\n# Detect objects in the image\npredictions = detector(image)\n", "api_call": "hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image object detection", "framework": "TensorFlow Hub", "functionality": "Object detection in images", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'\ndetector = hub.load(model_id)\n\nimage = tf.keras.preprocessing.image.load_img('image.jpg')\nimage = tf.keras.preprocessing.image.img_to_array(image)\nimage = tf.expand_dims(image, axis=0)\n\npredictions = detector(image)\n", "performance": {"dataset": "COCO", "accuracy": "Not specified"}, "description": "A pre-trained object detection model from TensorFlow Hub that can detect objects in images using the Single Shot MultiBox Detector (SSD) with MobileNet V2."}}
{"code": "###Instruction: Classify a short clip of people playing football to understand the actions and behaviors of the players.\n###Output: <<<domain>>>: Video classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/Video_classification_model_id/1'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained video classification model from TensorFlow Hub that is capable of classifying videos based on their content. It has been trained on a large-scale video dataset, such as Kinetics-400, allowing it to effectively recognize various actions and behaviors within a provided video clip. Once loaded, you can use this model to classify the content of your video and identify the actions performed by the players.<<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Load the pre-trained video classification model\nvideo_classifier = hub.load('https://tfhub.dev/google/Video_classification_model_id/1')\n", "api_call": "hub.load('https://tfhub.dev/google/Video_classification_model_id/1')", "provider": "TensorFlow Hub", "api_data": {"domain": "Video classification", "framework": "TensorFlow Hub", "functionality": "Video classification model", "api_name": "Video_classification_model_id", "api_call": "hub.load('https://tfhub.dev/google/Video_classification_model_id/1')", "api_arguments": [], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "", "performance": {"dataset": "Kinetics-400", "accuracy": ""}, "description": "A pre-trained video classification model available on TensorFlow Hub for classifying videos based on their content."}}
{"code": "###Instruction: We have several articles to analyze. We need to find a way to compare their similarity.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: To compare the similarity of different articles, you can use the Universal Sentence Encoder, which encodes text into high-dimensional vectors. By loading the model from TensorFlow Hub and obtaining the embeddings for each article's text, you can compute their similarity by calculating the cosine similarity or other distance metrics between the embeddings. This will help you to evaluate how closely related the articles are regarding their content.<<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world!'])", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.803"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: I have a collection of customer reviews about various products, and I want to find out which reviews are the most similar.\n###Output: <<<domain>>>: text-embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: By using the Universal Sentence Encoder from TensorFlow Hub, you can transform customer reviews into high-dimensional vectors. These vectors are suitable for comparing semantic similarity between reviews, making it easier to identify which ones are most similar. Once your reviews are converted into embeddings, you can use distance metrics like cosine similarity to determine the degree of similarity between pairs of embeddings. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embed text using pre-trained models", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world!'])\nprint(embeddings)", "performance": {"dataset": "various text classification tasks", "accuracy": "state-of-the-art"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for a wide range of tasks such as semantic similarity, clustering, and text classification. The model is trained and optimized for greater-than-word length text, such as sentences, phrases or short paragraphs."}}
{"code": "###Instruction: I have some animal photos, I want to train a tool will tell me what animal it is.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5'), <<<api_provider>>>: TensorFlow, <<<explanation>>>: The API call loads the MobileNetV2 model from TensorFlow Hub, which is a pre-trained model for image classification tasks. This model has been pre-trained on the ImageNet dataset, meaning it has been trained on a large dataset of images, including animal images. You can use this API call to obtain a pre-trained model that will be useful to classify your animal photos.<<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5')\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Pre-trained models for image classification", "api_name": "imagenet_mobilenet_v2_130_224_classification", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5')", "api_arguments": {"url": "https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5')\nimage = tf.keras.preprocessing.image.load_img('path/to/your/image.jpg', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, 0)\n\npredictions = model(image_array)\n", "performance": {"dataset": "ImageNet", "accuracy": "94.1%"}, "description": "MobileNetV2 is a family of neural network architectures for efficient on-device image classification and related tasks, originally published by Mark Sandler, et al. This model is pre-trained on the ImageNet dataset and can be used for various image classification tasks."}}
{"code": "###Instruction: Show me an example where I can cluster similar movie plots.\n###Output: <<<domain>>>: text-embedding, <<<api_call>>>: embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: Use the Universal Sentence Encoder API to load a pre-trained model encodes text into high-dimensional vectors. In doing so, you can extract similar features from movie plots thereby allowing you to cluster them according to similarity. The model will work best for texts that are longer than single words, such as sentences or short paragraphs. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into a high-dimensional vector", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world!'])", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.78"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: Assist me in identifying food entities in grocery store images.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4')]), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads a pre-trained image classification model called MobileNet V2 from TensorFlow Hub. This model can be used to classify images into one of 1001 different categories. For the task of identifying food entities in grocery store images, you can use this model to classify images into their corresponding categories. The following code shows how to load the model, preprocess an image, and predict the category. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4', output_shape=[1001])])\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, 0)\npredictions = model.predict(image_array)\n", "api_call": "tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4')])", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading pre-trained models", "api_name": "mobilenet_v2_100_224", "api_call": "tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4')])", "api_arguments": {"url": "https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4", "output_shape": "[1001]"}, "python_environment_requirements": {"tensorflow": ">=2.0", "tensorflow_hub": ">=0.12"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4', output_shape=[1001])\n])\n\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, 0)\n\npredictions = model.predict(image_array)\n", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained image classification model using MobileNet V2 architecture with 1001 output classes available on TensorFlow Hub."}}
{"code": "###Instruction: Based on the text that my customers give me in different languages, create a vector so I can do customer sentiment analysis.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder model from TensorFlow Hub. It is designed for encoding text into high-dimensional vectors, which can be used for various natural language processing tasks like sentiment analysis. The model is capable of handling input text in different languages, and returns a vector representation of the input that can be used to analyze customer sentiment. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world!'])\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world!'])", "performance": {"dataset": "STS", "accuracy": "0.78"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for various natural language processing tasks."}}
{"code": "###Instruction: I am building a mobile app that can identify different breeds of dogs, and I need fast feature extraction from images to recognize the breeds.\n###Output: <<<domain>>>: image-feature-vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224,224,3), trainable=False), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads a pre-trained model from TensorFlow Hub that takes a 224x224 RGB image as input and outputs a 1280-dimensional feature vector. Using the MobileNet V2 architecture, it's optimized for fast feature extraction. This makes it especially suitable for a mobile app where speed is crucial. Creating a KerasLayer with this model allows it to be fine-tuned for a new classification task (in this case, dog breed recognition). <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Load the MobileNet V2 feature vector model as a KerasLayer\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224,224,3), trainable=False)\n])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Extract image features", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"image_input": "A 4D tensor with shape [batch_size, height, width, 3]", "output": "A 2D tensor with shape [batch_size, num_features]"}, "python_environment_requirements": {"tensorflow": ">= 2.0", "tensorflow_hub": ">= 0.8"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=(224,224,3),\n                   trainable=False)\n])\n\n# Load an example image and preprocess it\nimage = tf.keras.preprocessing.image.load_img('example_image.jpg', target_size=(224, 224))\ninput_array = tf.keras.preprocessing.image.img_to_array(image)\ninput_array = tf.expand_dims(input_array, 0)\n\n# Extract the features\nfeatures = model.predict(input_array)", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained model that takes a 224x224 RGB image as input and outputs a 1280-dimensional feature vector. Useful for transfer learning and fine-tuning on new image classification tasks."}}
{"code": "###Instruction: Compare the similarity between two sentences and provide a numerical score.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the Universal Sentence Encoder model from TensorFlow Hub. This model is designed for encoding text into high-dimensional vectors. Once the text is converted to these vectors or embeddings, you can use them to calculate the similarity between the two sentences by measuring the cosine similarity or another similarity metric of the embeddings. This numerical score will indicate the level of similarity between the sentences. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Converts text to embeddings", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow_hub as hub; embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'); embeddings = embed(['Hello world']); print(embeddings)", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.803"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: I want to analyze customer reviews for sentiment analysis. Provide a method to transform the reviews into fixed-size vectors.\n###Output: <<<domain>>>: Text preprocessing, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the Universal Sentence Encoder model from TensorFlow Hub. This pre-trained text embedding model is capable of transforming sentences or text inputs, in this case, customer reviews, into fixed-size vectors. These vectors can then be used for various natural language processing tasks, such as sentiment analysis, enabling you to analyze and understand customer sentiment. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text preprocessing", "framework": "TensorFlow Hub", "functionality": "Loading", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": {"url": "https://tfhub.dev/google/universal-sentence-encoder/4"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.8.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world!'])\nprint(embeddings)", "performance": {"dataset": "Various", "accuracy": "Not specified"}, "description": "A pre-trained text embedding model that converts sentences into fixed-size vectors, suitable for various natural language processing tasks."}}
{"code": "###Instruction: I need to analyze a group of images and find out which ones are similar. First, I require extracting features of each image for comparison.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: model = tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_140_224/feature_vector/4', input_shape=[224, 224, 3], output_shape=[140])]), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call uses the pre-trained image feature vector model from TensorFlow Hub that employs the MobileNetV2 architecture on the ImageNet dataset. It is designed to extract features from images, which can be further used for various machine learning tasks such as finding similarities between images in your case. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_140_224/feature_vector/4', input_shape=[224, 224, 3], output_shape=[140])\n])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_140_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Extracts feature vector from images", "api_name": "imagenet-mobilenet_v2_140_224-feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_140_224/feature_vector/4')", "api_arguments": {"input_shape": "[224, 224, 3]", "output_shape": "[140]"}, "python_environment_requirements": {"tensorflow": ">=2.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow_hub as hub\nimport tensorflow as tf\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_140_224/feature_vector/4', input_shape=[224, 224, 3], output_shape=[140])\n])\n\nimage = tf.keras.Input(shape=(224, 224, 3))\nfeatures = model(image)", "performance": {"dataset": "ImageNet", "accuracy": "Not provided"}, "description": "A pre-trained image feature vector model using MobileNetV2 architecture on ImageNet dataset. It can be used to extract features from images for various machine learning tasks."}}
{"code": "###Instruction: In the city, there are many parking lots. We want to count the number of cars parked in a parking lot using a security camera. Can an API help us to do this?\n###Output: <<<domain>>>: image-object-detection, <<<api_call>>>: hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2_fpnlite_640x640/1'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the pre-trained SSD MobileNet V2 FPN-Lite model from TensorFlow Hub, which has been trained to detect objects in images. Once loaded, you can pass an image taken by a security camera to the detector to get back the detected objects' bounding boxes, class labels, and associated confidence scores. The results can be filtered to count the number of cars detected in the parking lot image. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Load the SSD MobileNet V2 FPN-Lite model\ndetector = hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2_fpnlite_640x640/1')\n# Use the model to detect objects in an image\nimage_tensor = tf.convert_to_tensor(image, dtype=tf.uint8)\ninput_tensor = tf.expand_dims(image_tensor, axis=0)\noutput_dict = detector(input_tensor)\n", "api_call": "hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2_fpnlite_640x640/1')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image object detection", "framework": "TensorFlow Hub", "functionality": "Detect objects in images", "api_name": "ssd_mobilenet_v2_fpnlite_640x640", "api_call": "hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2_fpnlite_640x640/1')", "api_arguments": {"input_tensor": "4D image tensor", "output_tensor": "list of tensors representing bounding boxes, classes, scores, and number of detections"}, "python_environment_requirements": {"tensorflow": ">=2.0", "tensorflow_hub": ">=0.12"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\ndetector = hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2_fpnlite_640x640/1')\nimage_tensor = tf.convert_to_tensor(image, dtype=tf.uint8)\ninput_tensor = tf.expand_dims(image_tensor, axis=0)\noutput_dict = detector(input_tensor)", "performance": {"dataset": "COCO", "accuracy": "mAP of 0.32"}, "description": "A pre-trained object detection model that detects objects in images using the Single Shot MultiBox Detector (SSD) architecture with MobileNet V2 FPN-Lite feature extractor."}}
{"code": "###Instruction: I am going in the forest to observe wildlife, and I want to take a photo of an animal and recognize its species.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: model = hub.KerasLayer(\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4\"), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained image classification model from TensorFlow Hub, specifically the MobileNet V2 model. Once loaded, the model can be used to classify images and identify the species of animals found in a forest. The model is trained on the ImageNet dataset, which contains a wide variety of animal classes. <<<code>>>: import tensorflow_hub as hub\nmodel = hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4')\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading pre-trained models", "api_name": "model_id", "api_call": "hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow_hub as hub\nmodel = hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4')", "performance": {"dataset": "ImageNet", "accuracy": "Not specified"}, "description": "Load a pre-trained image classification model from TensorFlow Hub using the provided model_id."}}
{"code": "###Instruction: I am trying to build a recommendation system that can match similar customer reviews. Convert the given text into a high-dimensional vector that I can use.\n###Input: \"This product is absolutely amazing! I am extremely happy with my purchase and would highly recommend it to others.\"\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The requested API call loads the Universal Sentence Encoder model from TensorFlow Hub, a pre-trained model that converts input text into high-dimensional vectors. These vectors can then be used for various natural language processing tasks, such as similarity matching for customer reviews in a recommendation system. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed([\"This product is absolutely amazing! I am extremely happy with my purchase and would highly recommend it to others.\"])\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embed text", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": "text_input", "python_environment_requirements": "tensorflow, tensorflow_hub", "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello, world!', 'Embedding with Universal Sentence Encoder'])", "performance": {"dataset": "STS benchmark", "accuracy": "0.77"}, "description": "A pre-trained model that converts text into high-dimensional vectors for downstream tasks such as sentiment analysis, translation, and classification."}}
{"code": "###Instruction: I would like to analyze the sentiments of some sentences by creating an embedding representation of each sentence.\n###Output: <<<domain>>>: text-embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder model from TensorFlow Hub, which is designed for embedding text into high-dimensional vectors. These vectors can be utilized for tasks like text classification, semantic similarity, clustering, and other natural language tasks. Once loaded, you simply pass a list of sentences to the model to generate the embeddings. <<<code>>>: import tensorflow_hub as hub\n# Load the Universal Sentence Encoder model\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n# Embed a list of sentences (replace 'sentences' with your list of sentences)\nembeddings = embed(sentences)", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "embeddings = embed(['Hello world'])", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.803"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: Our customer support chat service needs to rank responses by their relevance to solve users' issues. So, we need to get embeddings for a list of response options.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the Universal Sentence Encoder model from TensorFlow Hub. This model encodes text into high-dimensional vectors which are useful for tasks like text classification, semantic similarity, and clustering, among others. In this case, you'll use the model to obtain embeddings for a list of response options, allowing you to rank them by relevance to the users' issues based on their embeddings. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": "text_input", "python_environment_requirements": "tensorflow, tensorflow_hub", "example_code": "import tensorflow_hub as hub; embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'); embeddings = embed(['Hello world!'])", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient > 0.8"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: Let's say my client wants to use an app to identify different dog breeds by uploading a picture. The app should inform them which breed they just uploaded.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: model = hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/2', input_shape=(224, 224, 3)), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained model for image classification of dog breeds from TensorFlow Hub. It uses the MobileNet V2 architecture and is trained on the ImageNet dataset. By creating a KerasLayer with the provided input shape, this model can be integrated with a TensorFlow model to identify various dog breeds in uploaded images. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/2', input_shape=(224, 224, 3))\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/2')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading a pre-trained model for image classification", "api_name": "mobilenet_v2_100_224", "api_call": "hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/2')", "api_arguments": {"handle": "https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/2", "input_shape": "(224, 224, 3)"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.5.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/2', input_shape=(224, 224, 3))\n\n# Load an image and preprocess it\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(224, 224))\ninput_image = tf.keras.preprocessing.image.img_to_array(image)\ninput_image = tf.expand_dims(input_image, 0)\n\n# Make predictions\npredictions = model(input_image)\n\n# Decode predictions\ndecoded_predictions = tf.keras.applications.mobilenet_v2.decode_predictions(predictions.numpy())\n\nprint(decoded_predictions)", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained image classification model using MobileNetV2 architecture, with 224x224 input size, and 100% depth multiplier. The model is trained on the ImageNet dataset and can be used for various image classification tasks."}}
{"code": "###Instruction: Take a sample sentence and encode it into high-dimensional vector using available API.\n###Output: <<<domain>>>: Text preprocessing, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call is responsible for loading the Universal Sentence Encoder from TensorFlow Hub, which is a model designed to encode text into high-dimensional vectors. When provided with a list of sentences, this model will output a set of high-dimensional vectors that can be used for various natural language processing tasks like text classification, semantic similarity, and clustering. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['sample sentence'])\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text preprocessing", "framework": "TensorFlow Hub", "functionality": "Text preprocessing", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": {"input": "List of sentences"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.8.0"}, "example_code": "import tensorflow_hub as hub; embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'); embeddings = embed(['sample sentence'])", "performance": {"dataset": "Various datasets", "accuracy": "Not mentioned"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: Analyze the news and figure out the topics of the articles.\n###Output: <<<domain>>>: text-embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the pre-trained Universal Sentence Encoder model from TensorFlow Hub. This model converts input text into high-dimensional vectors, which can be used for various natural language tasks like text classification, semantic similarity, clustering, and topic analysis. By using this model, you can create embeddings for the text content of news articles and then use clustering or similarity metrics to identify the topics/groups of similar articles. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n# Create embeddings for the text contents of news articles (assuming 'news_articles' is a list of article text contents)\nembeddings = embed(news_articles)\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "embeddings = embed(['Hello world', 'Embedding with TensorFlow Hub'])", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.803"}, "description": "A pre-trained model that converts text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: I want to build an application that can distinguish different dog breeds from photos. Help me extract features from a set of dog images.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call adds a pre-trained TensorFlow Hub layer using the MobileNet V2 architecture that has been trained on the ImageNet dataset to extract feature vectors from images. This model layer can be used to extract features from a set of dog images by providing it as the input layer to a TensorFlow Sequential model. These features can then be used to train a classifier to distinguish between different dog breeds. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=(224, 224, 3),\n                   trainable=False),\n    tf.keras.layers.Dense(5, activation='softmax')\n])\n\nmodel.compile(optimizer='adam',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Extract image features", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"handle": "https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4", "trainable": "False"}, "python_environment_requirements": {"tensorflow": "2.x", "tensorflow_hub": "0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                    input_shape=(224,224,3),\n                    trainable=False),\n    tf.keras.layers.Dense(5, activation='softmax')\n])\n\nmodel.compile(optimizer='adam',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])", "performance": {"dataset": "ImageNet", "accuracy": "71.9%"}, "description": "A pre-trained image feature vector model using MobileNet V2 architecture on ImageNet dataset, suitable for extracting features from images."}}
{"code": "###Instruction: Please create a database of images and their corresponding features using a pre-trained model.\n###Output: <<<domain>>>: Image-feature-vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224, 224, 3)), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the pre-trained MobileNetV2 model from TensorFlow Hub that has been trained on the ImageNet dataset. This model is used for generating image feature vectors. Once loaded, it creates a KerasLayer that takes an input shape of (224, 224, 3), which allows you to feed in images of this size to extract their feature vector for the database. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n  hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224, 224, 3))\n])\n\nimage_tensor = tf.random.uniform(shape=[1, 224, 224, 3])\nfeature_vector = model(image_tensor)\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Generating image feature vectors", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input": "image_tensor", "output": "feature_vector"}, "python_environment_requirements": {"tensorflow": ">=2.0", "tensorflow_hub": ">=0.12"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=(224, 224, 3))\n])\n\nimage_tensor = tf.random.uniform(shape=[1, 224, 224, 3])\nfeature_vector = model(image_tensor)\nprint(feature_vector.shape)", "performance": {"dataset": "ImageNet", "accuracy": "71.9%"}, "description": "This API generates a feature vector for an input image using the MobileNetV2 model trained on the ImageNet dataset."}}
{"code": "###Instruction: Implement an image classifier to categorize the type of clothing items in a fashion eCommerce dataset.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained image classification model using the MobileNetV2 architecture with a 100% depth multiplier. The model has been trained on the ImageNet dataset and can be used to classify clothing items by type in a fashion eCommerce dataset. Once the model is loaded, images can be preprocessed and resized to the appropriate size (224x224) and passed through the classifier to generate probabilistic predictions. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\ndef classify_image(image_path):\n  image = tf.keras.preprocessing.image.load_img(image_path, target_size=(224, 224))\n  image_array = tf.keras.preprocessing.image.img_to_array(image)\n  image_array = tf.expand_dims(image_array, 0)\n  predictions = model(image_array)\n  return predictions.numpy()", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Load and use a pre-trained image classification model", "api_name": "imagenet_mobilenet_v2_100_224_classification", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": {"model_url": "https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\n\ndef classify_image(image_path):\n  image = tf.keras.preprocessing.image.load_img(image_path, target_size=(224, 224))\n  image_array = tf.keras.preprocessing.image.img_to_array(image)\n  image_array = tf.expand_dims(image_array, 0)\n  predictions = model(image_array)\n  return predictions.numpy()", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained image classification model using MobileNetV2 architecture with 100% depth multiplier, trained on ImageNet dataset."}}
{"code": "###Instruction: Please suggest an API to quickly and easily classify animals in wildlife pictures using a pre-trained model.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call allows you to load a pre-trained model from TensorFlow Hub for image classification tasks. The MobileNet V2 model has been trained on the ImageNet dataset with an accuracy of 94.1%. You can use this pre-trained model to classify animals in wildlife pictures quickly and easily. Follow the sample code below to load an image and use the model for classification. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5')\n\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, 0)\n\npredictions = model(image_array)\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading and using pre-trained models for image classification", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5')", "api_arguments": ["model_id"], "python_environment_requirements": {"tensorflow": ">=2.0", "tensorflow_hub": ">=0.12"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5'\nmodel = hub.load(model_id)\n\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, 0)\n\npredictions = model(image_array)\n", "performance": {"dataset": "ImageNet", "accuracy": "94.1%"}, "description": "This API allows users to load pre-trained models from TensorFlow Hub for image classification tasks. It provides access to a variety of models, such as MobileNet, Inception, and ResNet, which have been trained on large datasets like ImageNet. Users can easily load a model using its model_id and perform image classification on their own images."}}
{"code": "###Instruction: Calculate the feature vector of some images of different fruits.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call lets you load the MobileNetV2 model, pre-trained on the ImageNet dataset, to extract feature vectors from images of fruits. These feature vectors can then be utilized for various machine learning tasks, such as transfer learning, image classification, or clustering. This particular model (MobileNetV2) is optimized for both computational efficiency and model size, making it ideal for deployment on resource-constrained devices. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')\nimage_tensor = tf.zeros([1, 224, 224, 3])\nfeature_vector = model(image_tensor)\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Extracts feature vector from images", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input": "image_tensor", "output": "feature_vector"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')\nimage_tensor = tf.zeros([1, 224, 224, 3])\nfeature_vector = model(image_tensor)", "performance": {"dataset": "ImageNet", "accuracy": "71.8%"}, "description": "This API extracts a feature vector from images using the MobileNetV2 model trained on the ImageNet dataset. It is useful for transfer learning and other tasks that require image embeddings."}}
{"code": "###Instruction: I need to classify common items found in a household. How do I do this using a pre-trained model?\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: model = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained image classification model from TensorFlow Hub using the MobileNet V2 architecture, which can classify images into 1000 different categories. Once the model is loaded, you can use it to classify images of common household items by processing the image, resizing it for the model, and then feeding the resized image into the model for classification. <<<code>>>: import tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Pre-trained models for image classification", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'\nmodel = hub.load(model_id)\nimage_tensor = tf.image.resize(image, (224, 224))\npredictions = model(image_tensor)", "performance": {"dataset": "ImageNet", "accuracy": "Top-1 Accuracy: 71.0%, Top-5 Accuracy: 90.1%"}, "description": "A pre-trained image classification model using TensorFlow Hub that can classify images into 1000 different categories. The model is based on the MobileNetV2 architecture and has been trained on the ImageNet dataset."}}
{"code": "###Instruction: I'm organizing an animal-based flashcard game for kids, sort these images by animal content using a pre-trained model.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: model = hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4', output_shape=[1001]), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained MobileNetV2 model for image classification via TensorFlow Hub. MobileNetV2 is a lightweight deep learning model specifically optimized for mobile devices. It has been trained on the ImageNet dataset, enabling it to recognize a wide range of animals. By using the pre-trained model, the animal images can be sorted based on their content for the flashcard game. <<<code>>>: import tensorflow_hub as hub\nmodel = hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4', output_shape=[1001])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading pre-trained models", "api_name": "mobilenet_v2", "api_call": "hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4')", "api_arguments": {"handle": "https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4", "output_shape": "[1001]"}, "python_environment_requirements": {"tensorflow": "2.0", "tensorflow_hub": "0.7"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4', output_shape=[1001])\n\n# Load an image\nimage = tf.keras.preprocessing.image.load_img('path/to/your/image.jpg', target_size=(224, 224))\nimage = tf.keras.preprocessing.image.img_to_array(image)\nimage = tf.keras.applications.mobilenet_v2.preprocess_input(image)\nimage = tf.expand_dims(image, 0)\n\n# Make predictions\npredictions = model(image)\n\n# Decode predictions\ndecoded_predictions = tf.keras.applications.mobilenet_v2.decode_predictions(predictions.numpy(), top=5)\n\nfor i, (imagenet_id, label, score) in enumerate(decoded_predictions[0]):\n    print('{}. {}: {:.2f}%'.format(i + 1, label, score * 100))", "performance": {"dataset": "ImageNet", "accuracy": "71.8%"}, "description": "MobileNetV2 is a lightweight deep learning model for image classification. It is pre-trained on the ImageNet dataset and can be loaded using TensorFlow Hub."}}
{"code": "###Instruction: We need to develop an app to quickly identify plants. Can you provide a pre-trained model to classify plant images?\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call is for a pre-trained MobileNetV2 image classification model, which has been trained on the ImageNet dataset. You can incorporate it into your application for classifying plant images. To use the model, you need to create a Keras sequential model with a single layer containing the pre-trained MobileNetV2 model from TensorFlow Hub. Then, you can preprocess your images and feed them into the model to make predictions. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\n])\n\nimage = tf.keras.utils.get_file('image.jpg','https://example.com/image.jpg')\nimg = tf.keras.preprocessing.image.load_img(image, target_size=(224, 224))\nimg_array = tf.keras.preprocessing.image.img_to_array(img)\nimg_array = tf.expand_dims(img_array, 0)\n\npredictions = model.predict(img_array)\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Image classification model", "api_name": "imagenet_mobilenet_v2_100_224_classification", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": {"handle": "https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4", "trainable": "False"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.6.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\n])\n\nimage = tf.keras.utils.get_file('image.jpg','https://example.com/image.jpg')\nimg = tf.keras.preprocessing.image.load_img(image, target_size=(224, 224))\nimg_array = tf.keras.preprocessing.image.img_to_array(img)\nimg_array = tf.expand_dims(img_array, 0)\n\npredictions = model.predict(img_array)\n", "performance": {"dataset": "ImageNet", "accuracy": "71.9%"}, "description": "A pre-trained image classification model using MobileNetV2 architecture on ImageNet dataset."}}
{"code": "###Instruction: Design a mobile application which requires a custom model to classify 10 different dog breeds based on their photos.\n###Output: <<<domain>>>: image-feature-vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224, 224, 3), trainable=False), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call leverages a pre-trained MobileNet V2 model available from TensorFlow Hub to create a feature extractor for images. The model has been trained on the ImageNet dataset and can extract a 1280-dimensional feature vector, which can be fed into a custom classifier for the 10 dog breeds. To fine-tune the model, the KerasLayer is set to be non-trainable, and a new, trainable Dense layer with appropriate number of output classes and an activation function of 'softmax' is added. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nnum_classes = 10  # The number of dog breeds\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224, 224, 3), trainable=False),\n    tf.keras.layers.Dense(num_classes, activation='softmax')\n])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction from images", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "[batch_size, 224, 224, 3]", "output_shape": "[batch_size, 1280]"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "model = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                    input_shape=(224,224,3), trainable=False),\n    tf.keras.layers.Dense(num_classes, activation='softmax')\n])", "performance": {"dataset": "ImageNet", "accuracy": "71.9%"}, "description": "A pre-trained image feature vector model using MobileNetV2 architecture with 100% depth and 224x224 input size. The model is trained on the ImageNet dataset and can be used for feature extraction, fine-tuning, or as a component in a larger model."}}
{"code": "###Instruction: We need to identify bird species from some bird images we collected.\n###Output: <<<domain>>>: image-classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Inception V3 model from TensorFlow Hub, which is pre-trained on the ImageNet dataset. This model can be used for image classification tasks, such as identifying bird species in a given image. To perform classification, simply load the model using the provided API, preprocess the image input to the required dimensions, and pass the preprocessed image to the loaded model. The model will output predictions, which can be interpreted as classifications. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v3/classification/5'\nmodel = hub.load(model_id)\n\nimage = tf.keras.preprocessing.image.load_img('bird_image.jpg', target_size=(299, 299))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_tensor = tf.expand_dims(image_array, 0)\n\npredictions = model(image_tensor)", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Image classification using pre-trained models", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v3/classification/5'\nmodel = hub.load(model_id)\nimage = tf.keras.preprocessing.image.load_img('image.jpg', target_size=(299, 299))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_tensor = tf.expand_dims(image_array, 0)\n\npredictions = model(image_tensor)\n", "performance": {"dataset": "ImageNet", "accuracy": "Not specified"}, "description": "This API allows users to perform image classification using pre-trained models from TensorFlow Hub. Users can load a model using its model_id and then use it to classify images."}}
{"code": "###Instruction: Recommend a neural network layer to obtain a feature vector from a 224x224x3 image for the purpose of similarity search.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224, 224, 3)), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call creates a KerasLayer that wraps the pre-trained MobileNetV2 model. This model is specifically designed for feature extraction from images. By providing an input image with a shape of 224x224x3, the layer will output a 1280-dimensional feature vector that can be used for similarity search tasks. <<<code>>>: import tensorflow_hub as hub\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224, 224, 3))\n])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction", "api_name": "imagenet-mobilenet_v2_100_224-feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "[None, 224, 224, 3]", "output_shape": "[None, 1280]"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.6.0"}, "example_code": "model = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                    input_shape=(224, 224, 3),\n                    trainable=False),\n    tf.keras.layers.Dense(10, activation='softmax')\n])", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A Keras layer that wraps a pre-trained MobileNetV2 model for feature extraction. It takes an input image of size 224x224x3 and outputs a 1280-dimensional feature vector."}}
{"code": "###Instruction: We want to find semantically similar sentences in our customer reviews. Obtain a high-dimensional vector of each review sentence.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the Universal Sentence Encoder (USE) model from TensorFlow Hub. This model is designed to transform input text into high-dimensional vectors, which can then be used to compute semantic similarity between sentences, such as the customer review sentences in your application. Once the review sentences are converted into high-dimensional vectors, you can calculate the similarity using appropriate similarity measures (e.g., cosine similarity). <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['This is a review sentence', 'Another review sentence to compare'])\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into a high-dimensional vector", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world!'])", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.803"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks"}}
{"code": "###Instruction: Let's say we have a dataset of images and we want to compress and store them. Design a method for feature extraction and compression.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: To extract features and compress images, we can utilize a pre-trained MobileNet V2 model that transforms input images into feature vectors. This model is specifically designed for feature extraction and has been pre-trained on the ImageNet dataset using TensorFlow Hub. By using this model, we can transform images into 1280-dimensional vectors while preserving high-level features of the input images. This helps in compressing the images and storing them in a feature vector form. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Create a model using the MobileNet V2 KerasLayer as a feature extractor\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=[224, 224, 3], trainable=False),\n])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Extract feature vectors from images", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "[None, 224, 224, 3]", "output_shape": "[None, 1280]", "trainable": "False"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.6.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=(224, 224, 3),\n                   trainable=False),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])", "performance": {"dataset": "ImageNet", "accuracy": "71.9%"}, "description": "This module uses the MobileNet v2 architecture to extract feature vectors from images. It has been pre-trained on the ImageNet dataset and can be fine-tuned for various classification tasks."}}
{"code": "###Instruction: I took a picture of a plant in my garden, and I want to identify it using an image classification model.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: loaded_model = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads a pre-trained image classification model called MobileNetV2 from TensorFlow Hub. This model has been trained on the ImageNet dataset and can classify images into multiple categories. By inputting the image of the plant taken in your garden, the model can provide a prediction on the plant's identity based on the categories it has been trained on. <<<code>>>: import tensorflow_hub as hub\nloaded_model = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'\nloaded_model = hub.load(model_id)\n\n# Example image\nimage = tf.keras.utils.get_file('image.jpg','https://storage.googleapis.com/download.tensorflow.org/example_images/grace_hopper.jpg')\n\n# Preprocess image\nimage = tf.keras.preprocessing.image.load_img(image, target_size=(224, 224))\nimage = tf.keras.preprocessing.image.img_to_array(image)\nimage = tf.keras.applications.mobilenet_v2.preprocess_input(image)\nimage_batch = tf.expand_dims(image, 0)\n\n# Make predictions\npredictions = loaded_model(image_batch)\n", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained image classification model using MobileNetV2 architecture, trained on ImageNet dataset."}}
{"code": "###Instruction: I'm building a mobile app that classifies images taken by users. The model should be lightweight and fast.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained ImageNet classification model, MobileNetV2, from TensorFlow Hub. MobileNetV2 is a lightweight and fast model, suitable for mobile applications that require image classification. It is trained on the ImageNet dataset for classifying objects into various categories. <<<code>>>: import tensorflow_hub as hub\nloaded_model = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'\nloaded_model = hub.load(model_id)", "performance": {"dataset": "ImageNet", "accuracy": "Not specified"}, "description": "Load a pre-trained image classification model from TensorFlow Hub using the specified model_id."}}
{"code": "###Instruction: I have a collection of images from an automobile trade show and I want to identify the different vehicle models present in those images.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: model = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads a pre-trained MobileNetV2 model for image classification from TensorFlow Hub. This model has been trained on the ImageNet dataset and can be used for various image classification tasks including identifying vehicle models in images. The model is designed to be small and efficient, while maintaining high accuracy. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Load a pre-trained model for image classification", "api_name": "imagenet_mobilenet_v2_130_224_classification", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')", "api_arguments": {"model_url": "https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')\ninput_image = tf.keras.preprocessing.image.load_img('path/to/your/image.jpg', target_size=(224, 224))\ninput_array = tf.keras.preprocessing.image.img_to_array(input_image) / 255.0\ninput_tensor = tf.expand_dims(input_array, 0)\npredictions = model(input_tensor)\nclass_index = tf.argmax(predictions, axis=-1).numpy()[0]", "performance": {"dataset": "ImageNet", "accuracy": "Top-1 accuracy: 75.6%, Top-5 accuracy: 92.8%"}, "description": "A pre-trained MobileNetV2 model for image classification on the ImageNet dataset. The model is designed to be small and efficient while maintaining high accuracy. It can be used for various image classification tasks."}}
{"code": "###Instruction: Recommend a solution to classify diseases from the images of plant leaves.\n\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: model = tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224,224,3), trainable=False), tf.keras.layers.Dense(100, activation='softmax')]), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call uses a pre-trained MobileNetV2 model from TensorFlow Hub with 100% depth multiplier and 224x224 input size. This model generates feature vectors from input images, which can be used for classification tasks such as detecting diseases from plant leaves. You can create a custom deep learning model by adding additional layers like a Dense layer with the appropriate activation functions for your classification problem (softmax for multi-class problems).- <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224,224,3), trainable=False), tf.keras.layers.Dense(100, activation='softmax')])", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Generating image feature vectors", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "[None, 224, 224, 3]", "output_shape": "[None, 1280]"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.8.0"}, "example_code": {"import": ["import tensorflow as tf", "import tensorflow_hub as hub"], "model": ["model = tf.keras.Sequential([", "  hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',", "                 input_shape=(224,224,3),", "                 trainable=False),", "  tf.keras.layers.Dense(100, activation='softmax')", "])"]}, "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained deep learning model for generating image feature vectors using MobileNetV2 architecture with 100% depth and 224x224 input size."}}
{"code": "###Instruction: We need to extract features from a large set of images to use as input for an image classifier.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/5'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the pre-trained MobileNetV2 feature vector model from TensorFlow Hub, which is trained on the ImageNet dataset. After loading the model, you can extract feature vectors from images by passing them through this hub.KerasLayer. These feature vectors can then be used as the input for an image classifier model. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Create a Keras Sequential model\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/5',\n                   input_shape=(224, 224, 3),\n                   trainable=False),\n    # Add classification head\n    tf.keras.layers.Dense(10, activation='softmax')\n])\n# Compile the model\nmodel.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/5')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Extracting feature vector from images", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/5')", "api_arguments": {"input_shape": "[224, 224, 3]", "output_shape": "[1280]"}, "python_environment_requirements": {"tensorflow": ">=2.0", "tensorflow_hub": ">=0.12"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/5',\n                   input_shape=(224, 224, 3),\n                   trainable=False),\n    tf.keras.layers.Dense(10, activation='softmax')\n])\n\nmodel.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\nmodel.fit(x_train, y_train, epochs=5)", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained image feature vector model using MobileNetV2 architecture on ImageNet dataset. It can be used for various image classification tasks by adding a classification head on top of the feature vector."}}
{"code": "###Instruction: In music recommendation systems, we need to represent the songs as feature vectors. How can we do this?\n###Output: <<<domain>>>: Audio Embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/yamnet/1'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: One way to represent songs as feature vectors is to use the YAMNet model from TensorFlow Hub. YAMNet is a deep neural network that predicts 521 audio event classes based on the AudioSet dataset. It employs the Mobilenet_v1 depthwise-separable convolution architecture. By loading and using this pre-trained model, you can convert the audio of the songs into feature vectors, which can then be used in a music recommendation system. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel_id = 'https://tfhub.dev/google/yamnet/1'\nmodel = hub.load(model_id)", "api_call": "hub.load('https://tfhub.dev/google/yamnet/1')", "provider": "TensorFlow Hub", "api_data": {"domain": "Audio embedding", "framework": "TensorFlow Hub", "functionality": "Converts audio into embeddings", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/yamnet/1')", "api_arguments": ["audio"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/yamnet/1'\nmodel = hub.load(model_id)\nembeddings = model(audio)", "performance": {"dataset": "AudioSet", "accuracy": "Not provided"}, "description": "YAMNet is a deep net that predicts 521 audio event classes based on the AudioSet dataset. It employs the Mobilenet_v1 depthwise-separable convolution architecture."}}
{"code": "###Instruction: I have a list of user reviews on my shopping website, and I want to cluster them into different categories.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: To cluster user reviews, you can use the Universal Sentence Encoder (USE) model from TensorFlow Hub. This model is capable of converting text into high-dimensional vectors, which can then be used for various natural language tasks like text classification, semantic similarity, and clustering. By using the USE model to embed your user reviews, you can analyze the relationships between the embedded vectors and cluster them into different categories. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n# Assuming 'user_reviews' is a list of user review texts\nembeddings = embed(user_reviews)\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text data", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": {"input": "Text input"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.8.0"}, "example_code": "import tensorflow_hub as hub; embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'); embeddings = embed(['Hello world!'])", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.80"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: Somebody sent me a photo of a car brand's logo, and I need to identify the brand.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call creates a Keras Layer that includes a pre-trained model for image classification based on the MobileNetV2 architecture. The model is trained on the ImageNet dataset and can classify images into numerous classes. Once the Keras Layer is integrated into your neural network, it can be used to predict the class of the car brand's logo in the given image. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')\n])\nresult = model.predict(image_batch)\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Pre-trained models for image classification", "api_name": "imagenet-mobilenet_v2_130_224-classification", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')", "api_arguments": ["URL"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')\n])\nresult = model.predict(image_batch)", "performance": {"dataset": "ImageNet", "accuracy": "Not specified"}, "description": "A pre-trained model for image classification using MobileNetV2 architecture on the ImageNet dataset."}}
{"code": "###Instruction: I want to build an image-based recommendation system. Please suggest a way to classify images more efficiently.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: To classify images efficiently, you can use the pre-trained MobileNetV2 model from TensorFlow Hub that is trained on the ImageNet dataset. This model is optimized for performance and provides good accuracy for image classification tasks. By utilizing the 'hub.KerasLayer' API call, you can embed this model into your TensorFlow application, making it easy to apply this image classification model to your recommendation system.<<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Image Classification", "api_name": "imagenet_mobilenet_v2_100_224_classification", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": "URL: https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4", "python_environment_requirements": "tensorflow, tensorflow_hub", "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'),\n])\n", "performance": {"dataset": "ImageNet", "accuracy": "71.8%"}, "description": "A pre-trained image classification model using MobileNetV2 architecture on ImageNet dataset with 100% depth and 224x224 input size."}}
{"code": "###Instruction: Create a recommendation system that recommends similar products using product descriptions.\n###Output: <<<domain>>>: text-embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: By loading the Universal Sentence Encoder model, you can convert product descriptions into high-dimensional vectors. These vectors can then be used to measure semantic similarity between products by calculating their cosine similarity or other similarity metrics. This will allow you to create a recommendation system that recommends similar products based on their descriptions. <<<code>>>: import tensorflow_hub as hub\n# Load the Universal Sentence Encoder model\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n# Example product descriptions to get the embeddings\ndescriptions = ['A high-performance laptop with 8GB RAM and 256GB SSD', 'A gaming monitor with a 144Hz refresh rate and 1ms response time']\n# Get the embeddings for the product descriptions\nembeddings = embed(descriptions)\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world!'])\nprint(embeddings)", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.803"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: Analyze public opinions on a new coffee flavor and find out if they are related to each other.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder from TensorFlow Hub, which encodes text into high-dimensional vectors. These vectors can be used to measure the semantic similarity between sentences, allowing you to analyze public opinions on a new coffee flavor and find out how related they are to each other. Once the model is loaded, pass the input sentences to the 'embed' method to get the embeddings for each sentence. You can then compare these embeddings to determine the similarity between public opinions. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['sentence1', 'sentence2'])", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world!'])\nprint(embeddings)", "performance": {"dataset": "STS benchmark", "accuracy": "0.80"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: I am an app developer and I need a lightweight image classification model to classify images into different categories. How can I do that?\n###Output: <<<domain>>>: image-classification, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call provided here imports the lightweight pre-trained MobileNetV2 model from TensorFlow Hub. This model is specifically designed for image classification tasks and can classify images into 1000 different categories. You would incorporate this model as a KerasLayer in your TensorFlow pipeline for image classification. It is optimized for mobile devices, making it a suitable choice for app development. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nIMAGE_SHAPE = (224, 224)\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4', input_shape=IMAGE_SHAPE+(3,))\n])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Image classification using a pre-trained model", "api_name": "mobilenet_v2", "api_call": "hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4')", "api_arguments": {"model_url": "https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4", "input_shape": "IMAGE_SHAPE+(3,)"}, "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nIMAGE_SHAPE = (224, 224)\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4', input_shape=IMAGE_SHAPE+(3,))\n])\n\nimage = tf.keras.preprocessing.image.load_img('image.jpg', target_size=IMAGE_SHAPE)\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, 0)\n\nresult = model.predict(image_array)\n", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "MobileNetV2 is a pre-trained image classification model that can classify images into 1000 different categories. It is lightweight and optimized for mobile devices."}}
{"code": "###Instruction: I am not good at recognizing sports, sometimes I make mistakes. Therefore, I need a tool to check the answer for me.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained image classification model, MobileNet V2, from TensorFlow Hub. The model is trained on the ImageNet dataset and can effectively classify objects in images. To use it for recognizing sports, simply feed an image of a sporting event to the model, and it will provide you with predictions for the class of the image, helping you determine the type of sport.<<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel_id = 'https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5'\nmodel = hub.load(model_id)\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Pre-trained model for image classification", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5')", "api_arguments": [{"model_id": "string (URL or local path to the model)"}], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5'\nmodel = hub.load(model_id)\n\n# Load and preprocess an image\nimage = tf.keras.preprocessing.image.load_img('image.jpg', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, 0)\n\n# Classify the image\npredictions = model(image_array)\npredicted_class = tf.argmax(predictions, axis=-1).numpy()[0]\nprint('Predicted class:', predicted_class)", "performance": {"dataset": "ImageNet", "accuracy": "Not specified"}, "description": "A pre-trained model for image classification using TensorFlow Hub."}}
{"code": "###Instruction: Can you please make model to classify type of car\\vehicle from an image?\n###Output: <<<domain>>>: image-classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/mobilenet_v1_050_160/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the pre-trained MobileNet V1 model from TensorFlow Hub, which has been trained for image classification on the ImageNet dataset. Once loaded, you can use this model to classify objects or scenes in images, such as different types of vehicles.<<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Load the pre-trained MobileNet V1 model for image classification\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v1_050_160/classification/4')\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v1_050_160/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading", "api_name": "imagenet_mobilenet_v1_050_160_classification", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v1_050_160/classification/4')", "api_arguments": "URL", "python_environment_requirements": "tensorflow, tensorflow-hub", "example_code": "", "performance": {"dataset": "ImageNet", "accuracy": "Not specified"}, "description": "Loads a pre-trained MobileNet V1 model for image classification from TensorFlow Hub"}}
{"code": "###Instruction: Analyze online customer reviews and their sentiment by getting an embedding of each review.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API loads the Universal Sentence Encoder model from TensorFlow Hub, which is designed to encode text into high-dimensional vectors. By getting an embedding for each customer review, you can analyze the sentiment and other relevant features of the text. These embeddings can then be used as input for further natural language processing and sentiment analysis tasks. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello, world!', 'Greetings, humans!'])\nprint(embeddings)", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.78"}, "description": "A pre-trained model for embedding text into high-dimensional vectors that can be used in various natural language processing tasks."}}
{"code": "###Instruction: I want a system that can find the similarity between different movie reviews.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the pre-trained Universal Sentence Encoder model from TensorFlow Hub. This model converts text into high-dimensional vectors that can be used for various natural language processing tasks such as text classification, semantic similarity, clustering, etc. Using this encoding, you can find the similarity between different movie reviews by computing the cosine similarity, Pearson correlation, or other similarity measures between their embedding vectors. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embed text using a pre-trained model", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["text_input"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world'])", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.803"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: My company wants to build a recyclable materials recognition system. We plan to reuse some pre-trained models for transfer learning.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: To build a recyclable materials recognition system, you can use a pre-trained image feature vector model based on the MobileNetV2 architecture as a starting point. This model, which is available on TensorFlow Hub, can be loaded as a Keras layer and used for feature extraction from images. By reusing this model, you save time and effort compared to training a new model from scratch, and can fine-tune the model on your specific dataset of recyclable materials.<<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=[224, 224, 3], output_shape=[1280])\n])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "[224, 224, 3]", "output_shape": "[1280]"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=[224, 224, 3],\n                   output_shape=[1280])\n])\n\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, 0)\n\nfeatures = model.predict(image_array)", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained image feature vector model based on MobileNetV2 architecture, which can be used for image classification or as a feature extractor for transfer learning."}}
{"code": "###Instruction: We want to help our users analyze their posture while performing exercises. Help us detect human poses in images to do that.\n###Output: <<<domain>>>: Image pose detection, <<<api_call>>>: hub.load('https://tfhub.dev/google/movenet/singlepose/lightning/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the MoveNet model from TensorFlow Hub. MoveNet is a model that detects human poses in images and is trained on the COCO dataset. By using this model, you can pass an input image (or a batch of images) with the required shape [batch_size, height, width, 3] and receive an output containing the detected human poses. This data can be used to analyze a user's posture during exercise. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\npose = hub.load('https://tfhub.dev/google/movenet/singlepose/lightning/4')\n", "api_call": "hub.load('https://tfhub.dev/google/movenet/singlepose/lightning/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image pose detection", "framework": "TensorFlow Hub", "functionality": "Detect human poses in images", "api_name": "movenet", "api_call": "hub.load('https://tfhub.dev/google/movenet/singlepose/lightning/4')", "api_arguments": {"input_image": "A single image or batch of images with shape [batch_size, height, width, 3]"}, "python_environment_requirements": {"tensorflow": ">=2.5.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\npose = hub.load('https://tfhub.dev/google/movenet/singlepose/lightning/4')\ninput_image = tf.zeros([1, 192, 192, 3])\noutput = pose(input_image)", "performance": {"dataset": "COCO", "accuracy": "0.720"}, "description": "MoveNet is a model that detects human poses in images. It is trained on the COCO dataset and available on TensorFlow Hub."}}
{"code": "###Instruction: We need a way to classify and identify various objects in images, suggest a pre-trained model for that.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call adds the pre-trained MobileNetV2 model from TensorFlow Hub as a Keras layer. This model has been trained on the ImageNet dataset and can be used for classifying objects in images. The model architecture has been optimized for performance on mobile devices but still provides good accuracy for image classification tasks. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Create a Keras model using MobileNetV2 pre-trained model\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')\n])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Pre-trained image classification model", "api_name": "imagenet_mobilenet_v2_130_224_classification", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')", "api_arguments": {"url": "https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')\n])\nimage = tf.keras.preprocessing.image.load_img('path/to/your/image.jpg', target_size=(224, 224))\nimage = tf.keras.preprocessing.image.img_to_array(image)\nimage = tf.expand_dims(image, 0)\npredictions = model.predict(image)", "performance": {"dataset": "ImageNet", "accuracy": "Not specified"}, "description": "A pre-trained image classification model using MobileNetV2 architecture trained on ImageNet dataset."}}
{"code": "###Instruction: Let's take a picture from our hike yesterday, classify the primary plants or flowers in it.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: model = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The pre-trained image classification model, MobileNetV2, can be loaded using the TensorFlow Hub. It is trained on the ImageNet dataset and can classify images with a 71.0% accuracy. This model, which uses 100% width and has an input size of 224x224, can classify images into 1000 different categories. You can use it to identify and classify the primary plants or flowers in your hiking picture. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\n# Load the MobileNetV2 model\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading pre-trained models for image classification", "api_name": "imagenet_mobilenet_v2_100_224_classification", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": "URL of the pre-trained model", "python_environment_requirements": "TensorFlow 2.x, TensorFlow Hub", "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\n\n# Load an image and preprocess it\ndef load_image(file_path):\n    img = tf.keras.preprocessing.image.load_img(file_path, target_size=(224, 224))\n    img_array = tf.keras.preprocessing.image.img_to_array(img)\n    img_array = tf.expand_dims(img_array, 0)  # Create a batch\n    return img_array\n\n# Predict the class of the image\nimg_array = load_image('path/to/your/image.jpg')\npredictions = model(img_array)\n\n# Get the class with the highest probability\npredicted_class = tf.argmax(predictions, axis=-1).numpy()[0]", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained image classification model using MobileNetV2 architecture with 100% width and 224x224 input size. The model is trained on the ImageNet dataset and can be used to classify images into 1000 different categories."}}
{"code": "###Instruction: We are going to develop security cameras to monitor our client's warehouse for unauthorized access.\n###Output: <<<domain>>>: image-object-detection, <<<api_call>>>: hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained object detection model using the SSD MobileNet V2 architecture from TensorFlow Hub. The model is trained on the COCO dataset and can detect multiple objects in an image by returning their class, bounding box coordinates, and confidence scores. This model can be used to monitor a warehouse for unauthorized access by detecting people or objects that are not supposed to be in the area. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Load the SSD MobileNet V2 model\nmodel_id = 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'\nloaded_model = hub.load(model_id)\n# Assuming you have a preprocessed 'input_tensor' representing your image (shape [1, image_height, image_width, 3])\noutput_dict = loaded_model(input_tensor)\n# Extract detection boxes, scores, and classes from the output\nboxes = output_dict['detection_boxes'][0].numpy()\nscores = output_dict['detection_scores'][0].numpy()\nclasses = output_dict['detection_classes'][0].numpy().astype(np.int32)", "api_call": "hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image object detection", "framework": "TensorFlow Hub", "functionality": "Object detection", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'\nloaded_model = hub.load(model_id)\n\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg')\nimage_np = np.array(image)\n\ninput_tensor = tf.convert_to_tensor(image_np)\ninput_tensor = input_tensor[tf.newaxis, ...]\n\noutput_dict = loaded_model(input_tensor)\n\nboxes = output_dict['detection_boxes'][0].numpy()\nscores = output_dict['detection_scores'][0].numpy()\nclasses = output_dict['detection_classes'][0].numpy().astype(np.int32)", "performance": {"dataset": "COCO", "accuracy": "0.320"}, "description": "This API provides a pre-trained object detection model using TensorFlow Hub. The model is based on the SSD MobileNet V2 architecture and is trained on the COCO dataset. It can be used to detect multiple objects in an image and returns their class, bounding box coordinates, and confidence scores."}}
{"code": "###Instruction: I have a large collection of restaurant reviews in English, and I want to cluster them based on their content.\n###Output: <<<domain>>>: text-embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call allows you to load the Universal Sentence Encoder model from TensorFlow Hub, which embeds variable-length English text into fixed-length high-dimensional vectors. These vectors can then be used in various natural language processing tasks, such as clustering or semantic similarity. In your scenario, the model will be used to embed restaurant reviews, which can further be clustered based on their content. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow_hub as hub; embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'); embeddings = embed(['Hello world!'])", "performance": {"dataset": "STS Benchmark", "accuracy": "0.803"}, "description": "A model for encoding variable-length English text into fixed-length high-dimensional vectors. It is useful for applications such as semantic similarity, clustering, or text classification."}}
{"code": "###Instruction: Detect the fashion items in given images and create a model for fashion item feature extraction using pretrained image Feature Vector.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: To create a model for fashion item feature extraction, use TensorFlow Hub's MobileNetV2 image feature vector model, pretrained on ImageNet (imagenet_mobilenet_v2_100_224_feature_vector). The API call connects to TensorFlow Hub and loads the pretrained model as a KerasLayer, allowing you to use it as a module in your image classifier. The layer inputs are images with a shape of (224, 224, 3), and the output shape is (1280,). It is suitable for extracting features from fashion images. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Create a model with a single KerasLayer for feature extraction\nmodel = tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224, 224, 3))])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "(224, 224, 3)", "output_shape": "(1280,)"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained image feature vector model based on MobileNetV2 architecture for image classification tasks."}}
{"code": "###Instruction: Determine which type of fruit is in the photograph by analyzing and classifying the image.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: model = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained MobileNet V2 model for image classification from TensorFlow Hub. The model is trained on the ImageNet dataset and can be used to classify images into various categories, including fruit types. Once the model is loaded, it can be applied to the photograph to determine the type of fruit present in the image. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\nimage = tf.zeros([1, 224, 224, 3])  # Replace this with your image tensor\nlogits = model(image)", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Pre-trained models for image classification", "api_name": "imagenet_mobilenet_v2_100_224_classification", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": {"url": "https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4"}, "python_environment_requirements": {"tensorflow": "2.x", "tensorflow_hub": "0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\nimage = tf.zeros([1, 224, 224, 3])  # A batch of images with shape [batch_size, height, width, 3].\nlogits = model(image)  # Logits with shape [batch_size, num_classes].", "performance": {"dataset": "ImageNet", "accuracy": "71.9%"}, "description": "MobileNetV2 model for image classification, pre-trained on ImageNet and optimized for TensorFlow Hub."}}
{"code": "###Instruction: We want to build an image recognition system to classify paintings by artists. Please show us how to use a pretrained model for feature extraction from the paintings.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call provides a Keras Layer wrapping the MobileNet V2 model, pretrained on the ImageNet dataset for feature extraction. You can use this layer to create a custom image classification model for distinguishing paintings by artists. Add a dense layer with the desired number of artist classes, compile the model, and train it on your specific dataset. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nnum_classes = 10  # Number of artist classes\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'),\n    tf.keras.layers.Dense(num_classes, activation='softmax')\n])\n\nmodel.compile(optimizer=tf.keras.optimizers.Adam(),\n              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])\n\nmodel.fit(x_train, y_train, epochs=5)", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction from images", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"url": "https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'),\n    tf.keras.layers.Dense(num_classes, activation='softmax')\n])\n\nmodel.compile(optimizer=tf.keras.optimizers.Adam(),\n              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])\n\nmodel.fit(x_train, y_train, epochs=5)", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A Keras layer that wraps the MobileNet V2 model pre-trained on ImageNet for image feature extraction. It can be used to create a custom image classification model by adding a dense layer with the desired number of output classes and training on a specific dataset."}}
{"code": "###Instruction: We want to generate embeddings for a list of movie descriptions so we can later measure the similarity between these movies.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: embed = hub.KerasLayer('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call wraps the Universal Sentence Encoder model in a KerasLayer, enabling the model to process text and generate embeddings for various natural language tasks. In this case, we want to create embeddings for movie descriptions which can be later used to measure semantic similarity between movies. <<<code>>>: import tensorflow_hub as hub\nembed = hub.KerasLayer('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.KerasLayer('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": {"input": "Text or list of texts", "output": "Array of embeddings"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.8.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.KerasLayer('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world!', 'Embedding is fun!'])", "performance": {"dataset": "STS Benchmark", "accuracy": "0.803"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: Tell me what animal I have in my picture. How can I achieve this using a pre-trained TensorFlow model?\n\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: You can use the pre-trained MobileNetV2 image classification model from TensorFlow Hub to identify the animal in your picture. Once you load the model using hub.KerasLayer, you can preprocess the image to the required size (224, 224) and format, and then pass it to the model to get the predictions. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\n# Load the pre-trained MobileNetV2 model\nmodel = tf.keras.Sequential([\n    hub.KerasLayer(\n        handle='https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4',\n        input_shape=(224, 224, 3),\n        trainable=False\n    )\n])\n\n# Prepare the image (assuming 'path_to_your_image.jpg' is the path to your image)\nimage = tf.keras.preprocessing.image.load_img('path_to_your_image.jpg', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, 0)\n\n# Make predictions using the model\npredictions = model.predict(image_array)", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Pre-trained models for image classification", "api_name": "imagenet_mobilenet_v2_130_224_classification", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')", "api_arguments": {"handle": "https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4", "trainable": "Optional, default is False"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.6.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer(\n        handle='https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4',\n        input_shape=(224, 224, 3),\n        trainable=False\n    )\n])\n\nimage = tf.keras.preprocessing.image.load_img('path_to_your_image.jpg', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, 0)\n\npredictions = model.predict(image_array)\n", "performance": {"dataset": "ImageNet", "accuracy": "80.3%"}, "description": "A pre-trained image classification model using the MobileNetV2 architecture, trained on the ImageNet dataset. It is designed for efficient on-device performance with reduced computational and memory requirements."}}
{"code": "###Instruction: We have a long list of customer reviews for our products. We need to determine which ones are similar so we can improve specific products.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder model from TensorFlow Hub, which is designed to encode text into high-dimensional vectors. These embeddings can be used to compare the similarity of different texts, like customer reviews. By identifying similar reviews, you can group them together and analyze the specific issues raised or improvements desired for particular products. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Convert text into embeddings", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world!'])", "performance": {"dataset": "STS benchmark", "accuracy": "85.1% Pearson correlation"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: I have a folder containing images of animals, and I would like to automatically label these images with the name of the animal they contain.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads a pre-trained image classification model using the MobileNet V2 architecture from TensorFlow Hub. This model has been trained on the ImageNet dataset and can be used to classify images into various categories. In this case, it can be used to label images of animals according to the category they belong to. <<<code>>>: import tensorflow_hub as hub\nimport tensorflow as tf\n# Create a model with a single KerasLayer for image classification\nmodel = tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Pre-trained image classification model", "api_name": "imagenet/mobilenet_v2_100_224/classification", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": "URL of the pre-trained model", "python_environment_requirements": "tensorflow, tensorflow_hub", "example_code": "import tensorflow_hub as hub\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\n])\n\npredictions = model.predict(images)", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained image classification model using MobileNetV2 architecture on ImageNet dataset"}}
{"code": "###Instruction: I have an online marketplace where people sell secondhand items. I would like to categorize the photos of the products people upload.\n###Output: <<<domain>>>: image-classification, <<<api_call>>>: model = hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: To categorize the photos of products uploaded to your online marketplace, you can use the TensorFlow Hub pre-trained image classification model with Inception V3 architecture. This model has been trained on a vast range of images using the ImageNet dataset. By loading the pre-trained model with the given API call, you can use it to classify the images of the products into multiple categories. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Load the pre-trained Inception V3 model\nmodel = hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')\n# Assuming 'image' is a properly pre-processed image tensor\npredictions = model(image)\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Load and use pre-trained models for image classification", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v3/classification/5'\nmodel = hub.load(model_id)\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(299, 299))\nimage = tf.keras.preprocessing.image.img_to_array(image)\nimage = tf.expand_dims(image, axis=0)\npredictions = model(image)\n", "performance": {"dataset": "ImageNet", "accuracy": "N/A"}, "description": "Load and use a pre-trained image classification model from TensorFlow Hub to classify images."}}
{"code": "###Instruction: Provide me with the ability to identify objects present in a given image, for improving the accessibility of our application.\n###Output: <<<domain>>>: Image object detection, <<<api_call>>>: hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained object detection model, specifically SSD MobileNet V2, from TensorFlow Hub. The model is trained on the COCO dataset and can be used to detect objects present in an image. The object detection will help in enhancing accessibility by identifying and providing information about objects within images. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel_id = 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'\ndetector = hub.load(model_id)\n", "api_call": "hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image object detection", "framework": "TensorFlow Hub", "functionality": "Detect objects in images", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nmodel_id = 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'\ndetector = hub.load(model_id)\nimage = tf.image.decode_jpeg(tf.io.read_file('path/to/image.jpg'))\nresult = detector(image[tf.newaxis, ...])", "performance": {"dataset": "COCO", "accuracy": "mAP"}, "description": "This API allows you to detect objects in images using a pre-trained model from TensorFlow Hub. The model is based on the SSD MobileNet V2 architecture and has been trained on the COCO dataset."}}
{"code": "###Instruction: I have a collection of paintings and I want to extract their main features to use for indexing among different categories.\n###Output: <<<domain>>>: image-feature-vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224, 224, 3), output_shape=(1280,)), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: To extract main features from images of paintings for indexing purposes, you can use the pre-trained MobileNet V2 model from TensorFlow Hub. The model has been trained on the ImageNet dataset and can generate a 1280-dimensional feature vector for each input image of size (224, 224, 3). This feature vector can be used for indexing and categorizing the paintings in your collection. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Create a Keras model for feature extraction\nmodel = tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224, 224, 3), output_shape=(1280,), trainable=False)])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction from images", "api_name": "imagenet-mobilenet_v2_100_224-feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "[batch_size, 224, 224, 3]", "output_shape": "[batch_size, 1280]"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=(224, 224, 3),\n                   output_shape=(1280,),\n                   trainable=False)\n])", "performance": {"dataset": "ImageNet", "accuracy": "71.9%"}, "description": "This API provides a feature vector for images using the MobileNetV2 architecture trained on the ImageNet dataset. The input images should have shape (224, 224, 3), and the output feature vector has 1280 dimensions. The model is available on TensorFlow Hub and can be used for transfer learning applications."}}
{"code": "###Instruction: Calculate the similarity between two paragraphs of text using embeddings.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: In order to calculate the similarity between two paragraphs, you can load the Universal Sentence Encoder (USE) from TensorFlow Hub. The USE is a pre-trained model designed to generate embeddings of text. By encoding your two paragraphs into embeddings using this model, you can then compute the similarity between the two embeddings by calculating the cosine similarity or another similarity metric. This will give you a measure of how similar the two paragraphs are.<<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embed text using pre-trained models", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\ntext = ['This is a test sentence.']\nembeddings = embed(text)", "performance": {"dataset": "STS Benchmark", "accuracy": "Pearson correlation coefficient of 0.78"}, "description": "The Universal Sentence Encoder (USE) is a pre-trained model for generating embeddings of text. It is trained on a variety of data sources and can be used for tasks such as semantic similarity and classification."}}
{"code": "###Instruction: I'd like to analyze bird songs to identify their species. I need an audio model that can help me extract features from the recordings.\n###Output: <<<domain>>>: Audio embedding, <<<api_call>>>: model = hub.load('https://tfhub.dev/google/yamnet/1'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained model called YAMNet from TensorFlow Hub, which is used to generate audio embeddings. These embeddings can capture important features from audio data such as bird songs. Once the model is loaded, you can pass the samples and sample rate of the input audio to the model to obtain embeddings, which can then be utilized for species identification. <<<code>>>: import tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/yamnet/1')\n", "api_call": "hub.load('https://tfhub.dev/google/yamnet/1')", "provider": "TensorFlow Hub", "api_data": {"domain": "Audio embedding", "framework": "TensorFlow Hub", "functionality": "Audio embedding generation", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/yamnet/1')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/yamnet/1'\nmodel = hub.load(model_id)\nembeddings = model(samples, sample_rate)", "performance": {"dataset": "YAMNet", "accuracy": "Not specified"}, "description": "This API generates audio embeddings using a pre-trained model from TensorFlow Hub. The model can be loaded with a specified model_id, and embeddings can be extracted for input audio samples."}}
{"code": "###Instruction: Let's create a dog breed classifier and use the pretrained ImageNet MobileNet V2 model to extract dog breed features.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads a pre-trained ImageNet MobileNet V2 model from TensorFlow Hub, which is designed to extract image feature vectors. These feature vectors can then be used to train a classifier for specific tasks, such as dog breed classification. By using the high-level KerasLayer wrapper, you can conveniently integrate the feature extraction model into your own classifier neural network. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=(224, 224, 3),\n                   trainable=False),\n\n    tf.keras.layers.Dense(5, activation='softmax')\n])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction from images", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": ["URL"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                    input_shape=(224, 224, 3),\n                    trainable=False),\n    tf.keras.layers.Dense(5, activation='softmax')\n])", "performance": {"dataset": "ImageNet", "accuracy": "71.9%"}, "description": "A pre-trained image feature vector model based on MobileNet V2 architecture for extracting features from images. The model is trained on ImageNet dataset and has an accuracy of 71.9%."}}
{"code": "###Instruction: Recommend products similar to the given product description. Use a pre-built model to find the semantic similarity with other product descriptions.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder (USE) from TensorFlow Hub. The USE is a pre-trained text embedding model that converts sentences into fixed-size vector representations, which can be used for finding semantic similarity between text inputs. By using this model to embed your product descriptions, you can efficiently calculate similarity scores and recommend products with closely related text descriptions. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Text embedding using a pre-trained model", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow_hub as hub; embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'); embeddings = embed(['Hello, world!', 'Embed text with Universal Sentence Encoder'])", "performance": {"dataset": "various", "accuracy": "N/A"}, "description": "A pre-trained text embedding model that converts sentences into fixed-size vector representations, enabling efficient semantic similarity calculations and other natural language processing tasks."}}
{"code": "### Instruction: Determine which movie reviews are positive/negative by creating a high-dimensional representation of their content.\n### Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder model from TensorFlow Hub. The model is designed to transform text into high-dimensional vectors, making it useful for text classification, semantic similarity, clustering, and other natural language tasks. In this case, it will be employed to generate embeddings for movie reviews. These embeddings can then be used to classify the reviews as either positive or negative. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Load the Universal Sentence Encoder\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Text embedding model", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world'])\nprint(embeddings)", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.80"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: I need to identify the type of food in each picture I have in my album, so I need tensor values of the pretrained model \"imagenet-inception_v3-feature_vector\".\n###Input: {\"url\": \"https://tfhub.dev/google/imagenet/inception_v3/feature_vector/5\"}\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Inception V3 model from TensorFlow Hub, pretrained on the ImageNet dataset, which is used for image classification tasks. The model will assist you in classifying the type of food in each picture in your album. To do so, feed the model with images resized to 299x299 pixels and the model will generate tensor values to predict the categories of the images. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v3/classification/5'\nmodel = hub.load(model_id)\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading pre-trained models for image classification", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v3/classification/5'\nmodel = hub.load(model_id)\n\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(299, 299))\nimage = tf.keras.preprocessing.image.img_to_array(image)\nimage = tf.expand_dims(image, axis=0)\n\npredictions = model(image)\n", "performance": {"dataset": "ImageNet", "accuracy": "Not specified"}, "description": "Load a pre-trained model from TensorFlow Hub for image classification using the Inception V3 architecture."}}
{"code": "###Instruction: I'm building a chatbot and I need to analyze the similarity between pairs of sentences.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder (USE) from TensorFlow Hub. The USE encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks. This model is trained on a variety of data sources and optimized for greater-than-word length text, such as sentences, phrases, or short paragraphs. Once loaded, you can use the USE to embed input sentences and analyze the similarity between pairs of sentences. <<<code>>>: import tensorflow_hub as hub\n# Load the Universal Sentence Encoder\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n# Embed input sentences\nembeddings = embed(['Hello world', 'I am learning how to use the Universal Sentence Encoder'])", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": {"input": "List of sentences"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.8.0"}, "example_code": "import tensorflow_hub as hub; embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'); embeddings = embed(['Hello world', 'I am learning how to use the Universal Sentence Encoder'])", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.78"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks. The model is trained and optimized for greater-than-word length text, such as sentences, phrases, or short paragraphs."}}
{"code": "###Instruction: I captured a photo of an unknown animal, and I want to know the animal's classification.\n###Output: <<<domain>>>: image-classification, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call adds a KerasLayer that uses the MobileNet V2 pre-trained model for image classification from TensorFlow Hub. The model is trained on the ImageNet dataset with 100% depth and an input size of 224x224 pixels. After adding the KerasLayer to your model, you can pass an image to it and get the predicted class of the animal. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nfrom PIL import Image\nimport numpy as np\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\n])\n\n# Load and preprocess the image\nimage = Image.open('path/to/your/image.jpg').resize((224, 224))\ninput_image = np.array(image) / 255.0\ninput_image = np.expand_dims(input_image, axis=0)\n\n# Predict the class of the animal in the image\npredictions = model.predict(input_image)\npredicted_class = np.argmax(predictions[0])\nprint('Predicted class:', predicted_class)", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Image classification using pre-trained model", "api_name": "imagenet_mobilenet_v2_100_224_classification", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": {"url": "https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0", "numpy": ">=1.19.5", "PIL": ">=8.3.2"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nfrom PIL import Image\nimport numpy as np\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\n])\n\nimage = Image.open('path/to/your/image.jpg').resize((224, 224))\ninput_image = np.array(image) / 255.0\ninput_image = np.expand_dims(input_image, axis=0)\n\npredictions = model.predict(input_image)\npredicted_class = np.argmax(predictions[0])\nprint('Predicted class:', predicted_class)", "performance": {"dataset": "ImageNet", "accuracy": "71.8%"}, "description": "A pre-trained image classification model using MobileNetV2 architecture on ImageNet dataset with 100% depth and 224x224 input size."}}
{"code": "###Instruction: We need a way to detect objects on the road like stop signs, other vehicles, and pedestrians in our autonomous vehicle project. Suggest an API that can help us do that.\n###Output: <<<domain>>>: Image object detection, <<<api_call>>>: hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The SSD MobileNet V2 model is a pre-trained object detection model available on TensorFlow Hub. It is capable of identifying and locating objects in images. The model is trained on the COCO dataset, which contains various objects of interest for autonomous vehicle applications, such as stop signs, other vehicles, and pedestrians. By loading this model, you can use it to detect and locate objects in images relevant to your project. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\ndetector = hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')\nimage_tensor = tf.image.decode_image(tf.io.read_file('path/to/image.jpg'))\nimage_tensor = tf.expand_dims(image_tensor, 0)\nresult = detector(image_tensor)\nprint(result)\n", "api_call": "hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image object detection", "framework": "TensorFlow Hub", "functionality": "Identify and locate objects in images", "api_name": "ssd_mobilenet_v2", "api_call": "hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')", "api_arguments": {"input": "Tensor of shape [batch_size, height, width, 3]", "output": "Dictionaries with keys 'detection_boxes', 'detection_classes', 'detection_scores'"}, "python_environment_requirements": {"tensorflow": ">=2.0", "tensorflow_hub": ">=0.12"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\ndetector = hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')\nimage_tensor = tf.image.decode_image(tf.io.read_file('path/to/image.jpg'))\nimage_tensor = tf.expand_dims(image_tensor, 0)\nresult = detector(image_tensor)\nprint(result)", "performance": {"dataset": "COCO", "accuracy": "mAP of 0.22"}, "description": "A pre-trained model for object detection using SSD MobileNet V2 architecture, capable of identifying and locating objects in images."}}
{"code": "###Instruction: Provide a way to set up an image classification system that automates identification of photographs.\n###Output: <<<domain>>>: image-classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the pre-trained MobileNet V2 model from TensorFlow Hub, which has been trained on the ImageNet dataset for image classification. The model is designed to work with input images of size 224x224 pixels and has a depth multiplier of 1.0. Once loaded, you can use this model to automatically classify images by feeding the images into the model and receiving the predicted class labels. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Load the pre-trained MobileNet V2 model for image classification\nclassifier = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\n# Use the model to classify an image (assuming 'image' is a TensorFlow tensor representing your image)\nresult = classifier(image)\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading a pre-trained image classification model", "api_name": "imagenet_mobilenet_v2_100_224_classification", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": ["URL of the pre-trained model"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "", "performance": {"dataset": "ImageNet", "accuracy": "71.9%"}, "description": "Loads a pre-trained MobileNetV2 model for image classification trained on the ImageNet dataset with an input size of 224x224 pixels and a depth multiplier of 1.0."}}
{"code": "###Instruction: I am making an AI chatbot that responds to user messages. I need to create sentence embeddings efficiently.\n###Output: <<<domain>>>: Text preprocessing, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder model from TensorFlow Hub. The model is capable of generating sentence embeddings, which can be used to process text in an efficient manner for use in various natural language processing tasks, such as creating an AI chatbot. Once loaded, the model can take a list of sentences as input and return the corresponding embeddings. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world'])\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text preprocessing", "framework": "TensorFlow Hub", "functionality": "Loading", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["url: https://tfhub.dev/google/universal-sentence-encoder/4"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world'])", "performance": {"dataset": "Various", "accuracy": "Not specified"}, "description": "A text preprocessing API that loads the Universal Sentence Encoder model from TensorFlow Hub for generating sentence embeddings."}}
{"code": "###Instruction: Find a way to showcase the usage of a model to detect objects in a picture taken in a factory to count how many different pieces of equipment are there.\n###Output: <<<domain>>>: Image object detection, <<<api_call>>>: detector = hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the pre-trained Single Shot MultiBox Detector (SSD) with MobileNet V2 model from TensorFlow Hub. This model is used for object detection in images. It can be used to process images taken in a factory and detect various equipment present in the image. By counting the detected equipment, an estimate of the number of different pieces of equipment can be obtained. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\ndetector = hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')\n", "api_call": "hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image object detection", "framework": "TensorFlow Hub", "functionality": "Object detection in images", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'\ndetector = hub.load(model_id)\n\nimage = tf.keras.preprocessing.image.load_img('image.jpg')\nimage = tf.keras.preprocessing.image.img_to_array(image)\nimage = tf.expand_dims(image, axis=0)\n\npredictions = detector(image)\n", "performance": {"dataset": "COCO", "accuracy": "Not specified"}, "description": "A pre-trained object detection model from TensorFlow Hub that can detect objects in images using the Single Shot MultiBox Detector (SSD) with MobileNet V2."}}
{"code": "###Instruction: Convert an image to a feature vector that can be used in content-based image retrieval system.\n###Output: <<<domain>>>: Image Feature Vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads an image feature vector model using the MobileNetV2 architecture, trained on the ImageNet dataset. It's a KerasLayer that can be integrated into your model or used as a standalone feature extractor. Given an image, this layer will convert it into a feature vector (with shape [None, 1280]) that can be used for image retrieval, classification, or other tasks.<<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=(224,224,3), trainable=False)\n])\n\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(224, 224))\ninput_array = tf.keras.preprocessing.image.img_to_array(image)\ninput_array = tf.expand_dims(input_array, 0)\n\nfeatures = model.predict(input_array)", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Extract features from images", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "[None, 224, 224, 3]", "output_shape": "[None, 1280]", "trainable": "False"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.7.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                    input_shape=(224,224,3), trainable=False)\n])\n\n# Load an image and preprocess it\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(224, 224))\ninput_array = tf.keras.preprocessing.image.img_to_array(image)\ninput_array = tf.expand_dims(input_array, 0)\n\n# Get the feature vector\nfeatures = model.predict(input_array)", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained image feature vector model using MobileNetV2 architecture on ImageNet dataset. It can be used to extract features from images for various tasks like image classification, object detection, and image similarity."}}
{"code": "###Instruction: We're working on a travel blogging platform, and we need a way to extract the features of images that users upload.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call obtains a pre-trained image feature vector model based on MobileNetV2 from TensorFlow Hub. The model is designed for efficient feature extraction from images, with an input shape of [224, 224, 3] and an output shape of [1280]. Once the model is loaded, you can process images to extract their features, which can then be used for various purposes in your travel blogging platform, such as image similarity or organization. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nfeature_extractor = hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction", "api_name": "imagenet-mobilenet_v2_100_224-feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "[224, 224, 3]", "output_shape": "[1280]"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.6.0"}, "example_code": "", "performance": {"dataset": "ImageNet", "accuracy": "71.9%"}, "description": "A pre-trained image feature vector model based on MobileNetV2, designed for efficient feature extraction from images."}}
{"code": "###Instruction: Use the embeddings to find cluster seeds for a given set of job descriptions.\n###Output: <<<domain>>>: Text Embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the Universal Sentence Encoder model from TensorFlow Hub. This pre-trained model encodes text into 512-dimensional embeddings using a deep averaging network (DAN). It is useful for a variety of natural language processing tasks such as clustering. By using it to encode job descriptions into high-dimensional vectors, you can find representative cluster seeds for further processing. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional space", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": "input_text", "python_environment_requirements": "tensorflow, tensorflow_hub", "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world'])", "performance": {"dataset": "various", "accuracy": "not specified"}, "description": "A pre-trained model that encodes text into 512-dimensional embeddings using a deep averaging network (DAN). Useful for a variety of natural language processing tasks."}}
{"code": "###Instruction: The manager wants to build a product recommender system based on the types of items in customers\u2019 photos. Determine what each item is in the image.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: To classify items in a photo, you can load the pre-trained Inception V3 model from TensorFlow Hub using the provided model_id. This model has been designed to classify images into various categories based on the objects within a given image. It performs well in image classification tasks using the ImageNet dataset. Once the model is loaded, you can pass an image through it to get the classification output. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Load the Inception V3 model\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v3/classification/5'\nmodel = hub.load(model_id)\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading pre-trained models", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v3/classification/5'\nmodel = hub.load(model_id)", "performance": {"dataset": "ImageNet", "accuracy": "Not specified"}, "description": "Load a pre-trained image classification model from TensorFlow Hub using the model_id"}}
{"code": "###Instruction: Help me find the best matching property images from an image database for a real estate application.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: model = tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224, 224, 3), trainable=False)]), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: To find the best matching property images, we can use a pre-trained Image Feature Vector model like MobileNetV2 from TensorFlow Hub. This model is designed to extract features from images, which can then be compared to identify similar images. By using this model, you can process the property images from your database to generate feature vectors and calculate the similarity between the input image and each database image. Sorting the images based on their similarity scores will help you find the best matches. <<<code>>>: import tensorflow_hub as hub\nimport tensorflow as tf\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224, 224, 3), trainable=False)\n])", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Extract image features", "api_name": "imagenet-mobilenet_v2_100_224-feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "[None, 224, 224, 3]", "output_shape": "[None, 1280]"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224, 224, 3), trainable=False)\n])\n\nimage = tf.random.normal([1, 224, 224, 3])\nfeatures = model(image)", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained image feature vector model using MobileNetV2 architecture on the ImageNet dataset. The model is designed to extract features from images and can be used for various tasks such as image classification, object detection, and image similarity."}}
{"code": "###Instruction: I have a dataset of photos, and I need to classify all of those photos into different categories, so I'm thinking of using a pre-trained model.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: You can use the pre-trained MobileNetV2 model from TensorFlow Hub for classifying your photos. This model has been trained on the ImageNet dataset and is optimized for image classification tasks. By loading the model with the given API call, you can then preprocess your images and make predictions on the categories they belong to. The model's classification accuracy is 71.8% on the ImageNet dataset. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading a pre-trained model", "api_name": "imagenet_mobilenet_v2_100_224_classification", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": {"url": "https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4"}, "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\n\n# Load and preprocess an image\nimage = tf.keras.preprocessing.image.load_img('path/to/your/image.jpg', target_size=(224, 224))\ninput_array = tf.keras.preprocessing.image.img_to_array(image)\ninput_array = tf.expand_dims(input_array, 0)\ninput_array /= 255.0\n\n# Make predictions\npredictions = model(input_array)\n\n# Decode predictions to class names\nclass_names = tf.keras.applications.mobilenet_v2.decode_predictions(predictions.numpy())", "performance": {"dataset": "ImageNet", "accuracy": "71.8%"}, "description": "A pre-trained image classification model using MobileNetV2 architecture and trained on ImageNet dataset."}}
{"code": "###Instruction: Find objects in city surveillance camera images and get the objects with their corresponding detection scores.\n###Output: <<<domain>>>: image-object-detection, <<<api_call>>>: hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API loads the pre-trained SSD MobileNet V2 model from TensorFlow Hub, used for object detection in images. By passing an image to the detector, you receive detected objects along with their bounding boxes, class labels, and associated confidence scores. You can then process these scores and objects as needed for a city surveillance scenario. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'\ndetector = hub.load(model_id)\n\n# Assuming `input_image` is a preprocessed TensorFlow tensor representing the surveillance image\noutput = detector(input_image)\n\nnum_detections = int(output[\"num_detections\"])\ndetection_scores = output[\"detection_scores\"]\ndetection_class_entities = output[\"detection_class_entities\"]\n\nfor i in range(num_detections):\n    if detection_scores[i] > 0.5:\n        print(\"Detected object:\", detection_class_entities[i], \"with confidence:\", detection_scores[i])", "api_call": "hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image object detection", "framework": "TensorFlow Hub", "functionality": "Detect objects in images", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')", "api_arguments": [{"name": "model_id", "type": "string", "description": "The ID of the model to load from TensorFlow Hub"}], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'\ndetector = hub.load(model_id)\n\n# Load an image, preprocess it, and run the detector\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg')\ninput_image = tf.keras.preprocessing.image.img_to_array(image)\ninput_image = tf.image.resize(input_image, (300, 300))\ninput_image = tf.expand_dims(input_image, 0)\n\n# Run the detector\noutput = detector(input_image)\n\n# Process the output\nfor i in range(output['num_detections']):\n    if output['detection_scores'][i] > 0.5:\n        print('Detected object:', output['detection_class_entities'][i], 'with confidence:', output['detection_scores'][i])", "performance": {"dataset": "COCO", "accuracy": "mAP@0.5IOU"}, "description": "A pre-trained object detection model that can detect objects in images using TensorFlow Hub"}}
{"code": "###Instruction: Compare news articles for similarity and rank them.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the Universal Sentence Encoder model from TensorFlow Hub, which is a text embedding model designed to encode text into high-dimensional vectors. These vectors can be used for various natural language tasks, including comparing documents for similarity. Using the embeddings for your news articles, you can compute the cosine similarity between any two vectors to determine their similarity and rank them accordingly. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "embeddings = embed(['Hello world'])", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.803"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: We have some random images and we would like to classify them into different categories based on their context.\n###Output: <<<domain>>>: Image-classification, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the pre-trained MobileNet V2 model from TensorFlow Hub, which has been trained on the ImageNet dataset for classification. The model can identify various categories based on the context of an input image. Once loaded, it creates a KerasLayer with the loaded model that can be used to classify images into different categories. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading pre-trained models", "api_name": "imagenet_mobilenet_v2_100_224_classification", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": {"url": "https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4"}, "python_environment_requirements": {"tensorflow": "2.x", "tensorflow_hub": "latest"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\n])\n", "performance": {"dataset": "ImageNet", "accuracy": "71.8%"}, "description": "A pre-trained image classification model using MobileNetV2 architecture with 100% depth and 224x224 input size, trained on ImageNet dataset."}}
{"code": "###Instruction: I own a collection of paintings and I need to categorize them based on their depicted object.\n###Output: <<<domain>>>: image-classification, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/inception_v3/classification/5'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the pretrained Inception V3 model for image classification from TensorFlow Hub, which has been trained on the ImageNet dataset. Once loaded, it creates a KerasLayer that enables classifying images based on their depicted objects. This model can be used to categorize the paintings by identifying the main object(s) depicted in them. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Create a model with a single KerasLayer for image classification using Inception V3\nmodel = tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/imagenet/inception_v3/classification/5', input_shape=(299, 299, 3))])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading", "api_name": "inception_v3", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "api_arguments": {"url": "https://tfhub.dev/google/imagenet/inception_v3/classification/5"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\ndata_root = tf.keras.utils.get_file('flower_photos','https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz', untar=True)\nimage_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255)\nimage_data = image_generator.flow_from_directory(str(data_root), target_size=IMAGE_SHAPE)\nfeature_extractor_url = 'https://tfhub.dev/google/imagenet/inception_v3/classification/5'\nfeature_extractor_layer = hub.KerasLayer(feature_extractor_url, input_shape=(299,299,3))\nfeature_extractor_layer.trainable = False\nmodel = tf.keras.Sequential([\n  feature_extractor_layer,\n  tf.keras.layers.Dense(image_data.num_classes, activation='softmax')\n])\nmodel.compile(optimizer=tf.keras.optimizers.Adam(), loss='categorical_crossentropy', metrics=['acc'])\nsteps_per_epoch = np.ceil(image_data.samples/image_data.batch_size)\nhist = model.fit(image_data, epochs=6, steps_per_epoch=steps_per_epoch)", "performance": {"dataset": "ImageNet", "accuracy": "0.779"}, "description": "Inception V3 model for image classification, pretrained on ImageNet dataset."}}
{"code": "###Instruction: I want to create an app that suggests dog breeds based on the images uploaded by users. Recommend an API for me to use.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: model = tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/imagenet/inception_v3/classification/5')]), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: You can use the Inception V3 model from TensorFlow Hub for classifying dog breeds. This API call loads a pre-trained Inception V3 model for image classification which can classify images into multiple classes. Since it has been trained on the ImageNet dataset, it can recognize different dog breeds effectively. Incorporate this model into your app by loading it as a Keras layer in your TensorFlow model. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/imagenet/inception_v3/classification/5')])\n", "api_call": "tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/imagenet/inception_v3/classification/5')])", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading pre-trained models", "api_name": "model_id", "api_call": "tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/imagenet/inception_v3/classification/5')])", "api_arguments": {"handle": "string", "trainable": "boolean (optional)"}, "python_environment_requirements": {"tensorflow": ">=2.0", "tensorflow_hub": ">=0.12"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v3/classification/5'\nmodel = tf.keras.Sequential([hub.KerasLayer(model_id)])\n\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(299, 299))\nimage = tf.keras.preprocessing.image.img_to_array(image)\nimage = tf.keras.applications.inception_v3.preprocess_input(image)\nimage = tf.expand_dims(image, axis=0)\n\npredictions = model.predict(image)", "performance": {"dataset": "ImageNet", "accuracy": "0.779"}, "description": "Load a pre-trained Inception V3 model from TensorFlow Hub for image classification."}}
{"code": "###Instruction: Can you help me classify hotel reviews as positive or negative?\n###Output: <<<domain>>>: Text-embedding, <<<api_call>>>: embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder from TensorFlow Hub, a pre-trained model that encodes text into high-dimensional vectors. These embeddings capture the meaning and semantics of the input text, and can be used for a variety of natural language processing tasks, including text classification, semantic similarity, clustering, and beyond. Use the embeddings along with a supervised learning algorithm (such as SVM or logistic regression) to train your classifier for classifying hotel reviews as positive or negative. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nhotel_review_embeddings = embed(hotel_reviews)\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow_hub as hub; embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'); embeddings = embed(['Hello world'])", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.803"}, "description": "A pre-trained model that encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks"}}
{"code": "###Instruction: My kid took a photo of an animal. Please tell me its species.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4', input_shape=(224,224,3)), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the MobileNetV2 model from TensorFlow Hub, which is a pre-trained image classification model with a specified input size of 224x224 pixels. Once the model is loaded, it can be used to classify images into one of the many classes it has been trained on, which includes various animal species. You can provide the photo taken by your kid as input and get the species prediction. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4', input_shape=(224,224,3))\n])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Image classification model", "api_name": "mobilenet_v2_140_224", "api_call": "hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4')", "api_arguments": {"handle": "https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4", "input_shape": "(224, 224, 3)"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4', input_shape=(224,224,3))\n])\n\nimage = tf.keras.preprocessing.image.load_img('path/to/your/image.jpg', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, 0)\n\npredictions = model.predict(image_array)\n", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained image classification model using MobileNetV2 architecture with input size of 224x224 pixels."}}
{"code": "###Instruction: I have images of food items and I need help categorizing them as per the ImageNet categories.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')]), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads a pre-trained MobileNet V2 image classification model from TensorFlow Hub. The model is pre-trained on the ImageNet dataset, which includes various food items. It takes an input size of 224x224 and has an accuracy of 71.0%. Once loaded, you can apply the model directly to your images to obtain classification predictions for the given ImageNet categories. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Load the pre-trained MobileNet V2 image classification model\nmodel = tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')])\n", "api_call": "tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')])", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading", "api_name": "imagenet_mobilenet_v2_100_224_classification", "api_call": "tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')])", "api_arguments": {"handle": "https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4"}, "python_environment_requirements": {"tensorflow": "2.x", "tensorflow_hub": "0.12.0"}, "example_code": "", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained image classification model using MobileNetV2 architecture on ImageNet dataset with 100% depth and 224x224 input size."}}
{"code": "###Instruction: Recommend the most relevant workout exercises based on a given image.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads a pre-trained image feature vector model using the MobileNet V2 architecture with 100% depth and 224x224 input size. This model can be utilized for transfer learning to extract meaningful features from images and fine-tune on a specific classification task, such as recommending relevant workout exercises based on the given image. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   trainable=False),\n    tf.keras.layers.Dense(1)])\nmodel.build([None, 224, 224, 3])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Loading and using a pre-trained image feature vector model", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"handle": "https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4", "trainable": "False"}, "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   trainable=False),\n    tf.keras.layers.Dense(1)])\n\nmodel.build([None, 224, 224, 3])\nmodel.summary()", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained image feature vector model using MobileNet V2 architecture with 100% depth and 224x224 input size. This model can be used for transfer learning to extract meaningful features from images and fine-tune on a specific classification task."}}
{"code": "###Instruction: Let's find the semantic similarity between two sentences for our recommendation system.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder model from TensorFlow Hub, which is used to encode text into high-dimensional vectors. These vectors can then be used for various natural language processing tasks, such as text classification, semantic similarity, clustering, etc. For finding the semantic similarity between two sentences for your recommendation system, you can pass the sentences through the Universal Sentence Encoder to obtain their embeddings and then calculate the similarity using the cosine similarity between the embeddings. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world!'])\nprint(embeddings)", "performance": {"dataset": "STSbenchmark", "accuracy": "0.803"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks. The model is trained and optimized for greater-than-word length text, such as sentences, phrases, or short paragraphs."}}
{"code": "###Instruction: I need to separate different objects in an image, like differentiate the road, house and tree.\n###Output: <<<domain>>>: image-segmentation, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/tensorflow/deeplabv3/1', output_key='SemanticPredictions'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the DeepLabv3 model from TensorFlow Hub, which is an image segmentation model designed to assign semantic labels to every pixel in an input image. The model is based on the DeepLabv3 architecture and has been trained on the PASCAL VOC 2012 dataset. The API call creates a KerasLayer with the specified output key 'SemanticPredictions', which can be used to segment the objects in an image, like roads, houses, and trees. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nimage = tf.keras.Input(shape=(None, None, 3), dtype=tf.uint8, name='image_input')\nsegmentation = hub.KerasLayer('https://tfhub.dev/tensorflow/deeplabv3/1', output_key='SemanticPredictions')(image)\nmodel = tf.keras.Model(inputs=image, outputs=segmentation)\n", "api_call": "hub.KerasLayer('https://tfhub.dev/tensorflow/deeplabv3/1', output_key='SemanticPredictions')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image segmentation", "framework": "TensorFlow Hub", "functionality": "Semantic image segmentation", "api_name": "deeplabv3", "api_call": "hub.KerasLayer('https://tfhub.dev/tensorflow/deeplabv3/1', output_key='SemanticPredictions')", "api_arguments": {"input": "A 3-channel image tensor", "output": "A tensor with semantic labels"}, "python_environment_requirements": {"tensorflow": ">=2.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nimage = tf.keras.Input(shape=(None, None, 3), dtype=tf.uint8, name='image_input')\nsegmentation = hub.KerasLayer('https://tfhub.dev/tensorflow/deeplabv3/1', output_key='SemanticPredictions')(image)\nmodel = tf.keras.Model(inputs=image, outputs=segmentation)", "performance": {"dataset": "PASCAL VOC 2012", "accuracy": "82.1% mean intersection-over-union (mIOU)"}, "description": "DeepLabv3 is an image segmentation model for TensorFlow Hub that assigns semantic labels to every pixel of an input image. It is based on the DeepLabv3 architecture and trained on the PASCAL VOC 2012 dataset."}}
{"code": "###Instruction: We want to analyze paintings based on their visual characteristics and need a way to represent them numerically.\n###Output: <<<domain>>>: image-feature-vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=[224, 224, 3]), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call sets up a KerasLayer for the pre-trained MobileNet V2 model from TensorFlow Hub. The model is trained on the ImageNet dataset and is used for feature extraction from images. The input shape is [224, 224, 3], and the output is a 1280-dimensional feature vector. By using this model, you can represent paintings as feature vectors that can be used to analyze their visual characteristics numerically. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Create a model for feature extraction using the pre-trained MobileNet V2 model\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=[224, 224, 3])\n])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Convert images into feature vectors", "api_name": "imagenet-mobilenet_v2_100_224-feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "[None, 224, 224, 3]", "output_shape": "[None, 1280]"}, "python_environment_requirements": {"python_version": "3", "tensorflow_version": ">=2.0.0", "tensorflow_hub_version": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=(224, 224, 3),\n                   output_shape=(1280,))\n])", "performance": {"dataset": "ImageNet", "accuracy": "71.8%"}, "description": "A pre-trained image feature vector model that converts images into a 1280-dimensional feature vector using MobileNetV2 architecture trained on ImageNet dataset."}}
{"code": "###Instruction: Our company has a lot of images that we need to categorize into one of 1000 classes. We're looking for a pretrained model that could help.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads a pre-trained image classification model from TensorFlow Hub, specifically the MobileNetV2 model trained on the ImageNet dataset. This model can classify images into one of 1000 different categories. Once loaded, you can use this model to categorize your images by feeding them into the model for prediction. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel_id = 'https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'\nmodel = hub.load(model_id)\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Pre-trained models for image classification", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'\nmodel = hub.load(model_id)\nimage_tensor = tf.image.resize(image, (224, 224))\npredictions = model(image_tensor)", "performance": {"dataset": "ImageNet", "accuracy": "Top-1 Accuracy: 71.0%, Top-5 Accuracy: 90.1%"}, "description": "A pre-trained image classification model using TensorFlow Hub that can classify images into 1000 different categories. The model is based on the MobileNetV2 architecture and has been trained on the ImageNet dataset."}}
{"code": "### Instruction: Our team is working on identifying objects in images. We need a pre-trained model for this task.\n### Output: <<<domain>>>: Image-Classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the pre-trained MobileNet v2 model for image classification from TensorFlow Hub. The model is trained on the ImageNet dataset and accepts image input of size 224x224 pixels. It outputs a 1001-element vector of logits that represents the predicted class probabilities for the given image. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Load the pre-trained MobileNet v2 model for image classification\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading pre-trained model", "api_name": "imagenet_mobilenet_v2_130_224_classification", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')", "api_arguments": {"url": "https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.11.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')", "performance": {"dataset": "ImageNet", "accuracy": "0.919"}, "description": "This module uses the MobileNet v2 architecture for image classification, pre-trained on the ImageNet dataset. The model accepts image input of size 224x224 pixels and outputs a 1001-element vector of logits."}}
{"code": "###Instruction: I have a collection of images and I need to categorize them. Please generate predictions using a pre-trained model.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4', output_shape=[1001]), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads a pre-trained MobileNetV2 model for image classification from TensorFlow Hub. The MobileNetV2 model is lightweight and trained on the ImageNet dataset. Using this model, you can generate predictions for your collection of images and categorize them according to their respective classes. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4', output_shape=[1001])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading pre-trained models", "api_name": "mobilenet_v2", "api_call": "hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4')", "api_arguments": {"handle": "https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4", "output_shape": "[1001]"}, "python_environment_requirements": {"tensorflow": "2.0", "tensorflow_hub": "0.7"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4', output_shape=[1001])\n\n# Load an image\nimage = tf.keras.preprocessing.image.load_img('path/to/your/image.jpg', target_size=(224, 224))\nimage = tf.keras.preprocessing.image.img_to_array(image)\nimage = tf.keras.applications.mobilenet_v2.preprocess_input(image)\nimage = tf.expand_dims(image, 0)\n\n# Make predictions\npredictions = model(image)\n\n# Decode predictions\ndecoded_predictions = tf.keras.applications.mobilenet_v2.decode_predictions(predictions.numpy(), top=5)\n\nfor i, (imagenet_id, label, score) in enumerate(decoded_predictions[0]):\n    print('{}. {}: {:.2f}%'.format(i + 1, label, score * 100))", "performance": {"dataset": "ImageNet", "accuracy": "71.8%"}, "description": "MobileNetV2 is a lightweight deep learning model for image classification. It is pre-trained on the ImageNet dataset and can be loaded using TensorFlow Hub."}}
{"code": "###Instruction: A user wants to know how many objects are in an image they have taken with their phone. Calculate the count by processing the image.\n###Output: <<<domain>>>: Image object detection, <<<api_call>>>: detector = hub.load('https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads a pre-trained TensorFlow model for object detection using the Faster R-CNN architecture with Inception ResNet V2. This model can detect multiple objects within an image. Once the model is loaded, it can be used to process the image taken by the user and count the number of detected objects. <<<code>>>: import tensorflow_hub as hub\ndetector = hub.load('https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1')\n", "api_call": "hub.load('https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image object detection", "framework": "TensorFlow Hub", "functionality": "Object detection in images", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nmodel_id = 'https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1'\ndetector = hub.load(model_id)\nimage = tf.image.decode_jpeg(tf.io.read_file('image.jpg'))\nresult = detector(image[np.newaxis, ...])", "performance": {"dataset": "OpenImages V4", "accuracy": "Not specified"}, "description": "Detect objects in an image using TensorFlow Hub and the Faster R-CNN model with Inception ResNet V2"}}
{"code": "###Instruction: Create a program that alerts the user when a dog is at the door, by identifying the dogs in the pictures from a live webcam feed.\n###Output: <<<domain>>>: Image object detection, <<<api_call>>>: detector = hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/fpnlite_640x640/1'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained object detection model called SSD Mobilenet V2 from TensorFlow Hub. The model can detect multiple objects in images and has been trained on the COCO dataset. By using this model, you can create a program that processes live webcam feed and identifies dogs in pictures. If a dog is detected near the door, the program can alert the user. <<<code>>>: import tensorflow_hub as hub\ndetector = hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/fpnlite_640x640/1')\n", "api_call": "hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/fpnlite_640x640/1')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image object detection", "framework": "TensorFlow Hub", "functionality": "Object detection in images", "api_name": "ssd_mobilenet_v2", "api_call": "hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/fpnlite_640x640/1')", "api_arguments": {"image": "Input image tensor", "num_detections": "Number of detected objects", "detection_boxes": "Bounding boxes for detected objects", "detection_classes": "Class labels for detected objects", "detection_scores": "Confidence scores for detected objects"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.6.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\ndetector = hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/fpnlite_640x640/1')\n\n# Preprocess image\ninput_image = tf.image.resize(image, (640, 640))\ninput_image = tf.expand_dims(input_image, axis=0)\n\n# Run detector\noutput = detector(input_image)\n\n# Extract results\nnum_detections = output['num_detections'].numpy()\ndetection_boxes = output['detection_boxes'].numpy()\ndetection_classes = output['detection_classes'].numpy()\ndetection_scores = output['detection_scores'].numpy()", "performance": {"dataset": "COCO", "accuracy": "mAP 0.32"}, "description": "A pre-trained object detection model based on the SSD Mobilenet V2 architecture, capable of detecting multiple objects in an image. The model is trained on the COCO dataset and achieves a mean Average Precision (mAP) of 0.32."}}
{"code": "###Instruction: I want to analyze a group of sentences, find if there are similar ones so that I can group them together. Help me get embeddings for these sentences.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder model from TensorFlow Hub. The model is designed to convert text into high-dimensional vectors. These vectors can be used for various natural language processing tasks including text classification, semantic similarity, and clustering. By using this model, you can get embeddings for a group of sentences and then perform similarity analysis to group similar sentences together. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": {"input": "List of strings"}, "python_environment_requirements": {"tensorflow": "2.0.0", "tensorflow_hub": "0.8.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world', 'This is a test'])", "performance": {"dataset": "STS Benchmark", "accuracy": "Pearson correlation coefficient of 0.78"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: Are there any good pretrained image classifiers? I want to try one on this image and get top 5 predictions.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: Yes, there are pre-trained image classifiers available. One example is the Inception V3 model from TensorFlow Hub, which has been trained on the ImageNet dataset. You can load this model using the provided API call, and then use it to classify your image. To get the top 5 predictions, sort the model's output probabilities and select the top 5 classes. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Pre-trained image classification models", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow-hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v3/classification/5'\nmodel = hub.load(model_id)\n\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(299, 299))\ninput_image = tf.keras.preprocessing.image.img_to_array(image)\ninput_image = tf.expand_dims(input_image, 0)\n\npredictions = model(input_image)\n", "performance": {"dataset": "ImageNet", "accuracy": "0.779"}, "description": "This API provides pre-trained image classification models using TensorFlow Hub for various architectures like Inception V3, MobileNet, and others. These models are trained on the ImageNet dataset and can be used for transfer learning or fine-tuning on custom datasets."}}
{"code": "###Instruction: We are creating an app to recognize different dog breeds. I need to find a pre-trained model capable of helping me with this task.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the pre-trained MobileNet V2 model from TensorFlow Hub. The model is trained on ImageNet dataset and can be used for feature extraction from images. The model takes 224x224 images as inputs and outputs 1280-dimensional feature vectors. These feature vectors can be helpful in training your dog breed recognition model. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=(224, 224, 3),\n                   trainable=False),\n    tf.keras.layers.Dense(num_classes, activation='softmax')\n])\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\nmodel.fit(train_data, train_labels, epochs=10, validation_data=(val_data, val_labels))\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction", "api_name": "imagenet-mobilenet_v2_100_224-feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"handle": "https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4", "trainable": "False"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=(224, 224, 3),\n                   trainable=False),\n    tf.keras.layers.Dense(num_classes, activation='softmax')\n])\n\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\nmodel.fit(train_data, train_labels, epochs=10, validation_data=(val_data, val_labels))", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained MobileNetV2 model for extracting image feature vectors. The model takes an image of size 224x224 and returns a 1280-dimensional feature vector."}}
{"code": "###Instruction: I am starting an e-commerce platform, and I want to build a feature vector database of different products to identify and categorize them.\n###Output: <<<domain>>>: Image-feature-vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224, 224, 3), trainable=False), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call uses the MobileNet V2 model from TensorFlow Hub to extract feature vectors from your product images. It is pre-trained on the ImageNet dataset, which is useful for various image classification tasks. The model is used as a KerasLayer with the input shape of (224, 224, 3), ideal for your e-commerce platform's image categorization. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224, 224, 3), trainable=False)\n])\n\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, 0)\n\nfeature_vector = model.predict(image_array)\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Extracts feature vectors from images", "api_name": "imagenet-mobilenet_v2", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "(224, 224, 3)", "output_shape": "(1280,)"}, "python_environment_requirements": {"tensorflow": ">=2.0", "tensorflow_hub": ">=0.12"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224, 224, 3), trainable=False)\n])\n\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, 0)\n\nfeature_vector = model.predict(image_array)", "performance": {"dataset": "ImageNet", "accuracy": "Top-1 Accuracy: 71.9%, Top-5 Accuracy: 91.0%"}, "description": "A pre-trained image feature vector model that extracts feature vectors from images using MobileNetV2 architecture. It is trained on the ImageNet dataset and can be used for various image classification tasks."}}
{"code": "###Instruction: I have pictures of animals and I want to identify them by their species.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4')]), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call creates an instance of MobileNetV2 image classification model from TensorFlow Hub, pre-trained on the ImageNet dataset to identify images into 1000 different categories. By adding this Keras layer to your sequential model, you can use it to classify your pictures of animals by their species with high accuracy. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\ntf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4', output_shape=[1001])])\n", "api_call": "tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4')])", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Pre-trained Image Classifier", "api_name": "mobilenet_v2", "api_call": "tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4')])", "api_arguments": {"url": "https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4", "output_shape": "[1001]"}, "python_environment_requirements": {"tensorflow": "2.x", "tensorflow_hub": "0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4', output_shape=[1001])])\nmodel.build([None, 224, 224, 3])", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained image classification model using MobileNetV2 architecture on TensorFlow Hub. It can be used to classify images into 1000 different categories with high accuracy."}}
{"code": "###Instruction: We're creating a database of different foods, and I want to generate feature vectors for each food item from their images.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224,224,3)), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the pretrained MobileNet V2 model from TensorFlow Hub for generating feature vectors from images. The model has been trained on the ImageNet dataset and has an input shape of (224, 224, 3), which is the standard input size for this architecture. By feeding images of food items to this model, it will generate feature vectors representing different characteristics of these food items, which can be useful for various machine learning tasks. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224, 224, 3))\n])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Generate image feature vectors", "api_name": "imagenet-mobilenet_v2_100_224-feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"source": "https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4", "input_shape": "[None, 224, 224, 3]", "output_shape": "[None, 1280]"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=(224,224,3))\n])\n\nimage = tf.keras.preprocessing.image.load_img('example_image.jpg', target_size=(224, 224))\nimage = tf.keras.preprocessing.image.img_to_array(image)\nimage = tf.expand_dims(image, axis=0)\n\nfeature_vector = model(image)", "performance": {"dataset": "ImageNet", "accuracy": "71.9%"}, "description": "A pre-trained model that generates feature vectors from images using MobileNetV2 architecture with 100% depth and 224x224 input size. The model is trained on the ImageNet dataset and achieves 71.9% top-1 accuracy."}}
{"code": "###Instruction: I need to build a customer support chatbot that automatically replies to user queries. How can I represent sentences as numerical vectors for semantic similarity comparison?\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the Universal Sentence Encoder model from TensorFlow Hub, which maps text inputs to high-dimensional numerical vectors (embeddings). The model uses a deep averaging network (DAN) encoder to create 512-dimensional embeddings that can be used for various NLP tasks such as semantic similarity comparisons, which is useful for building a customer support chatbot that matches user queries with appropriate responses. <<<code>>>: import tensorflow_hub as hub\n# Load the Universal Sentence Encoder model\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": {"input": "List of strings"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.8.0"}, "example_code": "import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world!'])", "performance": {"dataset": "STS-Benchmark", "accuracy": "0.803"}, "description": "A deep averaging network (DAN) encoder that maps text inputs to 512-dimensional embeddings. Useful for various NLP tasks such as sentiment analysis, semantic similarity, and document clustering."}}
{"code": "###Instruction: In order to build a dogs versus cats classifier, I need a good feature extractor for images. Can you provide me with one?\n###Output: <<<domain>>>: image-feature-vector, <<<api_call>>>: hub.KerasLayer(\"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4\"), <<<api_provider>>>: TensorFlow Hub, and <<<explanation>>>: This API call uses the MobileNet V2 model from TensorFlow Hub for image feature extraction. The model has been pre-trained on the ImageNet dataset and can be embedded as a KerasLayer into your custom architecture for classification tasks such as dogs versus cats classifier. It takes an input shape of [224, 224, 3] and outputs a feature vector of length 1280. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Create a model with a single KerasLayer for feature extraction\nmodel = tf.keras.Sequential([\n    hub.KerasLayer(\"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4\",\n                   input_shape=(224, 224, 3),\n                   output_shape=[1280],\n                   trainable=False)\n])\n", "api_call": "hub.KerasLayer(\"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4\")", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Extract feature vector from images", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer(\"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4\")", "api_arguments": {"input_shape": "[224, 224, 3]", "output_shape": "[1280]"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.8.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer(\"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4\",\n                   input_shape=(224, 224, 3),\n                   output_shape=[1280],\n                   trainable=False),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "This API provides a pre-trained model to extract feature vectors from images using the MobileNetV2 architecture trained on the ImageNet dataset. It can be used for various image classification tasks and transfer learning."}}
{"code": "###Instruction: Analyze an image we have taken and categorize the primary subject of that image.\n###Output: <<<domain>>>: image-classification, <<<api_call>>>: tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')]), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call creates a pre-trained image classification model using the MobileNet V2 architecture from TensorFlow Hub, which has been trained on the ImageNet dataset. Once loaded, it creates a KerasLayer that can be used to categorize the primary subject in an image. You can then preprocess your image to the correct input size and pass it to the model to get the predicted category. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Load the pre-trained MobileNet V2 model\nmodel = tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')])\n# Prepare the input image (assuming 'path_to_your_image.jpg' is the path to the image you want to classify)\nimage = tf.keras.preprocessing.image.load_img('path_to_your_image.jpg', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, 0)\n# Make predictions using the model\npredictions = model.predict(image_array)", "api_call": "tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')])", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading pre-trained models", "api_name": "imagenet_mobilenet_v2_100_224_classification", "api_call": "tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')])", "api_arguments": {"model_url": "https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4"}, "python_environment_requirements": {"tensorflow": ">=2.0", "tensorflow_hub": ">=0.12"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\n])\n\nimage = tf.keras.preprocessing.image.load_img('path_to_your_image.jpg', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, 0)\n\npredictions = model.predict(image_array)\n", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained image classification model using MobileNetV2 architecture on ImageNet dataset."}}
{"code": "###Instruction: For analyzing customer reviews, I want to convert them into high-dimensional embeddings that we will use for sentiment analysis.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the Universal Sentence Encoder from TensorFlow Hub. This model is designed to convert text input, such as customer reviews, into high-dimensional embeddings. These embeddings can then be used for various natural language processing tasks, including sentiment analysis, by feeding them into a machine learning model. This allows the model to understand and analyze customer sentiments better. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text data for machine learning models", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": {"input": "List of sentences or phrases"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.8.0"}, "example_code": "import tensorflow_hub as hub; embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'); embeddings = embed(['Hello world', 'Embedding sentences with TensorFlow Hub'])", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.78"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks. The model is trained and optimized for greater-than-word length text, such as sentences, phrases or short paragraphs. It is trained on a variety of data sources and a variety of tasks with the aim of dynamically accommodating a wide variety of natural language understanding tasks."}}
{"code": "###Instruction: Please determine which two sentences from a group are semantically similar based on their embeddings.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder model, which encodes text into high-dimensional vectors. These vectors can be used to compare semantic similarity, text classification, clustering, and other natural language tasks. By calculating the cosine similarity or dot product between the embeddings of the sentences, it is possible to determine which two sentences are the most semantically similar. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text data", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": {"input_text": "List of sentences or phrases"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.8.0"}, "example_code": {"import tensorflow as tf": "", "import tensorflow_hub as hub": "", "embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')": "", "sentences = ['This is a test sentence.', 'Another example sentence.']": "", "embeddings = embed(sentences)": "", "print(embeddings)": ""}, "performance": {"dataset": "STSbenchmark", "accuracy": "0.803"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: Given a dataset of images, we need to extract their feature vectors for use in an image search engine application.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/feature_vector/1'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads a pre-trained image feature vector model from TensorFlow Hub designed to extract features from images. It uses a KerasLayer containing the model, which is based on the ImageNet dataset. Once loaded, these features can be used as input for different tasks like image search engines, classification tasks, or object detection, among others. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\ninput = tf.keras.layers.Input(shape=(224, 224, 3))\nfeatures = hub.KerasLayer('https://tfhub.dev/google/imagenet/feature_vector/1', trainable=False)(input)\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/feature_vector/1')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction", "api_name": "imagenet-feature-vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/feature_vector/1')", "api_arguments": {"url": "https://tfhub.dev/google/imagenet/feature_vector/1", "trainable": "False"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\ninput = tf.keras.layers.Input(shape=(224, 224, 3))\nfeatures = hub.KerasLayer('https://tfhub.dev/google/imagenet/feature_vector/1', trainable=False)(input)\nmodel = tf.keras.Model(inputs=input, outputs=features)", "performance": {"dataset": "ImageNet", "accuracy": "N/A"}, "description": "This API provides a pre-trained image feature vector model for extracting features from images using TensorFlow Hub. The model is based on the ImageNet dataset and can be used for various image-related tasks such as classification, detection, and segmentation."}}
{"code": "###Instruction: I want an AI to classify what's inside a photo by loading a pre-trained model from TensorFlow Hub.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: With this API call, you can load a pre-trained image classification model, namely MobileNet V2, from TensorFlow Hub. The model has been trained on the ImageNet dataset and can be used to classify the content inside photos. Once the model is loaded, you can process your images using that model to get accurate classifications. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading pre-trained models", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'\nmodel = hub.load(model_id)\n", "performance": {"dataset": "ImageNet", "accuracy": "Not specified"}, "description": "Load a pre-trained image classification model from TensorFlow Hub using the specified model_id."}}
{"code": "###Instruction: Preserve this art piece in a digital archive. Extract its features for future analysis.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=[224, 224, 3]), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: To extract features from the art piece's image for future analysis, you need to use an image feature vector model such as MobileNet V2 pre-trained on ImageNet. Load the MobileNet V2 model from TensorFlow Hub using the API call, and create a KerasLayer with an input shape of [224, 224, 3]. This layer will extract a high-dimensional feature vector from the input image, allowing you to store these features in a digital archive for future analysis. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Create a model with a single KerasLayer for feature extraction\nmodel = tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=[224, 224, 3])])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction from images", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "[224, 224, 3]", "output_shape": "[1280]"}, "python_environment_requirements": {"tensorflow": ">=2.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "model = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=[224, 224, 3], trainable=False),\n    tf.keras.layers.Dense(num_classes, activation='softmax')\n])", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained image feature vector model based on MobileNetV2 architecture for extracting features from images."}}
{"code": "###Instruction: How can we extract image features to compare the similarity between two interior designs?\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224, 224, 3)), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: To extract image features, you can use the pre-trained MobileNetV2 model from TensorFlow Hub trained on the ImageNet dataset. By creating a sequential Keras model with the MobileNetV2 KerasLayer, you can feed the images of the two interior designs into the model and get their feature vectors. You can then compare the similarity between the feature vectors to determine how similar the interior designs are. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Create a model with a single KerasLayer for feature extraction\nmodel = tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224, 224, 3))])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction from images", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "(224, 224, 3)", "output_shape": "(1280,)"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow-hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224, 224, 3))\n])\n\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, 0)\n\nfeatures = model.predict(image_array)", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained image feature vector model based on MobileNetV2 architecture, which is optimized for performance on mobile devices and other resource-constrained environments. It can be used for various image classification tasks, transfer learning, or as a feature extractor for other models."}}
{"code": "###Instruction: We have a survey containing phrases on the job market. We want to get a visualization of the job market. Can you provide an embedding of the survey phrases?\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: To achieve this, you can use the Universal Sentence Encoder from TensorFlow Hub, which is designed to convert textual input data into high-dimensional vectors. These vectors can then be used to visualize the job market phrases, allowing patterns and trends to be analyzed. Once the Universal Sentence Encoder is loaded, you can pass the survey phrases to it, and the model will generate embeddings for each phrase. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow_hub as hub; embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'); embeddings = embed(['text to embed'])", "performance": {"dataset": "STS", "accuracy": "Pearson correlation coefficient of 0.78"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: Try to identify the object in the image using a pre-trained model built on the TensorFlow Hub platform.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained MobileNet V2 TensorFlow model for image classification from TensorFlow Hub. The model is trained on the ImageNet dataset and takes input images of size 224x224. Once the pre-trained model is loaded, you can use it to classify objects in images by passing the image through the model and obtaining the predicted class label. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\n# Load the pre-trained MobileNet V2 model\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading pre-trained models", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": "URL of the pre-trained model", "python_environment_requirements": "tensorflow, tensorflow_hub", "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\n\nimage = tf.keras.preprocessing.image.load_img('path/to/your/image.jpg', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, 0)\n\npredictions = model(image_array)\n", "performance": {"dataset": "ImageNet", "accuracy": "71.9%"}, "description": "A pre-trained image classification model using MobileNet V2 architecture with 224x224 input size, available on TensorFlow Hub"}}
{"code": "###Instruction: In a warehouse, we would like to use a model to identify items stocked on the shelves by detecting objects in images.\n###Output: <<<domain>>>: Image object detection, <<<api_call>>>: detector = hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: To identify items stocked on the shelves in a warehouse, you can use the pre-trained Single Shot MultiBox Detector (SSD) with the MobileNetV2 backbone, which is available on TensorFlow Hub. This model is designed for object detection in images. Once the model is loaded, you can use it to detect objects in images of the warehouse shelves, helping to identify the stocked items. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'\ndetector = hub.load(model_id)\n\n# Load an image, convert it to an array and perform object detection\nimage = tf.keras.preprocessing.image.load_img('image.jpg')\nimage = tf.keras.preprocessing.image.img_to_array(image)\nresult = detector(image[np.newaxis, ...])", "api_call": "hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image object detection", "framework": "TensorFlow Hub", "functionality": "Object detection in images", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')", "api_arguments": {"model_id": "URL or path to the TensorFlow Hub model"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'\ndetector = hub.load(model_id)\n\nimage = tf.keras.preprocessing.image.load_img('image.jpg')\nimage = tf.keras.preprocessing.image.img_to_array(image)\n\nresult = detector(image[np.newaxis, ...])", "performance": {"dataset": "COCO", "accuracy": "Unknown"}, "description": "A pre-trained TensorFlow Hub model for detecting objects in images using the Single Shot MultiBox Detector (SSD) with MobileNetV2 backbone."}}
{"code": "###Instruction: I have a collection of butterfly images, so please find the image feature vectors for me.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v3_large_100_224/feature_vector/5', input_shape=(224, 224, 3), output_shape=(1280,)), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: To extract feature vectors from butterfly images, you can use this API call. It loads the pre-trained MobileNetV3-Large model for image feature vector generation from TensorFlow Hub. The model is trained on the ImageNet dataset and can handle input images of size 224x224 with 3 channels. Once loaded, it can be used to generate 1280-dimensional feature vectors for your butterfly images. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v3_large_100_224/feature_vector/5', input_shape=(224, 224, 3), output_shape=(1280,))\n])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v3_large_100_224/feature_vector/5')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Generate feature vectors for images", "api_name": "imagenet_mobilenet_v3_large_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v3_large_100_224/feature_vector/5')", "api_arguments": {"input_shape": "(224, 224, 3)", "output_shape": "(1280,)"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v3_large_100_224/feature_vector/5', input_shape=(224, 224, 3), output_shape=(1280,))\n])\n\n# Load an image and preprocess it\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, 0)\n\n# Generate feature vector\nfeature_vector = model.predict(image_array)", "performance": {"dataset": "ImageNet", "accuracy": "75.3%"}, "description": "This API provides a pre-trained image feature vector model, MobileNetV3-Large, from TensorFlow Hub. The model is trained on the ImageNet dataset and can be used to generate feature vectors for images of size 224x224 with 3 channels."}}
{"code": "###Instruction: I need to create a program that finds how similar two given sentences are. To do this, I first want to encode the sentences into high-dimensional vectors.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the Universal Sentence Encoder model from TensorFlow Hub, which can encode text into high-dimensional vectors. Using these vectors, you can perform various natural language tasks, such as measuring the semantic similarity between two sentences. In this case, you will encode both sentences and then calculate the similarity between the resulting vectors. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": {"input": "Text input"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.8.0"}, "example_code": "import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world'])", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.803"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: We need to find similar phrases within a set of sentences. To do this, first, we will encode these sentences into vectors.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the Universal Sentence Encoder model from TensorFlow Hub. This model is designed for converting text, such as sentences or phrases, into high-dimensional vector representations. These vector embeddings can then be used to find similar phrases within the given set of sentences. Using this technique, you can compute the semantic similarity between different phrases. <<<code>>>: import tensorflow_hub as hub\n# Load the Universal Sentence Encoder\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into a high-dimensional vector", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": {"input": "A list of strings"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.8.0"}, "example_code": "import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world!', 'Embedding with TensorFlow Hub'])", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.78"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks. The model is trained and optimized for greater-than-word length text, such as sentences, phrases, or short paragraphs."}}
{"code": "###Instruction: Translate the following English text into a semantic embedding: \"The quick brown fox jumps over the lazy dog.\"\n###Output: <<<domain>>>: Text-embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the Universal Sentence Encoder (USE) model from TensorFlow Hub, which is designed to convert text into high-dimensional vectors. These vectors represent the semantic meaning of the input text, making them suitable for various natural language processing tasks. Input the desired text as a list of sentences to obtain the corresponding embeddings. <<<code>>>: import tensorflow_hub as hub\n\n# Load the Universal Sentence Encoder model\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n\n# Input the text as a list of sentences\ntext = [\"The quick brown fox jumps over the lazy dog.\"]\n\n# Obtain the semantic embeddings of the input text\nembedding = embed(text)", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": {"input": "list of sentences"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.8.0"}, "example_code": "import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['sentence1', 'sentence2'])", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.803"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for various natural language processing tasks. It is pre-trained on a variety of data sources and can be fine-tuned for specific tasks."}}
{"code": "###Instruction: Compare the similarity of the following two sentences: \"The quick brown fox jumps over the lazy dog,\" and \"A speedy reddish-orange mammal leaps over a resting canine.\"\n###Input: \"The quick brown fox jumps over the lazy dog\", \"A speedy reddish-orange mammal leaps over a resting canine.\"\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder from TensorFlow Hub, which is a pre-trained model for encoding text into high-dimensional vectors. These vectors can then be used to calculate the semantic similarity between the two input sentences. The model has a Pearson correlation coefficient of 0.803 on the STS benchmark dataset. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nsentence1 = \"The quick brown fox jumps over the lazy dog\"\nsentence2 = \"A speedy reddish-orange mammal leaps over a resting canine\"\nembeddings = embed([sentence1, sentence2])\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": "input_text", "python_environment_requirements": "tensorflow, tensorflow_hub", "example_code": "import tensorflow_hub as hub; embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'); embeddings = embed(['Hello world!']); print(embeddings)", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.803"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: We would like to use transfer learning for an image classification problem. Extract features from images using a pre-trained feature vector model.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call uses a pre-trained MobileNetV2 image feature vector model available on TensorFlow Hub. The model extracts high-level features from input images (shape: [224, 224, 3]) and outputs feature vectors (shape: [1280]). You can use these feature vectors in the transfer learning process for your image classification problem. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=[224, 224, 3],\n                   output_shape=[1280])\n])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "[224, 224, 3]", "output_shape": "[1280]"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=[224, 224, 3],\n                   output_shape=[1280])\n])\n\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, 0)\n\nfeatures = model.predict(image_array)", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained image feature vector model based on MobileNetV2 architecture, which can be used for image classification or as a feature extractor for transfer learning."}}
{"code": "###Instruction: Calculate the similarity between two sentences for a recommendation system based on the content.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the Universal Sentence Encoder model from TensorFlow Hub. This model encodes text into high-dimensional vectors, which can be used to calculate similarity between sentences. Once the sentences are transformed into embeddings, you can use cosine similarity or another distance metric to compare them and determine how similar they are. This can be useful in building a recommendation system that suggests content based on similarity with user preferences. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": "text input", "python_environment_requirements": "tensorflow, tensorflow_hub", "example_code": "import tensorflow_hub as hub; embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'); embeddings = embed(['Hello world!']); print(embeddings)", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.803"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: Calculate the semantic similarities between the product descriptions of two items I found on an e-commerce site.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder, a model designed to encode text into high-dimensional vectors. The encoder can be used to calculate semantic similarity between two product descriptions by first embedding them into vectors and then comparing these vectors using a similarity metric, such as cosine similarity. The resulting value will indicate how semantically similar the product descriptions are. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Product description 1', 'Product description 2'])", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into a high-dimensional vector", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world'])", "performance": {"dataset": "STS Benchmark", "accuracy": "0.803"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: As we need to find the similarity among the users' reviews, we should preprocess the raw text to remove unwanted characters and get the corresponding text embedding.\n###Output: <<<domain>>>: Text preprocessing, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the Universal Sentence Encoder model from TensorFlow Hub. This model is responsible for converting raw text into high-dimensional vectors, while also preprocessing it by removing unwanted characters. These embeddings can then be used to calculate the similarity among users' reviews. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text preprocessing", "framework": "TensorFlow Hub", "functionality": "Text preprocessing module", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello, world!', 'How are you?'])", "performance": {"dataset": "Multiple", "accuracy": "N/A"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: A real-estate company wants to use computer vision to classify images of homes into multiple categories like 'modern', 'rustic', etc. Provide a suitable API to extract image feature vectors for building the classifier.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call allows loading a pre-trained image feature vector model based on the MobileNet V2 architecture from TensorFlow Hub. This model is trained on the ImageNet dataset and can extract useful features from images to build a custom image classifier. In this case, it can help classify images of homes into different styles like 'modern' or 'rustic'. <<<code>>>: model = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224,224,3)),\n    tf.keras.layers.Dense(num_classes, activation='softmax')\n])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction from images", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "[None, 224, 224, 3]", "output_shape": "[None, 1280]"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "model = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=(224,224,3), trainable=False),\n    tf.keras.layers.Dense(num_classes, activation='softmax')\n])", "performance": {"dataset": "ImageNet", "accuracy": "71.8%"}, "description": "A pre-trained image feature vector model based on MobileNetV2 architecture, which is optimized for mobile and edge devices. It is trained on ImageNet dataset and can be used for various image classification tasks."}}
{"code": "###Instruction: I have a list of customer reviews and want to group them based on their similarity.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder model from TensorFlow Hub. The model is designed to encode text into high-dimensional vectors that can be used for various natural language tasks, including grouping text based on similarity. Once you have embedded the customer reviews into high-dimensional vectors using this model, you can use clustering algorithms to create groups of similar reviews. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": {"input": "List of strings"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world!', 'This is a test sentence'])", "performance": {"dataset": "Various", "accuracy": "Not specified"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks. It is trained on a variety of data sources and a range of tasks."}}
{"code": "###Instruction: Analyze customer feedback and group them into positive and negative sentiments.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: Get embeddings for the input customer feedback using the Universal Sentence Encoder (USE) from TensorFlow Hub. These high-dimensional vectors can then be used for sentiment analysis to classify customer feedback into positive and negative groups. This will help in understanding customers' sentiments and improving the product or service based on the feedback. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world'])", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation of 0.803"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: To classify silhouettes, extract image features with a pre-trained model then build a new classification model.\n###Output: <<<domain>>>: image-feature-vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224, 224, 3)), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads a pre-trained MobileNet V2 model from TensorFlow Hub, which is designed for feature extraction from images. By using this layer, we can extract image features from silhouette images, and use them as input to build a new classification model. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nnum_classes = 'your_number_of_classes_here'\n# Create a model with a KerasLayer for feature extraction and a dense layer for classification\nmodel = tf.keras.Sequential([\n  hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224, 224, 3)),\n  tf.keras.layers.Dense(num_classes, activation='softmax')\n])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "(224, 224, 3)", "output_shape": "(1280,)"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.6.0"}, "example_code": "model = tf.keras.Sequential([\n  hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224, 224, 3)),\n  tf.keras.layers.Dense(num_classes, activation='softmax')\n])", "performance": {"dataset": "ImageNet", "accuracy": "71.9%"}, "description": "A pre-trained image feature vector model based on MobileNetV2 architecture, trained on ImageNet dataset."}}
{"code": "###Instruction: Measure the similarity between two strings, we want it encoded representations.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder model from TensorFlow Hub, which is a text embedding model that maps text inputs to a 512-dimensional vector space. By encoding the two input strings using this model, the similarity between the strings can be measured by calculating the cosine similarity or any other distance metric between their high-dimensional vector representations. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embeddings", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": {"input": "text"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.8.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world!'])", "performance": {"dataset": "STS benchmark", "accuracy": "0.78 Pearson correlation"}, "description": "A text embedding model that maps text inputs to a 512-dimensional vector space."}}
{"code": "###Instruction: I am building a news article clustering application. I need to get the embeddings of each news article to compare their similarity.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder (USE) model from TensorFlow Hub. USE is a pre-trained model designed to encode text, such as sentences or short paragraphs, into high-dimensional vectors. These vectors can be used for various natural language processing tasks, including text classification, semantic similarity, and clustering. In your case, it'll convert the news articles into embeddings and allow you to compare their similarity and perform clustering. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text data", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": {"url": "https://tfhub.dev/google/universal-sentence-encoder/4"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow_hub as hub\n\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world!'])\nprint(embeddings)", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.78"}, "description": "The Universal Sentence Encoder (USE) is a pre-trained model that encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering and other natural language tasks. It is designed for greater-than-word length text like sentences, phrases or short paragraphs."}}
{"code": "###Instruction: Help me find similar images in a large database for a given image.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call provides a feature extractor based on the pre-trained MobileNetV2 model from TensorFlow Hub. It transforms images into compact feature vectors which can be used to find similarity between images. By integrating the feature extractor into a custom Keras model, you can compare images from a large database and identify the most similar ones. <<<code>>>: import tensorflow_hub as hub\n\n# Create a Keras model with the MobileNetV2 extractor layer\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=(224, 224, 3), trainable=False)])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction from images", "api_name": "imagenet-mobilenet_v2_100_224-feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input": "image", "output": "feature_vector"}, "python_environment_requirements": {"tensorflow": ">=2.0", "tensorflow_hub": ">=0.12"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=(224, 224, 3),\n                   trainable=False),\n    tf.keras.layers.Dense(1)\n])\n\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, 0)\n\nfeatures = model.predict(image_array)", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "This API provides a compact representation of an image by extracting feature vectors using MobileNetV2 architecture pretrained on ImageNet dataset. It can be used for tasks like image classification, object detection, and image similarity."}}
{"code": "###Instruction: I want to recognize who is who in my photos, so create a model to turn the photos into vectors first.\n###Output: <<<domain>>>: image-feature-vector, <<<api_call>>>: model = tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/imagenet/inception_v3/feature_vector/5', input_shape=(299,299,3))]), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call constructs a feature extraction model using TensorFlow's Keras API and the Inception V3 architecture. This model, which is pre-trained on the ImageNet dataset, turns images into high-dimensional feature vectors. These feature vectors can be used as inputs for a facial recognition model that will identify people in your photos.<<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/inception_v3/feature_vector/5', input_shape=(299,299,3))\n])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/inception_v3/feature_vector/5')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction", "api_name": "inception_v3", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/inception_v3/feature_vector/5')", "api_arguments": {"input": "image", "output": "feature_vector"}, "python_environment_requirements": {"tensorflow": ">=2.0", "tensorflow_hub": ">=0.12"}, "example_code": "import tensorflow_hub as hub\nimport tensorflow as tf\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/inception_v3/feature_vector/5',\n                   input_shape=(299,299,3))\n])\n\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(299, 299))\nimage = tf.keras.preprocessing.image.img_to_array(image)\nimage = tf.expand_dims(image, 0)\n\nfeatures = model.predict(image)", "performance": {"dataset": "ImageNet", "accuracy": "77.9%"}, "description": "Feature extraction from images using Inception V3 model trained on ImageNet dataset"}}
{"code": "###Instruction: Analyze the pictures animals have taken and sort them into different animal categories. To do this, derive the feature vectors from their images so that I can train a classifier.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call extracts feature vectors from images using the MobileNetV2 architecture, which has been pre-trained on the ImageNet dataset. The feature vectors can be used to create a classifier that can sort the input images into different animal categories. In this case, the feature extraction layer is incorporated into a Keras model for further training and classification tasks. <<<code>>>: import tensorflow_hub as hub\nfeature_extractor = hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224,224,3), trainable=False)\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction from images", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"handle": "https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4", "output_shape": [1280], "trainable": "False"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "model = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=(224,224,3),\n                   trainable=False),\n    tf.keras.layers.Dense(num_classes, activation='softmax')\n])", "performance": {"dataset": "ImageNet", "accuracy": "71.8%"}, "description": "Extracts feature vectors from images using MobileNetV2 architecture pretrained on ImageNet dataset"}}
{"code": "###Instruction: I am creating a question-answering system and need to find the closest matching question in my database to a new user's question. Please provide the embeddings for the questions.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the Universal Sentence Encoder model from TensorFlow Hub. It's used for encoding text into high-dimensional vectors, and in this case, it will be applied to questions. These embeddings can then be used to compute the semantic similarity between a user's question and the questions in the database, allowing the system to provide the best match for the new user's question.<<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world!'])", "performance": {"dataset": "STS benchmark", "accuracy": "0.803"}, "description": "A text embedding model that encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: I took some pictures during my vacation and now I want to create a collection of images and organize them based on image features.\n###Output: <<<domain>>>: image-feature-vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224, 224, 3), output_shape=(1280,)), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call creates a KerasLayer that loads a pre-trained MobileNetV2 model from TensorFlow Hub to extract feature vectors from vacation images. With the input shape of (224, 224, 3) and output shape (1280,), you can load and preprocess images to the required size and perform feature extraction. The resulting feature vectors can then be used to organize your vacation image collection. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\n# Build a model to extract feature vectors\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=(224, 224, 3),\n                   output_shape=(1280,))\n])\n\n# Preprocess image and perform feature extraction\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, 0)\nfeatures = model.predict(image_array)\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction from images", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "(224, 224, 3)", "output_shape": "(1280,)"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=(224, 224, 3),\n                   output_shape=(1280,))\n])\n\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, 0)\n\nfeatures = model.predict(image_array)", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained model for extracting feature vectors from images using MobileNetV2 architecture trained on ImageNet dataset"}}
{"code": "###Instruction: I need to classify plant species using a machine learning model to know which type they are. Can I use this model to classify images of plants?\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: model = hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: Yes, you can use this API call to load a pre-trained TensorFlow model for image classification that uses the Inception V3 architecture. This model is trained on the ImageNet dataset, which includes a variety of plant species categories. It can help you classify images of plants by providing predictions for the species to which they belong. <<<code>>>: import tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "api_arguments": ["model_id"], "python_environment_requirements": "tensorflow, tensorflow_hub", "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v3/classification/5'\nmodel = hub.load(model_id)", "performance": {"dataset": "ImageNet", "accuracy": null}, "description": "Load an image classification model from TensorFlow Hub using the model_id."}}
{"code": "###Instruction: We want to cluster similar product reviews to understand the customer experience better.\n###Output: <<<domain>>>: text-embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the Universal Sentence Encoder from TensorFlow Hub. This pre-trained model generates meaningful text embeddings, which are high-dimensional vectors that represent text data. These embeddings can be used for various natural language tasks, such as text classification, semantic similarity, clustering, and more. Here, embeddings of product reviews can be generated for clustering similar reviews to better understand customer experiences. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\n# Load the Universal Sentence Encoder\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n# Get embeddings for a set of reviews (assuming 'reviews' is a list of review strings)\nembeddings = embed(reviews)\n\n# Perform clustering using your preferred algorithm\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embed text data", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": "URL of the model", "python_environment_requirements": "TensorFlow, TensorFlow Hub", "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello, world!', 'How are you?'])\nprint(embeddings)", "performance": {"dataset": "SNLI, MultiNLI", "accuracy": "86.9% on SNLI, 78.9% on MultiNLI"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: Write a code for embedding the given sentences into high-dimensional vectors to find similarity in their meanings.\n\n###Input: [\"I have a cat.\", \"My pet is a feline.\"]\n\n###Output: <<<domain>>>: text-embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder (USE) model from TensorFlow Hub which is a deep learning model for embedding sentences into high-dimensional vectors. These embedded vectors can be used to find similarity between sentences based on their meanings. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nsentences = [\"I have a cat.\", \"My pet is a feline.\"]\nembeddings = embed(sentences)\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow_hub as hub; embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'); embeddings = embed(['Hello world']); print(embeddings)", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.803"}, "description": "A deep-learning model for embedding text into high-dimensional vectors that can be used for various natural language processing tasks"}}
{"code": "###Instruction: Assist me in creating a model for image classification by extracting features from images.\n###Output: <<<domain>>>: Image-feature-vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', trainable=False), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained image feature vector model from TensorFlow Hub, specifically the MobileNet V2 model that has been trained on the ImageNet dataset. This model can be used to extract features from images which can serve as a base for creating custom image classification models. In the provided example, the model is added as a non-trainable KerasLayer, followed by a Dense layer to perform the classification. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = tf.keras.Sequential([\n  hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', trainable=False),\n  tf.keras.layers.Dense(10, activation='softmax')\n])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction from images", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"handle": "https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4", "trainable": "False"}, "python_environment_requirements": {"tensorflow": ">=2.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n  hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', trainable=False),\n  tf.keras.layers.Dense(10, activation='softmax')\n])", "performance": {"dataset": "ImageNet", "accuracy": "71.9%"}, "description": "This API provides a pre-trained image feature vector model based on MobileNetV2 architecture. It extracts features from images and can be used as a base model for various image classification tasks."}}
{"code": "###Instruction: We are facing an issue while categorizing different plants species in our garden. Could you please assist and identify them for us?\n###Output: <<<domain>>>: Image-classification, <<<api_call>>>: model = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained MobileNetV2 model from TensorFlow Hub for image classification. This model has been trained on the ImageNet dataset and can classify images into various classes. By loading the model, you can process images of plant species in your garden and let the model identify the different species for you. <<<code>>>: import tensorflow_hub as hub\n\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading pre-trained models for image classification", "api_name": "imagenet_mobilenet_v2_130_224_classification", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')", "api_arguments": {"url": "https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow_hub as hub\nimport tensorflow as tf\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')\nimage = tf.zeros([1, 224, 224, 3])  # A batch of images with shape [batch_size, height, width, 3].\nlogits = model(image)  # Logits with shape [batch_size, num_classes].", "performance": {"dataset": "ImageNet", "accuracy": "Not specified"}, "description": "A pre-trained MobileNetV2 model for classifying images using TensorFlow Hub."}}
{"code": "###Instruction: I want to create a custom image classifier for a project but don't want to train a model from scratch. What technology can I leverage to achieve this?\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: You can use the pre-trained image feature vector model built on the MobileNet V2 architecture from TensorFlow Hub. This model has been trained on the ImageNet dataset and can extract high-level features from images. By incorporating this pre-trained model as a hub.KerasLayer in your custom TensorFlow model and adding an appropriate output layer(s) for your task, you can achieve transfer learning, making it easier and faster to train your classifier without needing to train from scratch. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\n# Create a custom model using the pre-trained feature vector model\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=(224, 224, 3), trainable=False),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\n# Compile the custom model\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Extract high-level features from images", "api_name": "imagenet-mobilenet_v2_100_224-feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "[None, 224, 224, 3]", "output_shape": "[None, 1280]", "trainable": "False"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=(224, 224, 3), trainable=False),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained image feature vector model using MobileNetV2 architecture on the ImageNet dataset. It extracts high-level features from images and can be used for tasks like image classification, object detection, and transfer learning."}}
{"code": "###Instruction: We're organizing a car show, and we want to classify the different car models automatically using an application.\n###Output: <<<domain>>>: image-classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the pre-trained Inception V3 model from TensorFlow Hub for image classification. This model, which is trained on the ImageNet dataset, allows you to classify images into different car models. Once loaded, use the model to make predictions on a preprocessed image. The model will return probabilities for each class, and you can obtain the class index with the highest probability using the argmax function. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v3/classification/5'\nmodel = hub.load(model_id)\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(299, 299))\nimage = tf.keras.preprocessing.image.img_to_array(image)\nimage = tf.expand_dims(image, axis=0)\npredictions = model(image)\nclass_index = tf.argmax(predictions, axis=-1).numpy()[0]", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Pre-trained image classification model", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "api_arguments": {"model_id": "URL or path to the TensorFlow Hub model"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.6.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v3/classification/5'\nmodel = hub.load(model_id)\n\n# Load and preprocess an image\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(299, 299))\nimage = tf.keras.preprocessing.image.img_to_array(image)\nimage = tf.expand_dims(image, axis=0)\n\n# Make predictions\npredictions = model(image)\nclass_index = tf.argmax(predictions, axis=-1).numpy()[0]", "performance": {"dataset": "ImageNet", "accuracy": "Top-1: 77.9%, Top-5: 93.7%"}, "description": "A pre-trained image classification model using Inception V3 architecture, trained on ImageNet dataset."}}
{"code": "###Instruction: I want to create an AI-driven customer service chatbot. How can I create a similarity measure for the customer queries and the possible answers?\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: To measure the similarity between customer queries and possible answers, you can use the Universal Sentence Encoder provided by TensorFlow Hub. This model encodes text into high-dimensional vectors, which can then be used for tasks like semantic similarity measurement. Once you load the model, you can transform both the queries and answers into vectors and compute the similarity (e.g. cosine similarity) between them to find the most appropriate answer for each query. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow_hub as hub; embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'); embeddings = embed(['Hello world']); print(embeddings)", "performance": {"dataset": "STS-Benchmark", "accuracy": "Pearson correlation coefficient of 0.803"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks. It is trained and optimized for greater-than-word length text, such as sentences, phrases, or short paragraphs."}}
{"code": "###Instruction: For understanding the contents of user reviews, I would like to transform comments into numerical representations to be utilized in a machine learning model.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder model from TensorFlow Hub. The model is designed to embed text into high-dimensional space, making it suitable for various natural language processing tasks, such as semantic similarity, clustering, and classification. Once the model is loaded, you can use it to transform input text (such as user reviews) into numerical representations, which can be fed into a machine learning model. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Sample review text'])\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional space", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": "input_text", "python_environment_requirements": "tensorflow, tensorflow_hub", "example_code": "import tensorflow_hub as hub; embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'); embeddings = embed(['Hello world!'])", "performance": {"dataset": "Semantic Textual Similarity", "accuracy": "0.8"}, "description": "This API provides a pre-trained model to convert text into high-dimensional space, which can be used for various natural language processing tasks such as semantic similarity, clustering, and classification."}}
{"code": "###Instruction: I need to create chatbot responses for similar questions. Convert these sentences into vectors that can be clustered.\n###Output: <<<domain>>>: text-embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: To convert sentences into vectors that can be clustered, you can use the Universal Sentence Encoder from TensorFlow Hub. This model encodes text into high-dimensional vectors, which can be used for text classification, semantic similarity, and clustering for natural language tasks. Once loaded, you can pass your input sentences to the model to obtain their embeddings. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Load the Universal Sentence Encoder model\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n# Convert input sentences into embeddings (assuming 'sentences' is a list of strings)\nembeddings = embed(sentences)", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into a high-dimensional vector", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world!'])", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.78"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: I want to compare a large image dataset of different car models to suggest visually related recommendations to our users.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call creates a TensorFlow Hub KerasLayer using the MobileNetV2 pre-trained feature vector model, which is designed to extract features from images. You can pass your input images to this KerasLayer, and it will output high-dimensional feature vectors that can be used to compare and recommend visually related car images. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=[224, 224, 3])])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Extract features from images", "api_name": "imagenet-mobilenet_v2_100_224-feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "[224, 224, 3]", "output_shape": "[1280]"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.6.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n  hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=[224, 224, 3])\n])\n\n# Load an image and preprocess it\nimage = tf.keras.preprocessing.image.load_img('path/to/your/image.jpg', target_size=(224, 224))\nimage = tf.keras.preprocessing.image.img_to_array(image)\nimage = tf.expand_dims(image, 0)\n\n# Extract features from the image\nfeatures = model.predict(image)", "performance": {"dataset": "ImageNet", "accuracy": "71.9%"}, "description": "A pre-trained deep learning model that extracts features from images using the MobileNetV2 architecture."}}
{"code": "###Instruction: I am working on a project and I need to find similar images in my dataset. Extract feature vectors of images for comparison.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a Keras layer for the MobileNet_v2_100_224 architecture from TensorFlow Hub. This layer is used for image feature extraction, converting input images of shape [224, 224, 3] into feature vectors of shape [1280]. By using these feature vectors, you can compare and find similar images within your dataset. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=[224,224,3], trainable=False)])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction", "api_name": "imagenet-mobilenet_v2_100_224-feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "[None, 224, 224, 3]", "output_shape": "[None, 1280]"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.8.0"}, "example_code": "model = tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=[224,224,3], trainable=False)])", "performance": {"dataset": "ImageNet", "accuracy": "71.8%"}, "description": "This module uses the MobileNet_v2_100_224 architecture to extract image features. It takes an input image of shape [224, 224, 3] and outputs a feature vector of shape [1280]."}}
{"code": "###Instruction: We need to generate embeddings for product descriptions to cluster similar products together. Get an embedding for each product description.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the Universal Sentence Encoder model from TensorFlow Hub, which is designed to encode text into high-dimensional vectors for various natural language tasks. In this case, the model will generate embeddings for product descriptions. These embeddings can be utilized to cluster similar products together based on their descriptions. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional space", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": {"input": "List of strings"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world!', 'My name is John Doe'])", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.803"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: Capture the most populated areas of a city from aerial images taken from drones.\n###Output: <<<domain>>>: image-object-detection, <<<api_call>>>: hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the pre-trained Single Shot Detector (SSD) MobileNet V2 model from TensorFlow Hub. This model has been trained on the COCO dataset and can be used for detecting objects in images. By loading this model and passing aerial images of a city as input, you can obtain detected objects along with their bounding boxes, class labels, and associated confidence scores to analyze the most populated areas. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Load the SSD MobileNet V2 model\ndetector = hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')\n# Prepare the image (assuming 'image' is a TensorFlow tensor representing your aerial image)\nimage = tf.image.resize(image, (300, 300))\nimage = tf.expand_dims(image, 0)\n# Use the model to detect objects in the aerial image\nresults = detector(image)\n", "api_call": "hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image object detection", "framework": "TensorFlow Hub", "functionality": "Detect objects in images", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')", "api_arguments": {"model_id": "A unique identifier for the pre-trained model"}, "python_environment_requirements": {"tensorflow": ">=2.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'\ndetector = hub.load(model_id)\n\nimage = tf.image.decode_jpeg(tf.io.read_file('path/to/image.jpg'))\nimage = tf.image.resize(image, (300, 300))\nimage = tf.expand_dims(image, 0)\n\nresults = detector(image)\n\nprint(results['detection_boxes'])\nprint(results['detection_classes'])\nprint(results['detection_scores'])", "performance": {"dataset": "COCO", "accuracy": "mAP (mean average precision)"}, "description": "A pre-trained model for detecting objects in images using TensorFlow Hub"}}
{"code": "###Instruction: Determine what objects are visible in a given image.\n###Output: <<<domain>>>: image-classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained image classification model which uses the MobileNetV2 architecture, trained on the ImageNet dataset. Upon loading the model, you can pass an image to it, and the model will return predictions of the objects present in the image. The image needs to be preprocessed before being passed to the model.", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Image classification using pre-trained models", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nmodel_id = 'https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'\nmodel = hub.load(model_id)\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, 0)\nimage_array = tf.keras.applications.mobilenet_v2.preprocess_input(image_array)\npredictions = model(image_array)", "performance": {"dataset": "ImageNet", "accuracy": "71.8%"}, "description": "A pre-trained image classification model using MobileNetV2 architecture on ImageNet dataset."}}
{"code": "###Instruction: We need to build a content-based image search feature on our website.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: model = hub.load('https://tfhub.dev/google/imagenet/inception_v3/feature_vector/1'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the pre-trained Inception V3 model from TensorFlow Hub, which has been trained on the ImageNet dataset. This model is designed to extract image features, which can then be used to build a content-based image search feature on a website. Running an image through this model will generate a feature vector, which can be used to compare with other images and find similar content. <<<code>>>: import tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/imagenet/inception_v3/feature_vector/1')", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/feature_vector/1')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Extract image features", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/feature_vector/1')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v3/feature_vector/1'\nmodel = hub.load(model_id)\nimage = tf.random.normal([1, 299, 299, 3])\nfeatures = model(image)", "performance": {"dataset": "ImageNet", "accuracy": "Not specified"}, "description": "Load a pre-trained image feature vector model from TensorFlow Hub and use it to extract features from an image."}}
{"code": "###Instruction: Find out what's in the picture and recommend related products to customers.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call creates a Keras Layer hosting a pre-trained image feature vector model based on the MobileNet V2 architecture with 100% depth and 224x224 input size. It is a suitable choice for tasks like feature extraction from images, which can be further utilized to perform tasks like recommending related products based on the features extracted from a customer's input image. <<<code>>>: import tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=(224, 224, 3),\n                   output_shape=(1280,))\n])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction", "api_name": "imagenet-mobilenet_v2_100_224-feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "[None, 224, 224, 3]", "output_shape": "[None, 1280]"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=(224, 224, 3),\n                   output_shape=(1280,))\n])", "performance": {"dataset": "ImageNet", "accuracy": "71.9%"}, "description": "A pre-trained image feature vector model based on MobileNet V2 with 100% depth and 224x224 input size. Useful for extracting features from images."}}
{"code": "###Instruction: Calculate the similarity between two sentences using their embeddings. \n###Input: \"The cat is a domestic animal.\", \"The cat is a household pet.\"\n###Output: The similarity score between the two sentences is 0.897.\n###Explanation: First, you load the Universal Sentence Encoder from TensorFlow Hub using the given API call. Then, you pass the two sentences into the encoder to generate their respective embeddings. To compute the similarity between the embeddings, you can use the cosine similarity technique, which measures the cosine of the angle between the two embeddings. The closer the cosine is to 1, the greater the similarity between the sentences. In this case, the similarity score is 0.897, which indicates a high degree of similarity between the two sentences.", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Text embedding model", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "embeddings = embed(['Hello world', 'Embedding with TensorFlow Hub'])", "performance": {"dataset": "Various", "accuracy": "High"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: Can you find the semantic similarity between two sentences for me?", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into a high-dimensional vector", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": "input_text", "python_environment_requirements": "tensorflow, tensorflow_hub", "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world'])\nprint(embeddings)", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.803521"}, "description": "This API provides a method to convert text into a high-dimensional vector using the Universal Sentence Encoder from TensorFlow Hub. It can be used for tasks such as semantic similarity and clustering."}}
{"code": "###Instruction: How can we transform sentences into semantic vectors for a similarity search engine?\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: To transform sentences into semantic vectors for a similarity search engine, you can use the Universal Sentence Encoder from TensorFlow Hub. This encoder takes text input and generates high-dimensional vectors that represent the semantic content of the text. These vectors can then be used to perform similarity calculations and comparisons among different sentences. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello, world!'])", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text for various NLP tasks", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "embeddings = embed(['Hello, world!'])", "performance": {"dataset": "Various", "accuracy": "Not specified"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: Generate a detailed map caption of images captured by a drone over a natural disaster-affected area.\n###Output: <<<domain>>>: image-classification, <<<api_call>>>: model = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained MobileNet V2 model for image classification from TensorFlow Hub, which is trained on the ImageNet dataset. The model has been optimized for low-latency and small size, making it suitable for processing images captured by drones. To generate detailed image captions, you can use this model to classify regions within the images and provide a description based on the identified classes, which will help identify landmarks and disaster-affected areas. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Load the classification model\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading pre-trained models", "api_name": "imagenet_mobilenet_v2_100_224_classification", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": {"url": "https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.6.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\n\ndef predict(image):\n    logits = model(image)\n    return logits", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained MobileNetV2 model for image classification on the ImageNet dataset, with a 224x224 input size and 100% depth multiplier. This model is optimized for low-latency and small size, making it suitable for mobile and edge devices."}}
{"code": "###Instruction: I took a photo of my dog at the park, and I want to know its breed.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: model = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained TensorFlow model for image classification from TensorFlow Hub. The model uses the MobileNet V2 architecture and is trained on the ImageNet dataset. Once the model is loaded, it can be used to classify images into various classes, including dog breeds. To identify your dog's breed, you'll need to preprocess the image and pass it through the model, then decode the predictions to get the breed name. <<<code>>>:\n\nimport tensorflow as tf\nimport tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')\n\n# Load and preprocess the image\nimage = tf.keras.preprocessing.image.load_img('path/to/your/image.jpg', target_size=(224, 224))\nimage = tf.keras.preprocessing.image.img_to_array(image)\nimage = tf.expand_dims(image, 0)\n\n# Run the model\npredictions = model(image)\n\n# Decode the predictions\nclass_names = tf.keras.applications.mobilenet_v2.decode_predictions(predictions, top=1)\nprint(class_names)", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Image recognition", "api_name": "imagenet_mobilenet_v2_130_224_classification", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')", "api_arguments": {"url": "https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.6.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')\n\n# Load and preprocess an image\nimage = tf.keras.preprocessing.image.load_img('path/to/your/image.jpg', target_size=(224, 224))\nimage = tf.keras.preprocessing.image.img_to_array(image)\nimage = tf.expand_dims(image, 0)\n\n# Run the model\npredictions = model(image)\n\n# Decode the predictions\nclass_names = tf.keras.applications.mobilenet_v2.decode_predictions(predictions, top=1)\nprint(class_names)", "performance": {"dataset": "ImageNet", "accuracy": "Not specified"}, "description": "A pre-trained image classification model using MobileNetV2 architecture on the ImageNet dataset."}}
{"code": "###Instruction: Find out what kind of trees are in our park using a pre-trained deep learning model.\n###Output: <<<domain>>>: image-classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained Inception V3 model for image classification from TensorFlow Hub. The model was trained on the ImageNet dataset and has an accuracy of 77.9%. Once loaded, you can preprocess your tree images and use the model to predict the tree species by returning the class labels, which will help you identify the trees found in your park. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Load the pre-trained Inception V3 model\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v3/classification/5'\nmodel = hub.load(model_id)\n# Load image, preprocess it, and make prediction\nimage = tf.keras.preprocessing.image.load_img('path/to/tree_image.jpg', target_size=(299, 299))\nimage = tf.keras.preprocessing.image.img_to_array(image)\nimage = tf.keras.applications.inception_v3.preprocess_input(image)\npredictions = model(tf.expand_dims(image, 0))\n# Decode predictions\nclass_names = tf.keras.applications.inception_v3.decode_predictions(predictions.numpy(), top=5)\nfor class_name in class_names[0]:\n    print(class_name)", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading a pre-trained model", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v3/classification/5'\nmodel = hub.load(model_id)\n\n# Load image and preprocess\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(299, 299))\nimage = tf.keras.preprocessing.image.img_to_array(image)\nimage = tf.keras.applications.inception_v3.preprocess_input(image)\n\n# Make prediction\npredictions = model(tf.expand_dims(image, 0))\n\n# Decode predictions\nclass_names = tf.keras.applications.inception_v3.decode_predictions(predictions.numpy(), top=5)\nfor class_name in class_names[0]:\n    print(class_name)", "performance": {"dataset": "ImageNet", "accuracy": "0.779"}, "description": "This API allows you to load a pre-trained Inception V3 model from TensorFlow Hub for image classification tasks. The model is trained on the ImageNet dataset and achieves an accuracy of 77.9%."}}
{"code": "###Instruction: In order to analyze art pieces, extract and save feature vectors of famous paintings.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call creates a KerasLayer containing the MobileNetV2 model pretrained on the ImageNet dataset. The model is designed to extract feature vectors from images, and it can be used for image analysis tasks like image classification, object detection, and image similarity. In this case, it can be used to extract feature vectors of famous paintings for further analysis. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=[224, 224, 3])\n])\n\n# Load and preprocess the painting image (assuming 'path/to/image.jpg' is the path to the image file)\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, 0)\n\n# Extract and save the feature vector\nfeatures = model.predict(image_array)\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction from images", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "[224, 224, 3]", "output_shape": "[1280]"}, "python_environment_requirements": {"tensorflow": ">=2.0", "tensorflow_hub": ">=0.6.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=[224, 224, 3])\n])\n\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, 0)\n\nfeatures = model.predict(image_array)", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "This API extracts feature vectors from images using the MobileNetV2 model pretrained on the ImageNet dataset. It can be used for tasks like image classification, object detection, and image similarity."}}
{"code": "###Instruction: I would like to create a mobile app to quickly identify the type of tree based on a photo of its leaves.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/2'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained TensorFlow model, MobileNet V2, which focuses on image classification tasks. MobileNet V2 is trained on the ImageNet dataset, but it can be used for transfer learning to fine-tune the model to recognize tree leaves. You can use this pre-trained model as a base for your mobile app and retrain it with further tree leaf images, so it can classify leaf images by tree type effectively. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel_id = 'https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/2'\nmodel = hub.load(model_id)\n", "api_call": "hub.load('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/2')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading pre-trained models", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/2')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nmodel_id = 'https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/2'\nmodel = hub.load(model_id)", "performance": {"dataset": "ImageNet", "accuracy": "Not provided"}, "description": "Load pre-trained image classification models from TensorFlow Hub for transfer learning and fine-tuning."}}
{"code": "###Instruction: A farmer wants to analyze the images of soil to classify the type and quality of soil.\n###Output: <<<domain>>>: image-classification, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained image classification model using the MobileNetV2 architecture trained on the ImageNet dataset. The model can be used to classify images into 1000 different categories. Once loaded as a KerasLayer, you can pass an image to the model to get predicted class labels. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Create a model with a pre-trained image classification layer\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\n])\n# Load an image and preprocess it for model input\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, 0)\n# Get predictions for the image\npredictions = model(image_array)\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Image classification using pre-trained models", "api_name": "imagenet_mobilenet_v2_100_224_classification", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": {"handle": "https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4", "trainable": "False"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow-hub": ">=0.6.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\n])\n\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, 0)\n\npredictions = model(image_array)\n", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained image classification model using MobileNetV2 architecture trained on ImageNet dataset. The model can be used to classify images into 1000 different categories."}}
{"code": "###Instruction: Identify the contents of an image by loading a pretrained model and classify it.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads a pre-trained MobileNet V2 model for image classification from TensorFlow Hub. This enables you to easily input an image and classify it using the model for identifying its contents. The MobileNet V2 model is a lightweight neural network which can effectively classify images based on the ImageNet dataset. <<<code>>>: import tensorflow_hub as hub\nmodel_id = 'https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4'\nmodel = hub.load(model_id)\n", "api_call": "hub.load('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading pre-trained models for image classification", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4'\nmodel = hub.load(model_id)\n\nimage = tf.keras.preprocessing.image.load_img('image.jpg', target_size=(224, 224))\ninput_array = tf.keras.preprocessing.image.img_to_array(image)\ninput_array = tf.expand_dims(input_array, 0)\n\npredictions = model(input_array)\n", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "Load a pre-trained model for image classification from TensorFlow Hub and use it to classify images."}}
{"code": "###Instruction: While traveling, I want to use the API to detect various landmarks and monuments by snapping photos of them with my smartphone.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: model = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained image classification model from TensorFlow Hub using the MobileNet V2 architecture. The model has been trained on the ImageNet dataset, which includes a wide range of object classes, including various landmarks and monuments. Once the model is loaded, it can be used to classify images taken from your smartphone and detect the landmarks and monuments present in the images.  <<<code>>>: import tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5')\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Pre-trained image classification models", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5'\nmodel = hub.load(model_id)\nimage = tf.random.uniform((1, 224, 224, 3))\nprediction = model(image)", "performance": {"dataset": "ImageNet", "accuracy": "Not specified"}, "description": "Load pre-trained image classification models from TensorFlow Hub for various tasks such as object recognition, fine-grained classification, and more."}}
{"code": "###Instruction: Design a system for customer reviews classification based on the level of satisfaction.\n###Output: <<<domain>>>: text-embedding, <<<api_call>>>: embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder model from TensorFlow Hub, which encodes text into high-dimensional vectors. These vectors can be used for tasks such as text classification, semantic similarity, clustering, and other natural language tasks. In this case, the embeddings can be used as input to a classification model that will detect the level of satisfaction in customer reviews. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Load the Universal Sentence Encoder\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n# Obtain embeddings for some input text (assuming 'reviews' is a list of strings containing customer reviews)\nembeddings = embed(reviews)\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world!'])\nprint(embeddings)", "performance": {"dataset": "STS Benchmark", "accuracy": "Pearson correlation coefficient of 0.803"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: Provide me with a way to measure semantic similarity between two input sentences.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the Universal Sentence Encoder model, which is designed to encode text into high-dimensional vectors. These vectors can then be used to measure the semantic similarity between two input sentences. Once the sentences have been transformed into embeddings, you can compute the cosine similarity between the two vectors as a measure of their semantic similarity. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world'])", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.803"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks. The model is trained and optimized for greater-than-word length text, such as sentences, phrases or short paragraphs."}}
{"code": "###Instruction: In the pet store, we discovered an unknown animal. Help us identify the animal.\n###Output: <<<domain>>>: image-classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call uses TensorFlow Hub to load a pre-trained MobileNet V2 image classification model, which can help identify the animal in your image. To use the model, you need to preprocess the input image, converting it to the appropriate size and format, and then pass it through the model to obtain predicted class probabilities. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = \"https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5\"\nmodel = hub.load(model_id)\n\ninput_image = tf.keras.preprocessing.image.load_img(\"path/to/image.jpg\", target_size=(224, 224))\ninput_array = tf.keras.preprocessing.image.img_to_array(input_image)\ninput_batch = tf.expand_dims(input_array, 0)\n\npredictions = model(input_batch)\nprint(predictions)", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Pre-trained models for image classification", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5'\nmodel = hub.load(model_id)\n\ninput_image = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(224, 224))\ninput_array = tf.keras.preprocessing.image.img_to_array(input_image)\ninput_batch = tf.expand_dims(input_array, 0)\n\npredictions = model(input_batch)\nprint(predictions)", "performance": {"dataset": "ImageNet", "accuracy": "Not specified"}, "description": "A pre-trained model for image classification using TensorFlow Hub. This example demonstrates the use of the MobileNet V2 model to classify images."}}
{"code": "###Instruction: We have a set of movie reviews and need to generate embeddings for each review to perform sentiment analysis.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the Universal Sentence Encoder model from TensorFlow Hub, which converts text into high-dimensional vectors. These vectors can then be used for various natural language processing tasks, such as sentiment analysis. By generating embeddings for each movie review, you can analyze the sentiments expressed in the reviews and perform classification or clustering tasks based on the computed embeddings. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text using TensorFlow", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world!'])", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.803"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: Help me load a pre-trained image classification model to categorize fruits for my new dietary app project.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained MobileNet V2 image classification model from TensorFlow Hub. The model is trained on the ImageNet dataset and can be used for a variety of image classification tasks, including categorizing fruits for your dietary app. Once loaded, you can use the model to classify images by passing an image tensor to the model. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'\nmodel = hub.load(model_id)\n# Use the model to classify an image (assuming 'image_tensor' is a TensorFlow tensor representing your image)\nresult = model(image_tensor)", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Pre-trained image classification models", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'\nmodel = hub.load(model_id)\nresult = model(image_tensor)", "performance": {"dataset": "ImageNet", "accuracy": "Varies depending on the model"}, "description": "TensorFlow Hub provides a variety of pre-trained image classification models that can be easily loaded and used for various image classification tasks. The models are trained on the ImageNet dataset and their performance varies depending on the specific model chosen."}}
{"code": "###Instruction: I have a collection of images from a fashion show, and I want to extract the features of each image to use in a recommendation engine.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224, 224, 3), trainable=False), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call creates a KerasLayer from the MobileNetV2 model trained on the ImageNet dataset, allowing you to extract a 1280-dimensional feature vector from images. This can be used in a recommendation engine to find similar images based on their features. To use the model, images need to be preprocessed and resized to the required input format (224 x 224 pixels) before being passed through the model.<<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224, 224, 3), trainable=False)\n])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Extract features from images", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "[batch_size, height, width, 3]", "output_shape": "[batch_size, 1280]"}, "python_environment_requirements": {"tensorflow": ">=2.0", "tensorflow_hub": ">=0.12"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=(224, 224, 3),\n                   trainable=False)\n])\n\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_batch = tf.expand_dims(image_array, 0)\n\nfeatures = model.predict(image_batch)", "performance": {"dataset": "ImageNet", "accuracy": "71.9%"}, "description": "Extracts a 1280-dimensional feature vector from images using the MobileNetV2 architecture trained on the ImageNet dataset."}}
{"code": "###Instruction: I am working on analyzing customer reviews of a product, and I want to represent the text data in a way that is easy to work with. What is an API to efficiently convert textual data into numerical representations?\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The Universal Sentence Encoder is a model that allows you to convert text data into high-dimensional vectors or numerical representations. It is particularly useful for tasks like text classification, semantic similarity, clustering, and other natural language tasks. By encoding the customer reviews into these high-dimensional vectors, you can analyze them more efficiently. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embed text data", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": "URL of the model", "python_environment_requirements": "tensorflow, tensorflow_hub", "example_code": "import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world!'])", "performance": {"dataset": "STS benchmark", "accuracy": "0.803"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: We are developing an article recommendation system. Preprocess the following article title: \"Latest Advances in Artificial Intelligence and Machine Learning\".\n###Input: Latest Advances in Artificial Intelligence and Machine Learning\n###Output: <<<domain>>>: Text preprocessing, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the Universal Sentence Encoder model from TensorFlow Hub which is a pre-trained text encoder designed to convert text into a 512-dimensional vector. These vectors are useful for various natural language processing tasks, such as developing an article recommendation system. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\ntitle = \"Latest Advances in Artificial Intelligence and Machine Learning\"\nembedding = embed([title])", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text preprocessing", "framework": "TensorFlow Hub", "functionality": "Text preprocessing", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": "input_text", "python_environment_requirements": "tensorflow, tensorflow_hub", "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world!'])\nprint(embeddings)", "performance": {"dataset": "STS benchmark", "accuracy": "pearson correlation coefficient of 0.803"}, "description": "A pre-trained text encoder that converts text into a 512-dimensional vector. Useful for a wide range of natural language processing tasks."}}
{"code": "###Instruction: Imagine you are building a recommendation system that suggests articles to users on a website. To accomplish that, you need an embedding for each article title in order to compare their similarity.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the Universal Sentence Encoder model from TensorFlow Hub. This model is capable of transforming text into high-dimensional vectors, which can be utilized for various natural language processing tasks such as text classification, semantic similarity, and clustering. In this case, embeddings of article titles will be generated, which can be used to compare and measure their similarity for an article recommendation system. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text data", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": {"input_text": "List of sentences or phrases"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.8.0"}, "example_code": {"import tensorflow as tf": "", "import tensorflow_hub as hub": "", "embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')": "", "sentences = ['This is a test sentence.', 'Another example sentence.']": "", "embeddings = embed(sentences)": "", "print(embeddings)": ""}, "performance": {"dataset": "STSbenchmark", "accuracy": "0.803"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: Tell me what kind of flower is in this image by classifying it.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: model = hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call allows you to load a pre-trained Inception V3 model for image classification from TensorFlow Hub. By providing an input image, the model can classify the image and determine the type of flower it contains. The pre-trained model is trained on the ImageNet dataset. As the model is trained on various categories, it can recognize and classify different types of flowers. <<<code>>>: import tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Image classification using pre-trained models", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v3/classification/5'\nmodel = hub.load(model_id)\n\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(299, 299))\ninput_image = tf.keras.preprocessing.image.img_to_array(image)\ninput_image = tf.expand_dims(input_image, 0)\n\npredictions = model(input_image)\n", "performance": {"dataset": "ImageNet", "accuracy": "Not specified"}, "description": "TensorFlow Hub provides pre-trained models for image classification tasks. This example demonstrates how to load a pre-trained Inception V3 model from TensorFlow Hub and use it to classify an image."}}
{"code": "###Instruction: Verify if the following two sentences are related by measuring the semantic similarity: Sentence 1: \"The sky is blue today.\" Sentence 2: \"Today the atmosphere appears azure.\"\n###Input: The sky is blue today. Today the atmosphere appears azure.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The Universal Sentence Encoder is used to encode sentences into fixed-size embedding vectors. By encoding the given sentences, the semantic similarity can be measured, which helps in assessing if the sentences are related or not. <<<code>>>: import tensorflow_hub as hub\n# Load the Universal Sentence Encoder\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n# Embed both sentences\nsentence1_embedding = embed([\"The sky is blue today.\"])\nsentence2_embedding = embed([\"Today the atmosphere appears azure.\"])\n# Compute the similarity as the cosine of the angle between the two embeddings\nsimilarity = tf.reduce_sum(tf.multiply(sentence1_embedding, sentence2_embedding)) / (tf.norm(sentence1_embedding) * tf.norm(sentence2_embedding))", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": {"input": "text"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.8.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world!'])", "performance": {"dataset": "STS benchmark", "accuracy": "0.803"}, "description": "The Universal Sentence Encoder encodes text into a fixed-size embedding vector. It is trained on a variety of data sources and can be used for multiple NLP tasks such as text classification, semantic similarity, and clustering."}}
{"code": "###Instruction: Can you help me find a location of certain objects after providing some images?\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/5'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the pre-trained MobileNet V2 model as a KerasLayer from TensorFlow Hub. The model has been trained on the ImageNet dataset to extract feature vectors from images, which can be used for various image classification tasks. You can add a custom classification head on top of the feature vector and fine-tune the resulting model for your specific object recognition task. Once fine-tuned, the model can be used to identify the location of certain objects in the provided images. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Build the model\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/5',\n                   input_shape=(224, 224, 3),\n                   trainable=False),\n    tf.keras.layers.Dense(10, activation='softmax')\n])\n# Compile and train the model\nmodel.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\nmodel.fit(x_train, y_train, epochs=5)\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/5')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Extracting feature vector from images", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/5')", "api_arguments": {"input_shape": "[224, 224, 3]", "output_shape": "[1280]"}, "python_environment_requirements": {"tensorflow": ">=2.0", "tensorflow_hub": ">=0.12"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/5',\n                   input_shape=(224, 224, 3),\n                   trainable=False),\n    tf.keras.layers.Dense(10, activation='softmax')\n])\n\nmodel.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\nmodel.fit(x_train, y_train, epochs=5)", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained image feature vector model using MobileNetV2 architecture on ImageNet dataset. It can be used for various image classification tasks by adding a classification head on top of the feature vector."}}
{"code": "###Instruction: We need to get image feature vectors and build a simple image classifier for our image dataset.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/inception_v3/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call employs a pre-trained TensorFlow Hub model, InceptionV3, which extracts feature vectors from images. Feature vectors can be used for image recognition and classification tasks. By incorporating the model's feature extractor as a KerasLayer and combining it with additional layers, you can create a classifier for your specific image dataset. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v3/feature_vector/4'\ninputs = tf.keras.Input(shape=(224, 224, 3))\nfeature_extractor = hub.KerasLayer(model_id, trainable=False)(inputs)\noutputs = tf.keras.layers.Dense(1000, activation='softmax')(feature_extractor)\nmodel = tf.keras.Model(inputs=inputs, outputs=outputs)\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/inception_v3/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction from images", "api_name": "model_id", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/inception_v3/feature_vector/4')", "api_arguments": ["model_id", "input_shape", "trainable"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v3/feature_vector/4'\ninputs = tf.keras.Input(shape=(224, 224, 3))\nfeature_extractor = hub.KerasLayer(model_id, trainable=False)(inputs)\noutputs = tf.keras.layers.Dense(1000, activation='softmax')(feature_extractor)\nmodel = tf.keras.Model(inputs=inputs, outputs=outputs)", "performance": {"dataset": "ImageNet", "accuracy": "Not specified"}, "description": "This API allows users to extract feature vectors from images using a pre-trained model from TensorFlow Hub. The feature vectors can then be used for various image recognition and classification tasks."}}
{"code": "###Instruction: My friend sent me a picture of his new dog breed, but I can't recognize it. Can you classify this image for me?\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the MobileNet V2 model from TensorFlow Hub, which is pre-trained on the ImageNet dataset for image classification. Once the model is loaded, you can pass the image to it, and the model will return the probabilities for each class. You can then find the class with the highest probability to identify the dog breed in the image. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\n\n# Load the image and resize it to the required input size for the model (224x224 pixels)\nimage = tf.keras.preprocessing.image.load_img('/path/to/the/image.jpg', target_size=(224, 224))\nimage = tf.keras.preprocessing.image.img_to_array(image)\nimage = tf.expand_dims(image, axis=0)\n\n# Classify the image\nresults = model(image)\npredicted_class = tf.math.argmax(results[0], axis=-1).numpy()\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Image classification using pre-trained models", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": {"model_url": "https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4"}, "python_environment_requirements": {"tensorflow": ">= 2.0.0", "tensorflow_hub": ">= 0.6.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\nimage = tf.keras.preprocessing.image.load_img('path/to/your/image.jpg', target_size=(224, 224))\nimage = tf.keras.preprocessing.image.img_to_array(image)\nimage = tf.expand_dims(image, axis=0)\nresults = model(image)\npredicted_class = tf.math.argmax(results[0], axis=-1).numpy()", "performance": {"dataset": "ImageNet", "accuracy": "71.8%"}, "description": "A pre-trained image classification model using MobileNetV2 architecture, trained on ImageNet dataset, and available on TensorFlow Hub for easy integration."}}
{"code": "###Instruction: We have to recognize a variety of animals and classify them in a zoo, using a lightweight model that can work on mobile phones.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: model = tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')]), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call will load a TensorFlow Hub pre-trained image classification model, known as MobileNetV2. This model can recognize 1000 different categories and is lightweight so that it can be easily utilized on mobile phones. Once the model is imported, you can preprocess an image of size (224, 224) and pass it to the model to predict its class. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')\n])", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Image classification model", "api_name": "imagenet-mobilenet_v2_130_224-classification", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')", "api_arguments": {"handle": "https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4", "output_shape": "[1001]"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')\n])\n\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(224, 224))\ninput_array = tf.keras.preprocessing.image.img_to_array(image)\ninput_array = tf.expand_dims(input_array, 0)\n\npredictions = model.predict(input_array)", "performance": {"dataset": "ImageNet", "accuracy": "0.856"}, "description": "This model is a pre-trained image classification model based on MobileNetV2 architecture. It can classify images into 1000 different categories."}}
{"code": "###Instruction: I've got an article in English, and I'd like to analyze it by clustering similar paragraphs together. How would I go about turning each paragraph of text into a high-dimensional vector?\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: You can use the Universal Sentence Encoder model from TensorFlow Hub to convert each paragraph of text into high-dimensional vectors. This model is designed for various natural language processing tasks, including clustering similar text. After loading the model, you can feed in your paragraphs as a list of text strings, and it will output the corresponding embeddings for each paragraph. You can then use these embeddings for clustering the similar paragraphs. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": "input: List of text strings", "python_environment_requirements": "tensorflow, tensorflow_hub", "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world!', 'I am learning about text embedding'])", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.803"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: Tell me how to build a model using feature extraction from images, for use in a binary classification task.\n###Output: <<<domain>>>: image-feature-vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224, 224, 3), trainable=False), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: To build a model using feature extraction from images, load the pre-trained MobileNet V2 model available on TensorFlow Hub as a KerasLayer, with the provided URL, input_shape (224x224x3), and set the 'trainable' flag to False to prevent fine-tuning from occurring during model training. Next, add a Dense layer with a single output and 'sigmoid' activation function for binary classification. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                  input_shape=(224, 224, 3),\n                  trainable=False),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction from images", "api_name": "imagenet-mobilenet_v2_100_224-feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"url": "https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                  input_shape=(224, 224, 3),\n                  trainable=False),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])", "performance": {"dataset": "ImageNet", "accuracy": "71.9%"}, "description": "A pre-trained model that can be used to extract feature vectors from images using MobileNetV2 architecture with 224x224 input size."}}
{"code": "###Instruction: I work for an art gallery looking for a solution to classify images of our collection by art style.\n###Output: <<<domain>>>: image-feature-vector, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/inception_v3/feature_vector/1'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call helps in loading a pre-trained model from TensorFlow Hub, based on the Inception V3 architecture, which has been trained on the ImageNet dataset. This model can be used to extract feature vectors from images, like those of your art collection, to classify them into different art styles. Once the model is loaded, you can pass an image to it and get back the feature vector. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Load the pre-trained Inception V3 model for feature extraction\nmodule_name = 'https://tfhub.dev/google/imagenet/inception_v3/feature_vector/1'\nmodule = hub.load(module_name)\n# Assuming 'image' is a TensorFlow tensor representing an image from your art collection\nfeatures = module(image)\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/feature_vector/1')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Extract feature vector from images", "api_name": "module_name", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/feature_vector/1')", "api_arguments": ["module_name"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodule_name = 'https://tfhub.dev/google/imagenet/inception_v3/feature_vector/1'\nmodule = hub.load(module_name)\n\nimage = tf.random.uniform((1, 299, 299, 3))\nfeatures = module(image)", "performance": {"dataset": "ImageNet", "accuracy": "Not specified"}, "description": "This API allows you to extract feature vectors from images using a pre-trained model from TensorFlow Hub. The model is based on the Inception V3 architecture and has been trained on the ImageNet dataset."}}
{"code": "###Instruction: I just bought a new drone and I want to capture a street video where I can recognize the types of vehicles approaching.\n###Output: <<<domain>>>: Image object detection, <<<api_call>>>: detector = hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained TensorFlow model for object detection using the SSD MobileNet V2 architecture from TensorFlow Hub. The model can detect and recognize multiple objects in images, including various types of vehicles. Once the model is loaded, it can be used to process the frames captured by your drone's camera to identify the approaching vehicles. <<<code>>>: import tensorflow_hub as hub\ndetector = hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')\n", "api_call": "hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image object detection", "framework": "TensorFlow Hub", "functionality": "Detect objects in images", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nmodel_id = 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'\ndetector = hub.load(model_id)\n\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg')\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\ninput_image = tf.expand_dims(image_array, 0)\n\nresult = detector(input_image)\n", "performance": {"dataset": "COCO", "accuracy": "Unknown"}, "description": "A pre-trained TensorFlow Hub model for detecting objects in images using the SSD MobileNet V2 architecture."}}
{"code": "###Instruction: I want to measure the similarity between two images.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.load('https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the pre-trained MobileNetV2 model from TensorFlow Hub, which generates feature vectors from input images. You can use these feature vectors for various applications, such as image classification, object detection, or measuring image similarity. Once loaded, pass the image tensors through the model to get their respective feature vectors, and then compare the feature vectors' similarity using a similarity measure like cosine similarity. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Load the pre-trained MobileNetV2 model from TensorFlow Hub\nmodel = hub.load('https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4')\nimage_tensor1 = tf.constant(...)  # Replace with your first image tensor\nimage_tensor2 = tf.constant(...)  # Replace with your second image tensor\n# Get the feature vectors for the two images\nfeature_vector1 = model(image_tensor1)\nfeature_vector2 = model(image_tensor2)\n", "api_call": "hub.load('https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Generate feature vectors from images", "api_name": "image_feature_vector", "api_call": "hub.load('https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4')", "api_arguments": {"input": "image_tensor", "output": "feature_vector"}, "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = hub.load('https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4')\nimage_tensor = tf.zeros([1, 224, 224, 3])\nfeature_vector = model(image_tensor)", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained image feature vector model using MobileNetV2 architecture on TensorFlow Hub. It generates feature vectors from input images for various applications like image classification, object detection, and image similarity."}}
{"code": "###Instruction: Provide me with a tool to create an image classifier by extracting features from images in a dataset.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call provides a pre-trained MobileNetV2 model for extracting image features from TensorFlow Hub. The model accepts images of size 224x224 and returns a 1280-dimensional feature vector. This feature vector can be used to create a custom image classifier that can be fine-tuned for specific classification tasks. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', trainable=False),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Extract image features", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"url": "https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4", "trainable": "False"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', trainable=False),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])", "performance": {"dataset": "ImageNet", "accuracy": "71.9%"}, "description": "This API provides a pre-trained MobileNetV2 model for extracting image features. It takes an input image of size 224x224 and returns a 1280-dimensional feature vector."}}
{"code": "###Instruction: Figure out a way to extract valuable features from images of potential clients' products to compare their similarity.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call fetches a Keras layer that is pre-trained with the MobileNetV2 model on the ImageNet dataset. The layer extracts valuable features from images, which is helpful in comparing similarities between images. To use this model, ensure that the input images are resized to 224x224 dimensions. After extracting the features, a similarity measure can be used to compare them.<<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=(224, 224, 3),\n                   output_shape=(1280,))\n])\n\nimg = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(224, 224))\nimg_array = tf.keras.preprocessing.image.img_to_array(img)\nimg_array = tf.expand_dims(img_array, 0)\n\nfeatures = model.predict(img_array)\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Extract features from images", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "[None, 224, 224, 3]", "output_shape": "[None, 1280]"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.6.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                    input_shape=(224, 224, 3),\n                    output_shape=(1280,))\n])\n\nimg = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(224, 224))\nimg_array = tf.keras.preprocessing.image.img_to_array(img)\nimg_array = tf.expand_dims(img_array, 0)\n\nfeatures = model.predict(img_array)", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "This API provides a feature vector for an image using the MobileNetV2 model trained on ImageNet dataset. The input image should be of size 224x224."}}
{"code": "###Instruction: My personal trainer wants me to analyze my workout form. Can you help me detect my body position in a photo?\n###Output: <<<domain>>>: Image pose detection, <<<api_call>>>: hub.load('https://tfhub.dev/google/movenet/singlepose/lightning/3'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the MoveNet model from TensorFlow Hub, which is designed for efficient and accurate detection of human poses in images. Once the model is loaded, it can be used to detect body positions and provide pose keypoints for the image. This allows you to analyze your workout form based on the keypoints provided by the model. <<<code>>>: import tensorflow_hub as hub\nmovenet = hub.load('https://tfhub.dev/google/movenet/singlepose/lightning/3')\npose_keypoints = movenet(image_tensor)\n", "api_call": "hub.load('https://tfhub.dev/google/movenet/singlepose/lightning/3')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image pose detection", "framework": "TensorFlow Hub", "functionality": "Detect human poses in images", "api_name": "movenet", "api_call": "hub.load('https://tfhub.dev/google/movenet/singlepose/lightning/3')", "api_arguments": {"input": "image_tensor", "output": "pose_keypoints"}, "python_environment_requirements": {"tensorflow": ">=2.5.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow_hub as hub\nmovenet = hub.load('https://tfhub.dev/google/movenet/singlepose/lightning/3')\npose_keypoints = movenet(image_tensor)", "performance": {"dataset": "COCO", "accuracy": "70.6 mAP"}, "description": "MoveNet is a family of pose detection models designed for efficient and accurate detection of human poses in images."}}
{"code": "###Instruction: Can you help me highlight animals in my vacation photographs?\n###Output: <<<domain>>>: Image-object-detection, <<<api_call>>>: loaded_model = hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained object detection model using SSD MobileNet V2 from TensorFlow Hub. The model is trained on the COCO dataset and can detect multiple objects in an image, including animals. It returns their class, bounding box coordinates, and confidence scores. Using this model, you can process your vacation photographs to highlight the detected animals. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nimport numpy as np\n\nmodel_id = 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'\nloaded_model = hub.load(model_id)\n\n# Assuming 'image_np' is a NumPy array representing your vacation photograph\ninput_tensor = tf.convert_to_tensor(image_np)\ninput_tensor = input_tensor[tf.newaxis, ...]\n\noutput_dict = loaded_model(input_tensor)\n\nboxes = output_dict['detection_boxes'][0].numpy()\nscores = output_dict['detection_scores'][0].numpy()\nclasses = output_dict['detection_classes'][0].numpy().astype(np.int32)\n", "api_call": "hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image object detection", "framework": "TensorFlow Hub", "functionality": "Object detection", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'\nloaded_model = hub.load(model_id)\n\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg')\nimage_np = np.array(image)\n\ninput_tensor = tf.convert_to_tensor(image_np)\ninput_tensor = input_tensor[tf.newaxis, ...]\n\noutput_dict = loaded_model(input_tensor)\n\nboxes = output_dict['detection_boxes'][0].numpy()\nscores = output_dict['detection_scores'][0].numpy()\nclasses = output_dict['detection_classes'][0].numpy().astype(np.int32)", "performance": {"dataset": "COCO", "accuracy": "0.320"}, "description": "This API provides a pre-trained object detection model using TensorFlow Hub. The model is based on the SSD MobileNet V2 architecture and is trained on the COCO dataset. It can be used to detect multiple objects in an image and returns their class, bounding box coordinates, and confidence scores."}}
{"code": "###Instruction: Detect objects and their locations on this image I just took of my room.\n###Output: <<<domain>>>: Image object detection, <<<api_call>>>: hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained object detection model (SSD MobileNet V2) from TensorFlow Hub, which can detect and localize objects in images. With the help of this model, you can process an image to find objects and their specific locations. The model is trained on the popular COCO dataset, giving it a good understanding of numerous object classes. <<<code>>>: import tensorflow_hub as hub\ndetector = hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')\nresult = detector(image_tensor)\n", "api_call": "hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image object detection", "framework": "TensorFlow Hub", "functionality": "Object detection and localization", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nmodel_id = 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'\ndetector = hub.load(model_id)\nresult = detector(image_tensor)", "performance": {"dataset": "COCO", "accuracy": "mAP@0.5IOU"}, "description": "A pre-trained object detection model that can detect and localize objects in an image using TensorFlow Hub."}}
{"code": "###Instruction: Create a flower classification model using feature vectors pre-extracted from images.\n###Output: <<<domain>>>: Image Feature Vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=[None, 224, 224, 3]), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained MobileNet V2 model from TensorFlow Hub to extract feature vectors from images. The model, trained on the ImageNet dataset, is used for image classification tasks. By using this KerasLayer with the specified input shape, you can create a custom model to classify flowers based on feature vectors from images. Add a Dense layer for classification and train the model using the appropriate dataset. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224, 224, 3), trainable=False),\n    tf.keras.layers.Dense(5, activation='softmax')\n])\n\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "[None, 224, 224, 3]", "output_shape": "[None, 1280]"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=(224, 224, 3),\n                   trainable=False),\n    tf.keras.layers.Dense(10, activation='softmax')\n])\n\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\n# Train and evaluate the model\n# model.fit(train_images, train_labels, epochs=5)\n# model.evaluate(test_images, test_labels)", "performance": {"dataset": "ImageNet", "accuracy": "71.8%"}, "description": "The MobileNetV2 100 224 feature vector model is a pre-trained neural network that extracts features from images. It is trained on the ImageNet dataset and can be used for various image classification and feature extraction tasks."}}
{"code": "###Instruction: I am running a wildlife conservation project, and I need help to identify different species of animals and their locations in the images taken by camera traps.\n###Output: <<<domain>>>: Image object detection, <<<api_call>>>: detector = hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained object detection model from TensorFlow Hub based on the SSD Mobilenet V2 architecture, which is trained on the COCO dataset. The model can detect multiple objects in an image, including various animal species. By providing images taken by camera traps, the model will return detected objects along with their class labels, bounding boxes, and confidence scores, allowing you to identify the species and their locations in the images. <<<code>>>: import tensorflow_hub as hub\ndetector = hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')\n", "api_call": "hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image object detection", "framework": "TensorFlow Hub", "functionality": "Object detection", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nmodel_id = 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'\ndetector = hub.load(model_id)\nresult = detector(image_tensor)", "performance": {"dataset": "COCO", "accuracy": "Not specified"}, "description": "A pre-trained object detection model that can detect multiple objects in an image. The model is based on the SSD Mobilenet V2 architecture and is trained on the COCO dataset."}}
{"code": "###Instruction: We need to detect spam emails based on their subjects. Retrieve a high-dimensional vector from each email subject to be used for classification.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder model from TensorFlow Hub. This model is designed to encode text into high-dimensional vectors, which can be used for text classification, semantic similarity, clustering, and other natural language tasks. In this case, the model will be used to create high-dimensional vectors from email subjects to be used for spam detection. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world'])", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation of 0.803"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: There are a bunch of user reviews about our new product, and we need assistance categorizing them into different sentiments.\n###Output: <<<domain>>>: text-classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder model from TensorFlow Hub, which encodes text into high-dimensional vectors suitable for use across various natural language tasks. For example, these vectors can be used to classify the sentiment of user reviews by training a classifier on top of the embeddings generated by this model. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello, world!'])", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text classification", "framework": "TensorFlow Hub", "functionality": "Loading", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": {"model_url": "https://tfhub.dev/google/universal-sentence-encoder/4"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.8.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello, world!'])\nprint(embeddings)", "performance": {"dataset": "STSbenchmark", "accuracy": "0.803"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering and other natural language tasks."}}
{"code": "###Instruction: We have images that we want to analyze, and I hope I can find a way to extract features from these images for further analysis.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: model = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the pre-trained MobileNet V2 model from TensorFlow Hub that is trained on the ImageNet dataset. The trained model is designed to extract feature vectors from images. After loading the model, you can pass images through the model to obtain feature vectors that can be used for various machine learning tasks such as image classification, object detection, and more. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Load the pre-trained MobileNet V2 model\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')\n# Load and preprocess an image (assuming 'path/to/your/image.jpg' is the path to your image)\nimage = tf.keras.preprocessing.image.load_img('path/to/your/image.jpg', target_size=(224, 224))\ninput_image = tf.keras.preprocessing.image.img_to_array(image)\ninput_image = tf.expand_dims(input_image, 0)\n# Extract features\nfeatures = model(input_image)\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature vector extraction", "api_name": "imagenet-mobilenet_v2_100_224-feature_vector", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"image_size": "224x224", "input_type": "float32", "output_type": "float32", "batch_size": "variable"}, "python_environment_requirements": {"tensorflow": "2.0", "tensorflow_hub": "0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')\n\n# Load and preprocess an image\nimage = tf.keras.preprocessing.image.load_img('path/to/your/image.jpg', target_size=(224, 224))\ninput_image = tf.keras.preprocessing.image.img_to_array(image)\ninput_image = tf.expand_dims(input_image, 0)\n\n# Extract features\nfeatures = model(input_image)", "performance": {"dataset": "ImageNet", "accuracy": "71.0"}, "description": "This API allows you to extract feature vectors from images using the MobileNetV2 model trained on ImageNet. The feature vectors can be used for various machine learning tasks such as image classification, object detection, and more."}}
{"code": "###Instruction: What is a good way to find the similarity between two sentences?\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: A good way to find the similarity between two sentences is by using the Universal Sentence Encoder from TensorFlow Hub. This pre-trained model encodes sentences into high-dimensional vectors. By calculating the cosine similarity between the embeddings of the sentences, you can determine how similar the sentences are in terms of their meaning. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text using pre-trained models", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": "input_text", "python_environment_requirements": "tensorflow, tensorflow_hub", "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['text to be embedded'])\nprint(embeddings)", "performance": {"dataset": "SQuAD, SNLI, and others", "accuracy": "N/A"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering and other natural language tasks. The model is trained and optimized for greater-than-word length text, such as sentences, phrases or short paragraphs."}}
{"code": "###Instruction: I'm a clothing store owner, and I want to create a recommendation system that suggests similar clothes by comparing their features.\n###Output: <<<domain>>>: image-feature-vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=[224, 224, 3]), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the MobileNet V2 model from TensorFlow Hub, which has been pre-trained on the ImageNet dataset. This model is suitable for feature extraction from images. Once the KerasLayer is created with the specified input shape, it can be used to extract feature vectors from clothing images, allowing you to build a recommendation system that compares the feature vectors to suggest similar items. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Create a model with a single KerasLayer for feature extraction\nmodel = tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=[224, 224, 3])])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction from images", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "[224, 224, 3]", "output_shape": "[1280]"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.6.0"}, "example_code": "model = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=(224,224,3), trainable=False),\n    tf.keras.layers.Dense(num_classes, activation='softmax')\n])", "performance": {"dataset": "ImageNet", "accuracy": "71.9%"}, "description": "A pre-trained image feature vector model using MobilenetV2 architecture trained on ImageNet dataset for extracting features from images."}}
{"code": "###Instruction: I want to build a plant identifier app, and I need to determine the type of plant in a picture taken from the app.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained MobileNetV2 image classification model from TensorFlow Hub, which has been trained on the ImageNet dataset. The model can be used to identify various objects, including plants, in an image taken using your plant identifier app. Using the provided code examples, you can load the model, prepare the input image, and classify the plant species present in the image.<<<code>>>: import tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Pre-trained model for image classification", "api_name": "imagenet-mobilenet_v2_130_224-classification", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')", "api_arguments": {"url": "https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": {"import": ["import tensorflow as tf", "import tensorflow_hub as hub"], "load_model": "model = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')", "prepare_image": ["import numpy as np", "import PIL.Image as Image", "img = Image.open('path/to/your/image.jpg').resize((224, 224))", "img_array = np.array(img) / 255.0", "img_tensor = tf.expand_dims(img_array, 0)"], "classify_image": "predictions = model(img_tensor)"}, "performance": {"dataset": "ImageNet", "accuracy": "Top-1 accuracy: 75.2%, Top-5 accuracy: 92.5%"}, "description": "A pre-trained image classification model using MobileNetV2 architecture on ImageNet dataset."}}
{"code": "###Instruction: Can you please identify whether these two sentenes share a similar meaning or not?\n###Input: \"The quick brown fox jumps over the lazy dog.\", \"A speedy, sly fox leaps over a lounging canine.\"\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder model from TensorFlow Hub. This model is designed to encode text into high-dimensional vectors, in this case, the two input sentences. Once the sentences are transformed into these high-dimensional vectors, or embeddings, you can compute the cosine similarity between them. If the cosine similarity is significantly high, you can infer that the sentences share a similar meaning. <<<code>>>: import tensorflow_hub as hub\n\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nsentence1 = \"The quick brown fox jumps over the lazy dog.\"\nsentence2 = \"A speedy, sly fox leaps over a lounging canine.\"\nembeddings = embed([sentence1, sentence2])\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embed text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": "text_input", "python_environment_requirements": "tensorflow, tensorflow_hub", "example_code": "import tensorflow_hub as hub; embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'); embeddings = embed(['Hello, world!'])", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient > 0.8"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: I want to create a custom image classifier, but first I need to use a pre-trained model to extract features from my dataset images.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call integrates a pre-trained MobileNetV2 model as a KerasLayer for feature extraction. This model is trained on the ImageNet dataset and can be used to extract image features which can then be fed into your custom classifier. The model accepts input images with a shape of (224, 224, 3) and outputs feature vectors with a shape of (1280). <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=[224, 224, 3])\n])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Extract image features", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "[224, 224, 3]", "output_shape": "[1280]"}, "python_environment_requirements": {"tensorflow": ">=2.0", "tensorflow_hub": ">=0.12"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=[224, 224, 3])\n])\n", "performance": {"dataset": "ImageNet", "accuracy": "71.9%"}, "description": "A pre-trained image feature extraction model using MobileNetV2 architecture on ImageNet dataset."}}
{"code": "###Instruction: Recommend a mobile app for automatically classifying images taken by the user.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: You can use the pre-trained MobileNetV2 image classification model available on TensorFlow Hub. This model is trained on the ImageNet dataset and has an accuracy of 71.8%. It is optimized for mobile devices and can be used to classify images taken by users. Load the model using TensorFlow Hub and make predictions by passing in the input images. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\n# Load the pre-trained MobileNetV2 model\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\n\n# Load an image and preprocess it\nimage = tf.keras.preprocessing.image.load_img('path/to/your/image.jpg', target_size=(224, 224))\ninput_image = tf.keras.preprocessing.image.img_to_array(image)\ninput_image = tf.expand_dims(input_image, 0)\n\n# Make a prediction and decode it\npredictions = model(input_image)\nclass_names = tf.keras.applications.mobilenet_v2.decode_predictions(predictions.numpy(), top=1)\nprint(class_names)\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading and running a pre-trained model", "api_name": "imagenet_mobilenet_v2_100_224_classification", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": ["URL of the pre-trained model"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\n\n# Load an image\nimage = tf.keras.preprocessing.image.load_img('path/to/your/image.jpg', target_size=(224, 224))\ninput_image = tf.keras.preprocessing.image.img_to_array(image)\ninput_image = tf.expand_dims(input_image, 0)\n\n# Make a prediction\npredictions = model(input_image)\n\n# Decode the predictions\nclass_names = tf.keras.applications.mobilenet_v2.decode_predictions(predictions.numpy(), top=1)\nprint(class_names)", "performance": {"dataset": "ImageNet", "accuracy": "71.8%"}, "description": "A pre-trained image classification model based on MobileNetV2 architecture, trained on ImageNet dataset, and available on TensorFlow Hub."}}
{"code": "###Instruction: We want to find semantic similarity.\n###Output: <<<domain>>>: text-embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder from TensorFlow Hub, which is a model that encodes text into dense vector representations. These dense vectors can be used to perform various natural language processing tasks, including semantic similarity analysis. Once loaded, you can pass text (or a list of texts) to the encoder to obtain their dense vector representations. <<<code>>>: import tensorflow_hub as hub\n# Load the Universal Sentence Encoder\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n# Compute embeddings for given texts (assuming 'texts' is a list of strings)\nembeddings = embed(texts)\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Convert text into a dense vector representation", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": {"input": "Text or list of texts"}, "python_environment_requirements": {"tensorflow": ">= 2.0", "tensorflow_hub": ">= 0.8"}, "example_code": "import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world!'])", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.78"}, "description": "The Universal Sentence Encoder encodes text into a dense vector representation that can be used for various natural language processing tasks."}}
{"code": "###Instruction: We want to develop a smart surveillance system to monitor intruders. Please help us identify humans present in the images.\n###Output: <<<domain>>>: Image object detection, <<<api_call>>>: model = hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the SSD MobileNet V2 object detection model from TensorFlow Hub. This model is designed for detecting objects in images, including humans. Once the model is loaded, you can feed images of the area that you want to monitor to detect intruders, and process the results to identify any humans present in the images. <<<code>>>: import tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')\n", "api_call": "hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image object detection", "framework": "TensorFlow Hub", "functionality": "Load and use an object detection model", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')", "api_arguments": {"model_id": "The id of the model to be loaded from TensorFlow Hub"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'\nmodel = hub.load(model_id)\n\nimage = tf.image.decode_jpeg(tf.io.read_file('path/to/image.jpg'))\ndetected_objects = model(image[tf.newaxis, ...])", "performance": {"dataset": "COCO", "accuracy": "Unknown"}, "description": "Load and use an object detection model from TensorFlow Hub for detecting objects in images."}}
{"code": "###Instruction: My friends uploaded a collection of photos from our trip, and I want to organize them by identifying what is in each photo.\n\n###Input: <noinput>\n\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the pre-trained TensorFlow model for image classification using the Inception V3 architecture from TensorFlow Hub. The model is trained on the ImageNet dataset and can be used to classify images into one of the many object classes it recognizes. By using this model, you can identify the main object in each photo from your trip, which can be helpful in organizing your photos. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Load the pre-trained Inception V3 model for image classification\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v3/classification/5'\ninception_v3_model = hub.load(model_id)\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading pre-trained models", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v3/classification/5'\nmodel = hub.load(model_id)", "performance": {"dataset": "ImageNet", "accuracy": "Not provided"}, "description": "Load a pre-trained image classification model from TensorFlow Hub for image classification tasks."}}
{"code": "###Instruction: Identify which model is used to encode text for natural language processing tasks like text classification and semantic similarity.\n###Output: <<<domain>>>: Text embedding, <<<api_name>>>: universal-sentence-encoder, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The Universal Sentence Encoder, from TensorFlow Hub, is used to encode text for natural language tasks like text classification and semantic similarity. The encoder converts text into high-dimensional vectors suitable for these tasks. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world!', 'Embedding is fun!'])\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embeds text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["text_input"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world!', 'Embedding is fun!'])", "performance": {"dataset": "SNLI, MultiNLI, and others", "accuracy": "80-90%"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: Calculate the similarity between the following two sentences: \"The quick brown fox jumps over the lazy dog\" and \"The fast auburn fox leapt over the idle canine.\"\n###Input: \"The quick brown fox jumps over the lazy dog\", \"The fast auburn fox leapt over the idle canine.\"\n###Output: To calculate the similarity between the two sentences \"The quick brown fox jumps over the lazy dog\" and \"The fast auburn fox leapt over the idle canine.\", you can use the Universal Sentence Encoder model from TensorFlow Hub. This model transforms the given sentences into their corresponding fixed-size vector representations, and then you can compute the cosine similarity between these vectors to obtain a similarity score. Here is the Python code for doing so:\n\n```python\nimport tensorflow_hub as hub\nimport numpy as np\n\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nsentences = [\"The quick brown fox jumps over the lazy dog\", \"The fast auburn fox leapt over the idle canine.\"]\nembeddings = embed(sentences)\n\ndef cosine_similarity(v1, v2):\n    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n\nsimilarity = cosine_similarity(embeddings[0], embeddings[1])\nprint(similarity)\n```", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Text embedding using a pre-trained model", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow_hub as hub; embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'); embeddings = embed(['Hello, world!', 'Embed text with Universal Sentence Encoder'])", "performance": {"dataset": "various", "accuracy": "N/A"}, "description": "A pre-trained text embedding model that converts sentences into fixed-size vector representations, enabling efficient semantic similarity calculations and other natural language processing tasks."}}
{"code": "###Instruction: Construct a recommendation engine for a forum that finds similar threads based on the text content.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder model from TensorFlow Hub, which is used for embedding text data into high-dimensional vectors, capturing semantic meaning. Once the model is loaded, you can pass the text content of forum threads as input to obtain their embeddings, then use a similarity measure (such as cosine similarity) to identify similar threads for recommendations. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\n# Load Universal Sentence Encoder\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text data", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": "Text input", "python_environment_requirements": "TensorFlow, TensorFlow Hub", "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello, world!', 'How are you?'])", "performance": {"dataset": "Various text sources", "accuracy": "High similarity scores for semantically similar sentences"}, "description": "A text embedding model that converts text data into high-dimensional vectors, capturing semantic meaning and enabling various natural language processing tasks."}}
{"code": "###Instruction: They have a dataset of stained glass images and want to organize them into categories or classes. They need a pre-trained model.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads a pre-trained Inception V3 model from TensorFlow Hub. This model has been trained on the ImageNet dataset and can be used for image classification. You can use this pre-trained model for classifying your stained glass images into different categories or classes by passing your images to the model and obtaining their predicted class labels. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v3/classification/5'\nmodel = hub.load(model_id)\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(299, 299))\nimage = tf.keras.preprocessing.image.img_to_array(image)\nimage = tf.expand_dims(image, axis=0)\n\npredictions = model(image)", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading pre-trained models for image classification", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v3/classification/5'\nmodel = hub.load(model_id)\n\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(299, 299))\nimage = tf.keras.preprocessing.image.img_to_array(image)\nimage = tf.expand_dims(image, axis=0)\n\npredictions = model(image)\n", "performance": {"dataset": "ImageNet", "accuracy": "Not specified"}, "description": "Load a pre-trained model from TensorFlow Hub for image classification using the Inception V3 architecture."}}
{"code": "###Instruction: Provide me with a method to understand the semantic similarity between movie reviews.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the Universal Sentence Encoder model from TensorFlow Hub, which can embed text into high-dimensional vectors. These vectors can then be used for various natural language processing tasks, such as text classification, semantic similarity, clustering, etc. In this case, the model will be used to create embeddings for movie reviews, and the similarity between these embeddings can be used to measure the semantic similarity between the reviews. <<<code>>>: import tensorflow_hub as hub\n# Load the Universal Sentence Encoder\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": {"input": "List of sentences"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.8.0"}, "example_code": "import tensorflow_hub as hub; embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'); embeddings = embed(['Hello world', 'I am learning how to use the Universal Sentence Encoder'])", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.78"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks. The model is trained and optimized for greater-than-word length text, such as sentences, phrases, or short paragraphs."}}
{"code": "###Instruction: We have a large photo archive, and we need a model to recognize and categorize pictures based on their content.\n###Output: <<<domain>>>: image-feature-vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224, 224, 3), trainable=True), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call utilizes the pre-trained MobileNet V2 model from TensorFlow Hub for feature extraction and image classification. You can incorporate it into a Keras model with a Dense layer and softmax activation for categorization. By setting trainable=True, the model can be fine-tuned for the specific categories present in your large photo archive. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Create a model with a pre-trained MobileNetV2 KerasLayer for feature extraction and a Dense layer for classification\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224, 224, 3), trainable=True),\n    tf.keras.layers.Dense(10, activation='softmax')\n])\n# Compile and train the model\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\nmodel.fit(x_train, y_train, epochs=5)\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction", "api_name": "model_id", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"model_id": "string", "input_shape": "tuple", "trainable": "boolean"}, "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'\nmodel = tf.keras.Sequential([\n    hub.KerasLayer(model_id, input_shape=(224, 224, 3), trainable=True),\n    tf.keras.layers.Dense(10, activation='softmax')\n])\n\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\nmodel.fit(x_train, y_train, epochs=5)", "performance": {"dataset": "ImageNet", "accuracy": "Top-1 accuracy"}, "description": "A pre-trained image feature vector model for image classification and transfer learning, based on MobileNetV2 architecture."}}
{"code": "###Instruction: After a dinner party, I want to save the pictures taken during the party and find similar images for decoration purposes by extracting an image feature vector.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=[224, 224, 3]), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the MobileNet V2 model from TensorFlow Hub which is designed for image feature extraction. The model is pre-trained on ImageNet and can work with input images of size 224x224. By using this model, you can convert your dinner party images into 1280-dimensional feature vectors, which can be used to find similar images for decoration purposes. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=[224, 224, 3])])", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Image feature extraction", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "[224, 224, 3]", "output_shape": "[1280]"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.6.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer(\"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4\", input_shape=[224, 224, 3])\n])\n\nimage = tf.keras.Input(shape=(224, 224, 3))\nfeatures = model(image)", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained image feature extraction model using MobileNet V2 architecture with 224x224 input size and 1280-dimensional output feature vector. The model is trained on ImageNet dataset and can be used for various image recognition tasks."}}
{"code": "###Instruction: I am trying to create clusters of similar customer feedback for a product.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder from TensorFlow Hub, which encodes text into high-dimensional vectors. These vectors can be used for a wide range of natural language processing tasks, such as semantic similarity, clustering, and text classification. In this case, you can use the model to get embeddings for customer feedback texts and then apply clustering algorithms to group similar feedback together. <<<code>>>: import tensorflow_hub as hub\n# Load the Universal Sentence Encoder model\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": "text_input", "python_environment_requirements": "tensorflow, tensorflow_hub", "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\ntext_input = ['This is a sample text']\nembeddings = embed(text_input)", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.803"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for a wide range of tasks such as semantic similarity, clustering, and text classification."}}
{"code": "###Instruction: I have pictures of animals, and I need to find out what type of animals they are by leveraging pre-trained models.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads a pre-trained Inception V3 model which has been trained for image classification. This model can be used to distinguish different animal types based on the input images. By using this TensorFlow Hub model, you can easily classify the animal images provided. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Image classification using pre-trained models", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "api_arguments": [{"name": "model_id", "type": "string", "description": "The identifier of the pre-trained model to be loaded from TensorFlow Hub"}], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v3/classification/5'\nmodel = hub.load(model_id)\n", "performance": {"dataset": "ImageNet", "accuracy": "Not specified"}, "description": "Load and use pre-trained image classification models from TensorFlow Hub for classifying images"}}
{"code": "###Instruction: We are working on an app that can identify plants. We have the images of the leaves, so all we need is a pre-trained model to classify the images.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained MobileNetV2 model for image classification from TensorFlow Hub. This model has been trained on the ImageNet dataset and can be used to classify images of plant leaves or other objects. By incorporating this pre-trained model into your app, you can avoid training your own model from scratch and save time and resources. The model has an input size of 224x224 pixels and is designed for high accuracy (71.8% on ImageNet). <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Create a model using the MobileNetV2 architecture with pre-trained weights\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\n])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Image classification using pre-trained model", "api_name": "imagenet_mobilenet_v2_100_224_classification", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": {"url": "https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0", "numpy": ">=1.19.5", "PIL": ">=8.3.2"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nfrom PIL import Image\nimport numpy as np\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\n])\n\nimage = Image.open('path/to/your/image.jpg').resize((224, 224))\ninput_image = np.array(image) / 255.0\ninput_image = np.expand_dims(input_image, axis=0)\n\npredictions = model.predict(input_image)\npredicted_class = np.argmax(predictions[0])\nprint('Predicted class:', predicted_class)", "performance": {"dataset": "ImageNet", "accuracy": "71.8%"}, "description": "A pre-trained image classification model using MobileNetV2 architecture on ImageNet dataset with 100% depth and 224x224 input size."}}
{"code": "###Instruction: Analyze the sentiments of these customer reviews before processing their feedback.\n###Input: [\"I loved the service and the food!\", \"The staff was rude, and I had a terrible experience.\", \"Not too bad, could be better.\"]\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder from TensorFlow Hub. The encoder generates high-dimensional vector representations of input text that can be used to analyze sentiments. For each input sentence, the model will create a corresponding embedding which can then be fed to a sentiment analysis classifier. Once the classifier is trained, it can help infer the sentiment of the customer reviews. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['I loved the service and the food!', 'The staff was rude, and I had a terrible experience.', 'Not too bad, could be better.'])\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Universal Sentence Encoder", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": {"input": "A list of sentences or phrases"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.8.0"}, "example_code": "import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello, world!', 'How are you?'])", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.80"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: We want to obtain the location of a boat in an image. Detect objects in the given image and provide the location of the boat if found.\n###Output: <<<domain>>>: Image object detection, <<<api_call>>>: hub.load('https://tfhub.dev/tensorflow/efficientdet/d0/1'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the pre-trained EfficientDet model from TensorFlow Hub, which is used for object detection in images. Once loaded, you can pass an image to detect objects along with their bounding boxes and class labels. You can then search for the boat's class label to find its location in the image. <<<code>>>: import tensorflow_hub as hub\nmodel_id = 'https://tfhub.dev/tensorflow/efficientdet/d0/1'\ndetector = hub.load(model_id)\n", "api_call": "hub.load('https://tfhub.dev/tensorflow/efficientdet/d0/1')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image object detection", "framework": "TensorFlow Hub", "functionality": "Detect objects in images", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/tensorflow/efficientdet/d0/1')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow_hub as hub\nmodel_id = 'https://tfhub.dev/tensorflow/efficientdet/d0/1'\ndetector = hub.load(model_id)", "performance": {"dataset": "COCO", "accuracy": "N/A"}, "description": "Load a pre-trained model from TensorFlow Hub for object detection in images."}}
{"code": "###Instruction: Create a system to find the similarity between two sentences.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The Universal Sentence Encoder is used to encode text into high-dimensional vectors. By loading the model from TensorFlow Hub, you can generate embeddings for two sentences and calculate the similarity between them. The similarity is determined by computing the cosine similarity between the two sentence embeddings. With this method, you can gauge how closely related two pieces of text are. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world', 'Embedding text with TensorFlow Hub'])", "performance": {"dataset": "SNLI", "accuracy": "86.9%"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: I'm building a recommendation system for similar pictures. Provide me with a vector representation of a picture to measure image similarity.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/5'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained MobileNetV2 model for feature extraction from TensorFlow Hub. The model creates a high-dimensional vector representation of an image, which can then be used to measure similarity between different images. This can be helpful for building a recommendation system for image-based content. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/5',\n                   input_shape=(224,224,3),\n                   output_shape=(1280,))\n])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/5')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction", "api_name": "imagenet-mobilenet_v2_100_224-feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/5')", "api_arguments": "input_shape, output_shape", "python_environment_requirements": "tensorflow, tensorflow-hub", "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/5',\n                    input_shape=(224,224,3),\n                    output_shape=(1280,))\n])", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained MobileNetV2 model for extracting image feature vectors using TensorFlow Hub."}}
{"code": "###Instruction: Recommend to me some suitable products based on the textual similarity of their descriptions from a database.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The Universal Sentence Encoder API call allows you to load a pre-trained model in TensorFlow Hub that generates high-dimensional vectors from input text. These vectors can be used for various natural language tasks, such as text classification, semantic similarity, clustering, and more. In this case, you can use the model to obtain embeddings for each product description in a database and then identify similar products based on the textual similarity of their embeddings. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world!'])", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.803"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: Extract audio features to classify sounds in the environment.\n###Output: <<<domain>>>: Audio embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/yamnet/1'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the YAMNet model from TensorFlow Hub, which is a deep neural network designed to predict audio events from the AudioSet ontology. This model can extract features from audio samples and can be used to classify sounds in the environment. <<<code>>>: import tensorflow_hub as hub\n# Load the YAMNet model\nyamnet_model = hub.load('https://tfhub.dev/google/yamnet/1')\n", "api_call": "hub.load('https://tfhub.dev/google/yamnet/1')", "provider": "TensorFlow Hub", "api_data": {"domain": "Audio embedding", "framework": "TensorFlow Hub", "functionality": "Feature extraction from audio", "api_name": "yamnet", "api_call": "hub.load('https://tfhub.dev/google/yamnet/1')", "api_arguments": [], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "", "performance": {"dataset": "", "accuracy": ""}, "description": "YAMNet is a deep net that predicts audio events from the AudioSet ontology."}}
{"code": "###Instruction: Write an AI-powered program to summarize movie plots while retaining maximum details from the given plot.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the Universal Sentence Encoder (USE) model, which embeds text into high-dimensional vectors for tasks like text classification, semantic similarity, and clustering. With this model, you can convert movie plot sentences into high-dimensional vectors and use these embeddings to compare different parts of the plot or determine their importance. By retaining and combining the most relevant parts, you can create a summarized plot that retains maximum details. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow_hub as hub; embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'); embeddings = embed(['Hello world']); print(embeddings)", "performance": {"dataset": "STS-Benchmark", "accuracy": "Pearson correlation coefficient of 0.803"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks. It is trained and optimized for greater-than-word length text, such as sentences, phrases, or short paragraphs."}}
{"code": "###Instruction: Help me compare similarities between user reviews about two different products.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder model from TensorFlow Hub, which is a pre-trained model that can be used for various natural language processing tasks, including text embedding. By using this model, you can transform user reviews into continuous vector space, making it easier to compare similarities and differences between reviews of two different products. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into a continuous vector space", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text: A string or list of strings to be embedded"], "python_environment_requirements": ["tensorflow>=2.0.0", "tensorflow-hub>=0.12.0"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello, world!', 'How are you?'])\nprint(embeddings)", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.803"}, "description": "A pre-trained model for embedding text into a 512-dimensional vector space that can be used for various natural language processing tasks such as text classification, semantic similarity, clustering, and other downstream tasks."}}
{"code": "###Instruction: Provided with images of paintings, I want to determine which art era they belong to.\n###Output: <<<domain>>>: Image-feature-vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224, 224, 3), trainable=False), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call adds a pre-trained MobileNet V2 model as a Keras layer to extract features from images with dimensions of 224x224x3. The model has been trained on the ImageNet dataset and can be used for multiple image-related tasks including image classification, object detection, and image similarity. To classify paintings into art eras, you can use this feature vector layer as a starting point and train on top of it using your dataset. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224, 224, 3), trainable=False)\n])\n\nimage = tf.random.normal([1, 224, 224, 3])\nfeatures = model(image)\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Extract image features", "api_name": "imagenet-mobilenet_v2_100_224-feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "[None, 224, 224, 3]", "output_shape": "[None, 1280]"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224, 224, 3), trainable=False)\n])\n\nimage = tf.random.normal([1, 224, 224, 3])\nfeatures = model(image)", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained image feature vector model using MobileNetV2 architecture on the ImageNet dataset. The model is designed to extract features from images and can be used for various tasks such as image classification, object detection, and image similarity."}}
{"code": "###Instruction: Understand the relationship between two movie synopses and determine whether they seem similar or not.\n###Output: <<<domain>>>: text-embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder model from TensorFlow Hub. The model takes text as input and outputs high-dimensional vectors, which can be used for various natural language processing tasks, such as semantic similarity. By using this model, you can generate embeddings for two movie synopses and compare the embeddings to determine whether they are similar or not. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Load the Universal Sentence Encoder model\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n# Get embeddings for two movie synopses (Replace 'synopsis1' and 'synopsis2' with actual text)\nembeddings = embed([synopsis1, synopsis2])\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional space", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": {"input": "List of strings"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world!', 'My name is John Doe'])", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.803"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: Suggest personalized ads to users by creating a semantic similarity model that recommends advertisements based on textual similarity to user preferences stored in the description field. \n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call retrieves the Universal Sentence Encoder model from TensorFlow Hub. This model encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, and other natural language tasks. In this case, the high-dimensional vectors created using the Universal Sentence Encoder can be employed to accomplish semantic similarity for personalized ad recommendations based on user preferences in textual format. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello, world!'])\nprint(embeddings)", "performance": {"dataset": "STS benchmark", "accuracy": "0.803"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: There is a list of customer reviews and your task is to calculate the semantic similarity between each pair of reviews.\n###Output: <<<domain>>>: text-embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder model from TensorFlow Hub, which encodes text into high-dimensional vectors. These vectors can be used for a variety of natural language processing tasks, such as text classification, semantic similarity, clustering, etc. Here, the model will be used to calculate the semantic similarity between pairs of customer reviews. <<<code>>>: import tensorflow_hub as hub\n# Load Universal Sentence Encoder\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "embeddings = embed(['Hello world'])", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.803"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: Expose a method to compute the semantic similarity of pairs of sentences by comparing the high-dimensional vectors.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder model from TensorFlow Hub, which transforms input text into high-dimensional vectors. These vectors can be used for various natural language processing tasks, including semantic similarity computation. To calculate the semantic similarity between pairs of sentences, compare the generated vectors for each sentence. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into a high-dimensional vector", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": "input_text", "python_environment_requirements": "tensorflow, tensorflow_hub", "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world'])\nprint(embeddings)", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.803521"}, "description": "This API provides a method to convert text into a high-dimensional vector using the Universal Sentence Encoder from TensorFlow Hub. It can be used for tasks such as semantic similarity and clustering."}}
{"code": "###Instruction: I am analyzing tweets, and I want to know the sentiment of each tweet. Please help me convert tweets into meaningful representations.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder model from TensorFlow Hub, which is designed to encode text into high-dimensional vectors. Once loaded, it can be used to process and embed tweets into a vector space representation that can be used for various natural language tasks such as sentiment analysis. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text for various NLP tasks", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "embeddings = embed(['Hello, world!'])", "performance": {"dataset": "Various", "accuracy": "Not specified"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: I need to build a machine learning model that can automatically detect and classify different food items from images.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: model = hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained image classification model from TensorFlow Hub using the Inception V3 architecture. The model has been trained on the ImageNet dataset, which includes images of various food items. You can use this model to detect and classify different types of food items in images. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v3/classification/5'\nmodel = hub.load(model_id)\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v3/classification/5'\nmodel = hub.load(model_id)", "performance": {"dataset": "ImageNet", "accuracy": "Not provided"}, "description": "Load a pre-trained image classification model from TensorFlow Hub using the provided model_id."}}
{"code": "###Instruction: Identify the animal in the photo I have taken.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: model = tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/imagenet/inception_v3/classification/5')]), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call allows you to load a pre-trained Inception V3 model from TensorFlow Hub for image classification. The model has been trained on a wide range of object classes, including animals. You can use it to process the photo you have taken and predict the animal present in the image. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/imagenet/inception_v3/classification/5')])", "api_call": "tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/imagenet/inception_v3/classification/5')])", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading pre-trained models", "api_name": "model_id", "api_call": "tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/imagenet/inception_v3/classification/5')])", "api_arguments": {"handle": "string", "trainable": "boolean (optional)"}, "python_environment_requirements": {"tensorflow": ">=2.0", "tensorflow_hub": ">=0.12"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v3/classification/5'\nmodel = tf.keras.Sequential([hub.KerasLayer(model_id)])\n\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(299, 299))\nimage = tf.keras.preprocessing.image.img_to_array(image)\nimage = tf.keras.applications.inception_v3.preprocess_input(image)\nimage = tf.expand_dims(image, axis=0)\n\npredictions = model.predict(image)", "performance": {"dataset": "ImageNet", "accuracy": "0.779"}, "description": "Load a pre-trained Inception V3 model from TensorFlow Hub for image classification."}}
{"code": "###Instruction: Generate an appropriate label for instance of image.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: model = hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the pre-trained Inception V3 model for image classification from TensorFlow Hub. With this model, you can classify an input image instance into one of the many classes in the ImageNet dataset. The example code demonstrates how to load the model, preprocess an image, make a prediction, and decode the prediction into a class name (or label). <<<code>>>: import tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading pre-trained models", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v3/classification/5'\nmodel = hub.load(model_id)\n\n# Load and preprocess an image\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(299, 299))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, 0)\n\n# Make a prediction\npredictions = model(image_array)\n\n# Decode the predictions\nclass_names = tf.keras.applications.inception_v3.decode_predictions(predictions.numpy())", "performance": {"dataset": "ImageNet", "accuracy": "77.9%"}, "description": "This API allows you to load pre-trained models for image classification using TensorFlow Hub. The example provided demonstrates how to load the Inception V3 model, preprocess an image, make a prediction, and decode the predictions into class names."}}
{"code": "###Instruction: I'm traveling to a new city and I want to use my phone to identify different objects in my surroundings.\n###Output: <<<domain>>>: Image object detection, <<<api_call>>>: detector = hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained object detection model from TensorFlow Hub, which uses the SSD Mobilenet V2 architecture. It is capable of detecting multiple objects in an image or a frame taken from the camera of a cellphone. Once the model is loaded, it can be used to identify various objects in the images. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Load the detector model from TensorFlow Hub\ndetector = hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')\n", "api_call": "hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image object detection", "framework": "TensorFlow Hub", "functionality": "Detect objects in images", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')", "api_arguments": {"model_id": "URL of the TensorFlow Hub model"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.6.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'\ndetector = hub.load(model_id)\n\nimage = tf.image.decode_image(tf.io.read_file('path/to/image.jpg'))\nresult = detector(image[tf.newaxis, ...])", "performance": {"dataset": "COCO", "accuracy": "Not specified"}, "description": "A pre-trained TensorFlow Hub model for detecting objects in images using the SSD Mobilenet V2 architecture."}}
{"code": "###Instruction: Analyze a list of movie reviews and group them based on semantic similarity by first converting the reviews into embeddings.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: By using this API call, you can load the Universal Sentence Encoder model from TensorFlow Hub. The model is designed for encoding text into high-dimensional vectors, which can be used for various natural language processing tasks, including text classification, semantic similarity, clustering, etc. By converting the movie reviews into embeddings using this model, you can then analyze and group them based on semantic similarities. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text data", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow_hub as hub; embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'); embeddings = embed(['Hello world!'])", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.78"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: I am working on a car accident detection system. Show me how to detect object and classify them in images\n###Output: <<<domain>>>: Image object detection, <<<api_call>>>: hub.load('https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads a pre-trained Faster R-CNN model with Inception-ResNet V2 feature extractor from TensorFlow Hub. The model has been trained on the OpenImages V4 dataset and is configured to detect objects in images. Once the model is loaded, you can input an image, and the model will output detected objects along with their class labels and bounding boxes. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1'\ndetector = hub.load(model_id)\n# Assuming 'image' is a path to your image\nimage = tf.image.decode_jpeg(tf.io.read_file('path/to/image.jpg'))\nconverted_image = tf.image.convert_image_dtype(image, tf.float32)[tf.newaxis, ...]\nresult = detector(converted_image)", "api_call": "hub.load('https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image object detection", "framework": "TensorFlow Hub", "functionality": "Detect objects in images", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1'\ndetector = hub.load(model_id)\nimage = tf.image.decode_jpeg(tf.io.read_file('path/to/image.jpg'))\nconverted_image = tf.image.convert_image_dtype(image, tf.float32)[tf.newaxis, ...]\nresult = detector(converted_image)", "performance": {"dataset": "OpenImages V4", "accuracy": "Not specified"}, "description": "A pre-trained image object detection model that detects objects in images using the Faster R-CNN architecture with Inception-ResNet V2 as the feature extractor."}}
{"code": "###Instruction: Identify the objects present in the picture I took from my last hiking trip.\n###Output: <<<domain>>>: Image object detection, <<<api_call>>>: loaded_model = hub.load('https://tfhub.dev/tensorflow/efficientdet/lite0/detection/1'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the pre-trained EfficientDet model from TensorFlow Hub for object detection in images. Once loaded, the model can be used to detect objects in images such as the one from your last hiking trip. The detected objects will be returned along with their bounding boxes, class labels, and confidence scores. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel_id = 'https://tfhub.dev/tensorflow/efficientdet/lite0/detection/1'\nloaded_model = hub.load(model_id)", "api_call": "hub.load('https://tfhub.dev/tensorflow/efficientdet/lite0/detection/1')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image object detection", "framework": "TensorFlow Hub", "functionality": "Object detection", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/tensorflow/efficientdet/lite0/detection/1')", "api_arguments": ["model_id"], "python_environment_requirements": ["import tensorflow as tf", "import tensorflow_hub as hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/tensorflow/efficientdet/lite0/detection/1'\nloaded_model = hub.load(model_id)\n\nimage = tf.keras.preprocessing.image.load_img('image_path')\nimage = tf.keras.preprocessing.image.img_to_array(image)\nimage = image / 255.0\nimage = tf.expand_dims(image, 0)\n\noutput = loaded_model(image)", "performance": {"dataset": "", "accuracy": ""}, "description": "Load a pre-trained TensorFlow Hub model for image object detection and use it to detect objects in an input image."}}
{"code": "###Instruction: We are creating a visual recommender system based on images. We need to extract features from them.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained MobileNetV2 model from TensorFlow Hub, which extracts feature vectors from images. The input images should be 224x224 pixels with 3 channels (RGB), and the output is a 1280-dimensional feature vector. Once these features are extracted, you can use them to build a visual recommender system by comparing the extracted features of different images. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\n# Define the model\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=(224, 224, 3),\n                   trainable=False),\n])\n\n# Use the model to extract features from an image (assuming 'image' is a resized 224x224x3 NumPy array representing your image)\nfeatures = model.predict(image.reshape(1, 224, 224, 3))\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Extract image features", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "[batch_size, 224, 224, 3]", "output_shape": "[batch_size, 1280]"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=(224, 224, 3),\n                   trainable=False),\n    tf.keras.layers.Dense(10, activation='softmax')\n])\n\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])", "performance": {"dataset": "ImageNet", "accuracy": "71.9%"}, "description": "A pre-trained image feature vector model, MobileNetV2, for TensorFlow Hub that extracts features from images. The input images should be 224x224 pixels with 3 channels (RGB). The output is a 1280-dimensional feature vector. The model is trained on the ImageNet dataset."}}
{"code": "###Instruction: In order to analyze the sentiment of tweets on Twitter, I need the Universal Sentence Encoder model to convert tweets into embeddings for analysis.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the Universal Sentence Encoder model from TensorFlow Hub. This model encodes text into high-dimensional vectors that are useful for various natural language processing tasks, including text classification, semantic similarity, clustering, and sentiment analysis. In this case, the embeddings will be used to analyze the sentiment of tweets from Twitter. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world!'])\nprint(embeddings)", "performance": {"dataset": "STS Benchmark", "accuracy": "Pearson correlation coefficient of 0.803"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: Detect and count the number of different objects in a picture I took at a beach.\n###Output: <<<domain>>>: Image object detection, <<<api_call>>>: model = hub.load('https://tfhub.dev/google/faster_rcnn/inception_resnet_v2/atrous/oid_v4/1'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained Faster R-CNN model with the Inception-ResNet-v2 feature extractor from TensorFlow Hub. The model is trained on the Open Images Dataset v4 and is capable of detecting and counting objects in images. In this case, it will be used to process an image taken at a beach and identify and count the number of different objects. <<<code>>>: import tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/faster_rcnn/inception_resnet_v2/atrous/oid_v4/1')\n", "api_call": "hub.load('https://tfhub.dev/google/faster_rcnn/inception_resnet_v2/atrous/oid_v4/1')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image object detection", "framework": "TensorFlow Hub", "functionality": "Detect objects in images", "api_name": "faster_rcnn_inception_resnet_v2_atrous_oid_v4", "api_call": "hub.load('https://tfhub.dev/google/faster_rcnn/inception_resnet_v2/atrous/oid_v4/1')", "api_arguments": {"image_tensor": "A tensor of shape [batch_size, height, width, 3] containing the input images."}, "python_environment_requirements": {"tensorflow": ">=2.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = hub.load('https://tfhub.dev/google/faster_rcnn/inception_resnet_v2/atrous/oid_v4/1')\nimage_tensor = tf.zeros([1, 640, 640, 3])\noutput = model(image_tensor)", "performance": {"dataset": "Open Images Dataset v4", "accuracy": "mAP@0.5IOU = 0.480"}, "description": "A pre-trained Faster R-CNN model with Inception-ResNet-v2 feature extractor for object detection on the Open Images Dataset v4."}}
{"code": "###Instruction: I am visiting different places and I want to know which landmark I am visiting.\n###Output: <<<domain>>>: image-classification, <<<api_call>>>: hub.KerasLayer(\"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4\"), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the pre-trained MobileNetV2 model from TensorFlow Hub specialized for image classification tasks. Once loaded, it creates a KerasLayer designed for classification of images with an input size of 224x224 pixels. This model has been trained on the ImageNet dataset, enabling it to classify various objects and landmarks in images. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Create a model with a single KerasLayer for image classification\nmodel = tf.keras.Sequential([hub.KerasLayer(\"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4\")])\n", "api_call": "hub.KerasLayer(\"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4\")", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Pre-trained model for image classification", "api_name": "imagenet_mobilenet_v2_100_224", "api_call": "hub.KerasLayer(\"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4\")", "api_arguments": {"url": "https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = tf.keras.Sequential([\n    hub.KerasLayer(\"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4\")\n])\n", "performance": {"dataset": "ImageNet", "accuracy": "71.9%"}, "description": "A pre-trained model for image classification using MobileNetV2 architecture with 224x224 input size, trained on ImageNet dataset."}}
{"code": "###Instruction: Identify different types of birds when hikers send the images to our system.\n###Output: <<<domain>>>: Image-classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the pre-trained Inception V3 model from TensorFlow Hub. The Inception V3 model has been trained on the ImageNet dataset, which contains a wide variety of images, including many bird species. Once loaded, you can use this model to classify images submitted by hikers into one of 1000 different classes. This will make it possible to identify different types of birds present in those images. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v3/classification/5'\nmodel = hub.load(model_id)\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(299, 299))\ninput_image = tf.keras.preprocessing.image.img_to_array(image)\ninput_image = tf.expand_dims(input_image, 0)\npredictions = model(input_image)\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Pre-trained model for image classification", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v3/classification/5'\nmodel = hub.load(model_id)\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(299, 299))\ninput_image = tf.keras.preprocessing.image.img_to_array(image)\ninput_image = tf.expand_dims(input_image, 0)\npredictions = model(input_image)\n", "performance": {"dataset": "ImageNet", "accuracy": "0.779"}, "description": "A pre-trained model for image classification using Inception V3 architecture, available on TensorFlow Hub. The model has been trained on the ImageNet dataset and can be used to classify images into 1000 different classes."}}
{"code": "###Instruction: How can I compare the similarity between multiple sentences?\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: To compare the similarity between multiple sentences, you can use the Universal Sentence Encoder, which converts text into high-dimensional vectors. By loading the model using the API call, you can encode the sentences and then compute the cosine similarity between the resulting vectors. This will give you a measure of how similar the sentences are in terms of their semantic meaning. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": {"input": "List of strings"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.8.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world', 'Embedding with TensorFlow Hub'])\nprint(embeddings)", "performance": {"dataset": "Common benchmarks", "accuracy": "State-of-the-art performance"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: Tell me what kind of animal/bird is in this photo I just took.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: model = hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call will load a pre-trained TensorFlow image classification model from TensorFlow Hub. The model uses the Inception V3 architecture and is trained on the ImageNet dataset. It can be used to classify images, including those of animals or birds, and recognize the object in the photo. By passing your taken photo to the model, it will return the predicted class for the animal or bird present in the image. <<<code>>>: import tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading and using pre-trained models", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v3/classification/5'\nmodel = hub.load(model_id)\nimage = tf.keras.preprocessing.image.load_img('image.jpg', target_size=(299, 299))\ninput_image = tf.keras.preprocessing.image.img_to_array(image)\ninput_image = tf.expand_dims(input_image, 0)\npredictions = model(input_image)\n", "performance": {"dataset": "ImageNet", "accuracy": "Not provided"}, "description": "This API is used to load and use pre-trained image classification models from TensorFlow Hub for tasks like object recognition and scene understanding."}}
{"code": "###Instruction: Determine the top 3 closest category matches for a given image using the Inception V3 pre-trained model.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: model = hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the Inception V3 pre-trained model for image classification from TensorFlow Hub. Once the model is loaded, it can be used to classify images into categories. To determine the top 3 closest category matches for a given image, you will use this model and obtain the highest scoring class indices from the model's output. <<<code>>>: import tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "api_arguments": {"model_id": "string"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v3/classification/5'\nmodel = hub.load(model_id)", "performance": {"dataset": "ImageNet", "accuracy": "Not provided"}, "description": "Load a pre-trained image classification model from TensorFlow Hub using the model's ID."}}
{"code": "###Instruction: I need a simple way to encode text into vectors for my clustering algorithm.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call retrieves the Universal Sentence Encoder model from TensorFlow Hub. The encoder is designed to convert input text into fixed-size embedding vectors. These vectors can be used for a variety of natural language processing tasks, such as text classification, semantic similarity, and clustering. Once the model is loaded, you can pass the text as input and receive the corresponding embedding vectors. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Load the Universal Sentence Encoder\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n# Get embeddings for the input text\nembeddings = embed(['Hello world!'])\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": {"input": "text"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.8.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world!'])", "performance": {"dataset": "STS benchmark", "accuracy": "0.803"}, "description": "The Universal Sentence Encoder encodes text into a fixed-size embedding vector. It is trained on a variety of data sources and can be used for multiple NLP tasks such as text classification, semantic similarity, and clustering."}}
{"code": "###Instruction: Find a tool to extract features from images and create a model to identify different types of plants.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads a feature extraction layer from TensorFlow Hub using MobileNetV2 trained on the ImageNet dataset. By having this feature extraction layer, you can create a new model for transfer learning or fine-tuning to identify different types of plants using image input. You can simply add a Dense layer for classification. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer(\"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4\",\n                   input_shape=(224,224,3),\n                   output_shape=[1280],\n                   trainable=False),\n    tf.keras.layers.Dense(num_classes, activation='softmax')\n])", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": [224, 224, 3], "output_shape": [1280], "trainable": false}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.6.0"}, "example_code": "model = tf.keras.Sequential([\n    hub.KerasLayer(\"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4\",\n                   input_shape=(224,224,3),\n                   output_shape=[1280],\n                   trainable=False),\n    tf.keras.layers.Dense(num_classes, activation='softmax')\n])", "performance": {"dataset": "ImageNet", "accuracy": 0.71}, "description": "This is a feature vector obtained from the MobileNetV2 model trained on the ImageNet dataset. It can be used for transfer learning and fine-tuning on new datasets."}}
{"code": "###Instruction: How do I create image-feature-vector for the last travel destination photo album to organize similar pictures together?\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: model = hub.load('https://tfhub.dev/google/imagenet/inception_v1/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call will load the Inception V1 pre-trained model from TensorFlow Hub. This model is designed for creating feature vectors from images. Once the model is loaded, you can use it to create feature vectors for each photo in your travel destination album, which will allow you to group similar images together by comparing their high-dimensional representations. <<<code>>>: import tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/imagenet/inception_v1/feature_vector/4')\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v1/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Create image feature vector", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v1/feature_vector/4')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v1/feature_vector/4'\nmodel = hub.load(model_id)\nfeature_vector = model(image_tensor)", "performance": {"dataset": "ImageNet", "accuracy": "Not specified"}, "description": "Load an image feature vector model from TensorFlow Hub and use it to create feature vectors for images."}}
{"code": "###Instruction: Identify the make and model of a car using an image posted on an online car marketplace.\n###Input: \"https://url-to-image-of-car-from-marketplace\"\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads a pre-trained image classification model called MobileNet V2 from TensorFlow Hub. This model has been trained on the ImageNet dataset and can detect many categories of objects, including car makes and models. Once the model is loaded, you can pass the image (either directly or pre-processed) to the model to obtain the predicted class labels for the car make and model.<<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel_id = 'https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'\nmodel = hub.load(model_id)\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading pre-trained models", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'\nmodel = hub.load(model_id)\n", "performance": {"dataset": "ImageNet", "accuracy": "Not specified"}, "description": "Load a pre-trained image classification model from TensorFlow Hub using the specified model_id."}}
{"code": "###Instruction: Assist me in identifying animal species present in a collection of images for an ecological study.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: extractor = hub.KerasLayer('https://tfhub.dev/google/imagenet/inception_v3/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads a pre-trained TensorFlow model, Inception V3, as a KerasLayer from TensorFlow Hub. This model is designed for feature extraction from images. You can use the extracted feature vectors as input for a classifier to identify animal species present in the given image collection for your ecological study. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nextractor = hub.KerasLayer('https://tfhub.dev/google/imagenet/inception_v3/feature_vector/4')\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/inception_v3/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction from images", "api_name": "model_id", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/inception_v3/feature_vector/4')", "api_arguments": ["model_id", "input_shape", "trainable"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v3/feature_vector/4'\ninputs = tf.keras.Input(shape=(224, 224, 3))\nfeature_extractor = hub.KerasLayer(model_id, trainable=False)(inputs)\noutputs = tf.keras.layers.Dense(1000, activation='softmax')(feature_extractor)\nmodel = tf.keras.Model(inputs=inputs, outputs=outputs)", "performance": {"dataset": "ImageNet", "accuracy": "Not specified"}, "description": "This API allows users to extract feature vectors from images using a pre-trained model from TensorFlow Hub. The feature vectors can then be used for various image recognition and classification tasks."}}
{"code": "###Instruction: I am building a tool to measure the similarity between different product descriptions. To do this, I need to first get embeddings for each description.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the Universal Sentence Encoder model from TensorFlow Hub. This model encodes text into high-dimensional vectors. By obtaining these vectors or embeddings for each product description, you can then measure the similarity between different products based on their descriptions. These high-dimensional vectors can further be used for various natural language processing tasks like text classification, semantic similarity, clustering, etc. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Converts text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello, world!', 'How are you?'])", "performance": {"dataset": "Various", "accuracy": "N/A"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: Show me how to classify an image of a car into one of the 1000 categories.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads a pre-trained ImageNet MobileNetV2 classification model from TensorFlow Hub. This model classifies images into 1000 different categories. To use it, you will create a Keras Sequential model with the MobileNetV2 layer, preprocess the input image to be of the correct size (224x224), and convert it to a tensor. Finally, feed the tensor to the model to get the predictions. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')\n])\n\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(224, 224))\ninput_array = tf.keras.preprocessing.image.img_to_array(image)\ninput_array = tf.expand_dims(input_array, 0)\n\npredictions = model.predict(input_array)\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Image classification model", "api_name": "imagenet-mobilenet_v2_130_224-classification", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')", "api_arguments": {"handle": "https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4", "output_shape": "[1001]"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')\n])\n\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(224, 224))\ninput_array = tf.keras.preprocessing.image.img_to_array(image)\ninput_array = tf.expand_dims(input_array, 0)\n\npredictions = model.predict(input_array)", "performance": {"dataset": "ImageNet", "accuracy": "0.856"}, "description": "This model is a pre-trained image classification model based on MobileNetV2 architecture. It can classify images into 1000 different categories."}}
{"code": "###Instruction: We need to create an image classifier for recognizing dog breeds. Before creating the classifier, we should extract a fixed-length feature vector from each image.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4', output_shape=[1280]), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call integrates a pre-trained MobileNetV2 model from TensorFlow Hub for extracting a 1280-dimensional feature vector from images. The model is pre-trained on the ImageNet dataset, and the resulting feature vector can be integrated into a classifier for recognizing dog breeds. This process harnesses transfer learning, taking advantage of features learned on a broader dataset (in this case, ImageNet). <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\n# Load an instance of the pre-trained MobileNetV2 model as a Keras layer\nmodel = hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4', output_shape=[1280])\n\n# Prepare the image (assuming 'image' is a TensorFlow tensor representing an input image)\nimage_preprocessed = tf.keras.applications.mobilenet_v2.preprocess_input(image)\nimage_expanded = tf.expand_dims(image_preprocessed, 0)\n\n# Extract the feature vector from the image\nfeature_vector = model(image_expanded)", "api_call": "hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4', output_shape=[1280])", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Extract feature vector from images", "api_name": "image_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4', output_shape=[1280])", "api_arguments": {"handle": "https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4", "output_shape": "[1280]"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.6.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4', output_shape=[1280]),\n    tf.keras.layers.Dense(1)\n])\n\nimage = tf.keras.preprocessing.image.load_img('path/to/your/image.jpg', target_size=(224, 224))\nimage = tf.keras.preprocessing.image.img_to_array(image)\nimage = tf.keras.applications.mobilenet_v2.preprocess_input(image)\nimage = tf.expand_dims(image, 0)\n\nfeature_vector = model.predict(image)\nprint(feature_vector)", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "This API allows you to extract a 1280-dimensional feature vector from an image using the MobileNetV2 architecture, which is pre-trained on the ImageNet dataset. The feature vector can be used for various tasks, such as image classification, object detection, and transfer learning."}}
{"code": "###Instruction: Help me create a machine learning model to identify whether a solar panel is damaged or not using images.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: To create a machine learning model for identifying damaged solar panels, you can start by using a pre-trained image feature vector extraction model like MobileNetV2. The API call provided uses TensorFlow and TensorFlow Hub to create a KerasLayer that can extract feature vectors from images with a 224x224 input size. You can use this KerasLayer as the base of your model and then add a Dense layer with a sigmoid activation function for binary classification (damaged or not damaged). Train your model on a dataset of solar panel images labeled with their damage status. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                  input_shape=(224, 224, 3),\n                  trainable=False),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction from images", "api_name": "imagenet-mobilenet_v2_100_224-feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"url": "https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                  input_shape=(224, 224, 3),\n                  trainable=False),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])", "performance": {"dataset": "ImageNet", "accuracy": "71.9%"}, "description": "A pre-trained model that can be used to extract feature vectors from images using MobileNetV2 architecture with 224x224 input size."}}
{"code": "###Instruction: Suppose you want to build a search engine that can find the most visually similar products in your online shop. You need to extract feature vectors from product images.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call uses a MobileNet V2 architecture module from TensorFlow Hub for image feature vector extraction. This module accepts images of shape (224, 224, 3) and outputs a 1280-dimensional feature vector for each image. These feature vectors can then be used to find visually similar products in your online shop by comparing and ranking the similarity of their feature vectors. <<<code>>>: import tensorflow_hub as hub\nfeature_extractor = hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Image feature extraction", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"url": "https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=(224, 224, 3),\n                   trainable=False)\n])\n\nx = tf.keras.layers.Input(shape=(224, 224, 3))\nfeatures = model(x)\n", "performance": {"dataset": "ImageNet", "accuracy": "71.9%"}, "description": "This module uses MobileNet V2 architecture for image feature vector extraction. It accepts a batch of images of shape (224, 224, 3) and returns a 1280-dimensional feature vector for each image."}}
{"code": "###Instruction: I am a teacher and want to classify images related to educational material. Find out the category of educational images by providing the image's URL.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: You can use the pre-trained MobileNetV2 model from TensorFlow Hub for image classification. The model is trained on the ImageNet dataset and can classify images into 1000 different categories. You can load the model as a Keras layer and pass the preprocessed image to the model for making predictions. After predicting, you can decode the predictions to get the class name of the classified image. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\n# Create the model\nmodel = tf.keras.Sequential([\n  hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5')\n])\n\n# Load an image and preprocess it\nimage = tf.keras.preprocessing.image.load_img('path/to/your/image.jpg', target_size=(224, 224))\ninput_image = tf.keras.preprocessing.image.img_to_array(image)\ninput_image = tf.expand_dims(input_image, 0)\n\n# Make predictions\npredictions = model.predict(input_image)\n\n# Decode the predictions\nclass_names = tf.keras.applications.mobilenet_v2.decode_predictions(predictions, top=1)\nprint(class_names)", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Image classification using pre-trained models", "api_name": "imagenet_mobilenet_v2_130_224_classification", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5')", "api_arguments": {"url": "https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5"}, "python_environment_requirements": {"tensorflow": "2.x", "tensorflow_hub": "0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5')\n])\n\n# Load an image and preprocess it\nimage = tf.keras.preprocessing.image.load_img('path/to/your/image.jpg', target_size=(224, 224))\ninput_image = tf.keras.preprocessing.image.img_to_array(image)\ninput_image = tf.expand_dims(input_image, 0)\n\n# Make predictions\npredictions = model.predict(input_image)\n\n# Decode the predictions\nclass_names = tf.keras.applications.mobilenet_v2.decode_predictions(predictions, top=1)\nprint(class_names)", "performance": {"dataset": "ImageNet", "accuracy": "Not specified"}, "description": "A pre-trained image classification model using MobileNetV2 architecture from TensorFlow Hub. The model is trained on ImageNet dataset and can classify images into 1000 different categories."}}
{"code": "###Instruction: Can you find the semantic similarity between a list of sentences given their embeddings obtained from a pre-trained model?\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: By utilizing the API call to load the Universal Sentence Encoder from TensorFlow Hub, you can generate high-dimensional vectors that represent the given sentences. After getting the embeddings for each sentence, you can use your preferred method (e.g., cosine similarity, Euclidean distance) to calculate the semantic similarity between the embeddings which will provide a measure of the similarity between the input sentences. <<<code>>>: import tensorflow_hub as hub\n# Load the Universal Sentence Encoder\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text using pre-trained models", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": {"input": "List of sentences"}, "python_environment_requirements": ["pip install tensorflow", "pip install tensorflow-hub"], "example_code": "import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world!', 'Embedding with TensorFlow Hub is easy!'])", "performance": {"dataset": "Various", "accuracy": "N/A"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks. It is pre-trained on a variety of data sources and can be used with TensorFlow Hub."}}
{"code": "###Instruction: An airport authority wants to detect the presence of drones close to the airport runway.\n###Output: <<<domain>>>: image-object-detection, <<<api_call>>>: detector = hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the pre-trained SSD MobileNet V2 model from TensorFlow Hub. This model is designed for object detection in images, and you can use it to detect various objects, including drones. Just pass an input image to the loaded model and obtain the detection results, including object bounding boxes and class labels. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Load the SSD MobileNet V2 model\ndetector = hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')\n# Load an image and convert it to a tensor (replace 'path/to/image.jpg' with the path to the actual image)\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg')\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\ninput_image = tf.expand_dims(image_array, 0)\n# Use the model to detect objects in the image\nresult = detector(input_image)\n", "api_call": "hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image object detection", "framework": "TensorFlow Hub", "functionality": "Detect objects in an image", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'\ndetector = hub.load(model_id)\n\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg')\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\ninput_image = tf.expand_dims(image_array, 0)\n\nresult = detector(input_image)", "performance": {"dataset": "COCO", "accuracy": "Not specified"}, "description": "Detect objects in an image using a pre-trained model from TensorFlow Hub"}}
{"code": "###Instruction: I have a lot of images and I want to categorize them based on the objects present in the images.\n###Output: <<<domain>>>: Image object detection, <<<api_call>>>: hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the SSD MobileNet V2 model from TensorFlow Hub that has been pre-trained to detect objects in images. By running the model on your images, you can identify the objects and their categories in the images, which can help you group and categorize them according to the objects present. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel_id = 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'\ndetector = hub.load(model_id)\n\nimage = tf.keras.preprocessing.image.load_img('image.jpg')\ninput_image = tf.keras.preprocessing.image.img_to_array(image)\ninput_image = tf.expand_dims(input_image, 0)\n\nresult = detector(input_image)\n", "api_call": "hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image object detection", "framework": "TensorFlow Hub", "functionality": "Detect objects in images", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow-hub", "tensorflow"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'\ndetector = hub.load(model_id)\n\nimage = tf.keras.preprocessing.image.load_img('image.jpg')\ninput_image = tf.keras.preprocessing.image.img_to_array(image)\ninput_image = tf.expand_dims(input_image, 0)\n\nresult = detector(input_image)\n\nprint(result)", "performance": {"dataset": "COCO", "accuracy": "mAP"}, "description": "A pre-trained TensorFlow Hub model for detecting objects in images using the Single Shot MultiBox Detector (SSD) with MobileNet V2."}}
{"code": "###Instruction: I'm planning to do sentiment analysis on a bunch of news articles. Help me convert the article content to 20-dimensional vectors.\n###Output: <<<domain>>>: Text language model, <<<api_call>>>: hub.load('https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained text language model that has been optimized for generating 20-dimensional embeddings for input text. These 20-dimensional vectors are generated using TensorFlow Hub and the model is based on the Google News dataset. This model will help you convert the content of news articles into embeddings that can be used for sentiment analysis. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1')", "api_call": "hub.load('https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text language model", "framework": "TensorFlow Hub", "functionality": "Loading", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1')", "api_arguments": ["model_url"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "embed = hub.load('https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1')\nembeddings = embed(['cat is on the mat', 'dog is in the fog'])", "performance": {"dataset": "Google News", "accuracy": "20 dimensions"}, "description": "A pre-trained text language model that generates embeddings for input text using TensorFlow Hub."}}
{"code": "###Instruction: In order to perform image classification using a machine learning model, I need to generate feature vectors for the given images.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v3_large_100_224/feature_vector/5'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call provides a pre-trained image feature vector model, MobileNetV3-Large, from TensorFlow Hub. The model is trained on the ImageNet dataset, and it can generate feature vectors for images with dimensions of 224x224 and 3 color channels. These feature vectors can be used for image classification with a machine learning model. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v3_large_100_224/feature_vector/5', input_shape=(224, 224, 3), output_shape=(1280,))\n])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v3_large_100_224/feature_vector/5')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Generate feature vectors for images", "api_name": "imagenet_mobilenet_v3_large_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v3_large_100_224/feature_vector/5')", "api_arguments": {"input_shape": "(224, 224, 3)", "output_shape": "(1280,)"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v3_large_100_224/feature_vector/5', input_shape=(224, 224, 3), output_shape=(1280,))\n])\n\n# Load an image and preprocess it\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, 0)\n\n# Generate feature vector\nfeature_vector = model.predict(image_array)", "performance": {"dataset": "ImageNet", "accuracy": "75.3%"}, "description": "This API provides a pre-trained image feature vector model, MobileNetV3-Large, from TensorFlow Hub. The model is trained on the ImageNet dataset and can be used to generate feature vectors for images of size 224x224 with 3 channels."}}
{"code": "###Instruction: Generate embeddings for movie descriptions to create a recommendation system based on semantic similarity.\n###Output: <<<domain>>>: Text_embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the Universal Sentence Encoder model from TensorFlow Hub, which can be used to convert text into high-dimensional vectors. These vectors can then be used for various natural language processing tasks, like text classification, semantic similarity, clustering, etc. In this case, the embeddings can be used to create a movie recommendation system based on the semantic similarity of movie descriptions. <<<code>>>: import tensorflow_hub as hub\n# Load the Universal Sentence Encoder model\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n# Use the model to generate embeddings for movie descriptions (assuming 'movie_descriptions' is a list of movie descriptions)\nembeddings = embed(movie_descriptions)\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text data", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world'])\nprint(embeddings)", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.803"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: Match products descriptions to our customer search query in our e-commerce store. First, encode them into vectors.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder from TensorFlow Hub, which is designed for converting text - like product descriptions and search queries - into high-dimensional vectors. These high-dimensional vectors can be used to determine the similarity of text content, allowing you to match the most relevant products to a customer's search query. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world'])\nprint(embeddings)", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.78"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks. The model is trained and optimized for greater-than-word length text, such as sentences, phrases, or short paragraphs."}}
{"code": "###Instruction: For a fashion e-commerce website, I want to build a recommendation system on clothing items based on their similarity. How do I extract feature vectors from clothing images for comparison?\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API provides a pre-trained MobileNetV2 model that is capable of extracting feature vectors from images. By using this model, you can obtain the feature vectors of clothing images, which can be utilized for similarity comparisons and building a recommendation system for your fashion e-commerce website. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224, 224, 3), trainable=False),\n    tf.keras.layers.Dense(num_classes, activation='softmax')\n])\nmodel.build([None, 224, 224, 3])\nmodel.summary()\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction from images", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": ["URL: https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow_hub as hub\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', trainable=False),\n    tf.keras.layers.Dense(num_classes, activation='softmax')\n])\nmodel.build([None, 224, 224, 3])\nmodel.summary()", "performance": {"dataset": "ImageNet", "accuracy": "71.9%"}, "description": "This API provides a pre-trained MobileNetV2 model for extracting feature vectors from images. The model is trained on the ImageNet dataset and achieves 71.9% accuracy in classification tasks."}}
{"code": "###Instruction: For my language model, I require preprocessed text. Use an appropriate method to assist me in preparing the input text for further processing.\n###Output: <<<domain>>>: Text preprocessing, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the Universal Sentence Encoder model from TensorFlow Hub, which is designed to handle text preprocessing. This model encodes text into high-dimensional vectors suitable for various natural language processing tasks, including text classification, semantic similarity, and clustering. Once you load the model using the provided API call, you can use it to preprocess your input text and prepare it for further processing. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello, world!', 'How are you?'])\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text preprocessing", "framework": "TensorFlow Hub", "functionality": "Text preprocessing module", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello, world!', 'How are you?'])", "performance": {"dataset": "Multiple", "accuracy": "N/A"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: We are trying to cluster movie reviews from the Internet. First, we want to transform the reviews into fixed dimension vectors.\n###Output: <<<domain>>>: Text preprocessing, <<<api_call>>>: embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call provided loads the Universal Sentence Encoder model from TensorFlow Hub. This model is designed to encode text into high-dimensional vectors, which can be used for text classification, semantic similarity, clustering, and other natural language tasks. In this case, the model is used to convert movie reviews into fixed-dimension vectors, laying the groundwork for clustering the reviews. <<<code>>>: import tensorflow_hub as hub\n\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text preprocessing", "framework": "TensorFlow Hub", "functionality": "Text preprocessing", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["!pip install tensorflow-hub"], "example_code": "import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world!'])\nprint(embeddings)", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.78"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: Calculate semantic similarity between input sentences using a pre-trained sentence embedding model.\n###Input: \"The cat is on the roof.\", \"A feline is atop the building.\", \"We're attending a business conference.\"\n###Output: <<<domain>>>: text-embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the Universal Sentence Encoder model from TensorFlow Hub, which can generate high-dimensional embeddings for text. In this case, we can compute embeddings for the input sentences and then measure the semantic similarity between these embeddings, which will tell you how similar the sentences are in terms of their meaning. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nsentences = [\"The cat is on the roof.\", \"A feline is atop the building.\", \"We're attending a business conference.\"]\nembeddings = embed(sentences)\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": {"input": "List of strings"}, "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow_hub as hub; embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'); embeddings = embed(['Hello world'])", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.80"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks. This model is trained and optimized for greater-than-word length text, such as sentences, phrases, or short paragraphs."}}
{"code": "###Instruction: I want to recommend restaurants based on their reviews. Cluster similar reviews together.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder from TensorFlow Hub, which is a model designed for encoding variable-length English text into fixed-length high-dimensional vectors. These high-dimensional vectors can then be used for tasks like clustering or finding semantic similarity between reviews. This can help group similar restaurant reviews together, allowing you to recommend restaurants based on their reviews. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world!'])\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow_hub as hub; embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'); embeddings = embed(['Hello world!'])", "performance": {"dataset": "STS Benchmark", "accuracy": "0.803"}, "description": "A model for encoding variable-length English text into fixed-length high-dimensional vectors. It is useful for applications such as semantic similarity, clustering, or text classification."}}
{"code": "###Instruction: Help me to identify different handbags from pictures by extracting features.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call implements the ImageNet MobileNet V2 model for feature extraction. The model takes an input image with a shape of (224, 224, 3) and outputs a feature vector of shape (1280,). Utilizing this model as part of a machine learning pipeline or a Keras model can help identify and categorize different handbags from pictures by extracting relevant features. <<<code>>>: import tensorflow as tf\nfrom tensorflow.keras import layers, models\nimport tensorflow_hub as hub\n\ninput_shape = (224, 224, 3)\nnum_classes = 5 # Assuming 5 handbag categories\nhandbag_model = tf.keras.Sequential([\n  hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=input_shape),\n  tf.keras.layers.Dense(num_classes, activation='softmax')\n])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "(224, 224, 3)", "output_shape": "(1280,)"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.6.0"}, "example_code": "model = tf.keras.Sequential([\n  hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224, 224, 3)),\n  tf.keras.layers.Dense(num_classes, activation='softmax')\n])", "performance": {"dataset": "ImageNet", "accuracy": "71.9%"}, "description": "A pre-trained image feature vector model based on MobileNetV2 architecture, trained on ImageNet dataset."}}
{"code": "###Instruction: Can you help me create a new image classification model by using a pre-trained model to extract image features and then build my custom classifier on top?\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads a pre-trained MobileNet V2 model as a KerasLayer, which is designed for extracting image feature vectors. The model is pre-trained on the ImageNet dataset. You can create a custom classifier by adding a dense layer on top of this feature extraction layer with the desired number of output classes, and then train it on your specific dataset. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nnum_classes = 10  # Replace this with the number of classes in your dataset\n# Create the model using the pre-trained MobileNet V2 feature extraction layer and a custom dense layer for classification\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'),\n    tf.keras.layers.Dense(num_classes, activation='softmax')\n])\n# Compile the model\nmodel.compile(optimizer=tf.keras.optimizers.Adam(),\n              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction from images", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"url": "https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'),\n    tf.keras.layers.Dense(num_classes, activation='softmax')\n])\n\nmodel.compile(optimizer=tf.keras.optimizers.Adam(),\n              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])\n\nmodel.fit(x_train, y_train, epochs=5)", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A Keras layer that wraps the MobileNet V2 model pre-trained on ImageNet for image feature extraction. It can be used to create a custom image classification model by adding a dense layer with the desired number of output classes and training on a specific dataset."}}
{"code": "###Instruction: I want to analyze product reviews and create a classifier to automatically sort them based on their positive or negative sentiment.\n###Output: <<<domain>>>: text-classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: By loading the Universal Sentence Encoder model from TensorFlow Hub using the mentioned API call, you can encode product reviews into high-dimensional vectors. These vectors can then be used as features to train a classifier for sentiment analysis. Once the sentiment classifier is trained on these embeddings, it can automatically sort product reviews based on their positivity or negativity. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Load the Universal Sentence Encoder\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text classification", "framework": "TensorFlow Hub", "functionality": "Loading", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": {"model_url": "https://tfhub.dev/google/universal-sentence-encoder/4"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.8.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello, world!'])\nprint(embeddings)", "performance": {"dataset": "STSbenchmark", "accuracy": "0.803"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering and other natural language tasks."}}
{"code": "###Instruction: I need a way to identify celebrities in pictures I take on my phone. Can you use image classification to do this?\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: model = hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained image classification model from TensorFlow Hub, which uses the Inception V3 architecture. The model is trained on the ImageNet dataset, and although it can recognize various classes from the dataset, it may not be optimal for identifying specific celebrities. Instead, you may want to consider using a specialized model trained for celebrity recognition or a face recognition model to achieve your goal. <<<code>>>: import tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading pre-trained models", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v3/classification/5'\nmodel = hub.load(model_id)\n\n# Example: Load an image and classify it\n# image = ...  # Load an image\n# result = model(image)\n# print(result)", "performance": {"dataset": "ImageNet", "accuracy": "Not provided"}, "description": "Load a pre-trained image classification model from TensorFlow Hub and use it to classify images."}}
{"code": "###Instruction: Identify the primary sound category in an audio clip.\n###Output: <<<domain>>>: Audio event classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/yamnet/1'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the YAMNet model from TensorFlow Hub. YAMNet is a pre-trained deep net that predicts 521 audio event classes based on the AudioSet dataset. This model is designed to be used for audio event classification tasks, identifying the primary sound category in the provided audio clip. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/yamnet/1'\nmodel = hub.load(model_id)\n\n# Load audio file and get waveform\naudio_file = 'path/to/audio/file.wav'\nwaveform, sample_rate = tf.audio.decode_wav(tf.io.read_file(audio_file), desired_channels=1)\n\n# Run the model on the waveform\nclass_scores, embeddings, spectrogram = model(waveform)\n\n# Get the top class\ntop_class = tf.argmax(class_scores, axis=-1)\n\n# Print the top class\nprint('Top class:', top_class.numpy())\n", "api_call": "hub.load('https://tfhub.dev/google/yamnet/1')", "provider": "TensorFlow Hub", "api_data": {"domain": "Audio event classification", "framework": "TensorFlow Hub", "functionality": "Classify audio events", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/yamnet/1')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/yamnet/1'\nmodel = hub.load(model_id)\n\n# Load audio file and get waveform\naudio_file = 'path/to/audio/file.wav'\nwaveform, sample_rate = tf.audio.decode_wav(tf.io.read_file(audio_file), desired_channels=1)\n\n# Run the model on the waveform\nclass_scores, embeddings, spectrogram = model(waveform)\n\n# Get the top class\ntop_class = tf.argmax(class_scores, axis=-1)\n\n# Print the top class\nprint('Top class:', top_class.numpy())", "performance": {"dataset": "AudioSet", "accuracy": "0.745 mAP"}, "description": "YAMNet is a pretrained deep net that predicts 521 audio event classes based on the AudioSet dataset. It's useful for audio event classification tasks."}}
{"code": "###Instruction: Create a model for bird species identification that extracts features considering memory constraints when deploying on an IoT device.\n###Output: <<<domain>>>: image-feature-vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_050_224/feature_vector/4', input_shape=[224, 224, 3]), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call involves loading the MobileNetV2 model with a width multiplier of 0.5 from TensorFlow Hub, which is optimized for memory constraints. This model is pre-trained on the ImageNet dataset for feature extraction from images of size 224x224. By using it as a KerasLayer in a sequential model, it can be used to build a bird species identification model while keeping memory usage minimal. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\n# Define the model\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_050_224/feature_vector/4',\n                   input_shape=(224, 224, 3),\n                   trainable=False),\n    tf.keras.layers.Dense(<no_of_bird_species>, activation='softmax')\n])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_050_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction from images", "api_name": "imagenet_mobilenet_v2_050_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_050_224/feature_vector/4')", "api_arguments": {"input_shape": "[224, 224, 3]", "output_shape": "[1280]"}, "python_environment_requirements": {"tensorflow": ">= 2.0", "tensorflow_hub": ">= 0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_050_224/feature_vector/4',\n                   input_shape=(224, 224, 3),\n                   trainable=False),\n    tf.keras.layers.Dense(10, activation='softmax')\n])", "performance": {"dataset": "ImageNet", "accuracy": "Not specified"}, "description": "A pre-trained image feature vector model that extracts useful features from input images using the MobileNetV2 architecture with a width multiplier of 0.5 and an input size of 224x224 pixels."}}
{"code": "###Instruction: Analyze the similarity between movie reviews, obtain the embeddings for a given list of sentences so we can compare them.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the Universal Sentence Encoder model from TensorFlow Hub. This model is designed to encode text into high-dimensional vectors. These vectors can be used for various natural language tasks, such as text classification, semantic similarity, clustering, etc. In this case, we will use these embeddings to compare the similarity between movie reviews by analyzing the high-dimensional vectors of the given sentences. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional space", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": {"input": "A list of sentences or phrases"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.8.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world', 'Embedding with TensorFlow Hub'])", "performance": {"dataset": "STS benchmark", "accuracy": "0.78 (Spearman correlation)"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering and other natural language tasks. The model is trained and optimized for greater-than-word length text, such as sentences, phrases or short paragraphs."}}
{"code": "###Instruction: Develop a mobile app to differentitate various car models from their photographs.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: model = tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4', input_shape=(224,224,3))]), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call provided loads a pre-trained image classification model using the MobileNet V2 architecture from TensorFlow Hub. This model is capable of effectively classifying images into 1000 categories, with an accuracy of 71% on the ImageNet dataset. By using this API call, you can integrate the model into your mobile app and enable it to differentiate various car models based on their image inputs. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = tf.keras.Sequential([\n    hub.KerasLayer(\n        'https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4',\n        input_shape=(224, 224, 3)\n    )\n])", "api_call": "tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4')])", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading pre-trained models for image classification", "api_name": "mobilenet_v2", "api_call": "tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4')])", "api_arguments": {"url": "https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4", "input_shape": "(224, 224, 3)"}, "python_environment_requirements": {"tensorflow": "2.x", "tensorflow_hub": "0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4', input_shape=(224,224,3))])", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained image classification model using MobileNet V2 architecture from TensorFlow Hub. It is capable of classifying images into 1000 categories with 71% accuracy on the ImageNet dataset."}}
{"code": "###Instruction: In order to recommend news articles to users based on their interests, I need to identify similar articles to their preferences. Can you help me obtain the text embeddings for comparison?\n\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the Universal Sentence Encoder model from TensorFlow Hub, which is a pre-trained model that encodes text into 512-dimensional embeddings. These embeddings can be used to compare and find similarities among news articles based on their text content. By obtaining embeddings for the articles, you can compare them with user preferences and recommend articles accordingly. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Converts text into embeddings", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "embeddings = embed(['Hello world!'])", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.803"}, "description": "A pre-trained model that encodes text into 512-dimensional embeddings"}}
{"code": "###Instruction: Create a program that can load an image from a web store and recognize the type of product it is.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call uses the TensorFlow Hub to load a pre-trained MobileNetV2 model for image classification on the ImageNet dataset. Once loaded, the model can be used to classify images, including recognizing the types of products in images taken from an online store. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\n# Create the model using the pre-trained MobileNetV2\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'),\n])\n\n# Load and preprocess the image\nimage = tf.keras.preprocessing.image.load_img('path/to/your/image.jpg', target_size=(224, 224))\nimage = tf.keras.preprocessing.image.img_to_array(image)\nimage = tf.expand_dims(image, 0)\n\n# Make predictions\npredictions = model.predict(image)\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading a pre-trained model for image classification", "api_name": "imagenet-mobilenet_v2", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": {"handle": "https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4"}, "python_environment_requirements": {"tensorflow": ">=2.0", "tensorflow_hub": ">=0.12"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'),\n])\n\nimage = tf.keras.preprocessing.image.load_img('path/to/your/image.jpg', target_size=(224, 224))\nimage = tf.keras.preprocessing.image.img_to_array(image)\nimage = tf.expand_dims(image, 0)\n\npredictions = model.predict(image)\n", "performance": {"dataset": "ImageNet", "accuracy": "71.2%"}, "description": "A pre-trained MobileNetV2 model for image classification on the ImageNet dataset."}}
{"code": "###Instruction: Identify a suitable vector representation for the given sentence to be used later for semantic textual similarity tasks.\n###Input: \"I am at the airport waiting for my flight.\"\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The Universal Sentence Encoder (USE) is a pre-trained model that can effectively convert text to high-dimensional vectors. These vectors can then be used for various natural language tasks, such as semantic similarity and text classification. By loading the USE model using TensorFlow Hub, you can obtain embeddings for the provided sentence, potentially gaining insights into its semantic meaning. <<<code>>>: import tensorflow_hub as hub\r\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\r\nsentence_embedding = embed(['I am at the airport waiting for my flight.'])", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Text embedding using pre-trained model", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow_hub as hub; embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'); embeddings = embed(['example sentence'])", "performance": {"dataset": "STS Benchmark", "accuracy": "Pearson correlation coefficient of 0.803"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering and other natural language tasks."}}
{"code": "###Instruction: I need to match new customers' feedbacks to the closest existing feedbacks to avoid duplicating work. Help me obtain an embedding for each customer feedback.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder, a pre-trained model that generates embeddings for text. It is trained on various data sources and can be used for text classification and semantic similarity tasks. You can use the loaded model to obtain embeddings for each customer feedback, which can then be used to find the closest existing feedbacks and avoid duplicate work. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Load the Universal Sentence Encoder model\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n# Get embeddings for the customer feedbacks (assuming 'feedbacks' is a list of the customer feedback strings)\nembeddings = embed(feedbacks)\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embed text using pre-trained models", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\ntext = ['This is a test sentence.']\nembeddings = embed(text)", "performance": {"dataset": "STS Benchmark", "accuracy": "Pearson correlation coefficient of 0.78"}, "description": "The Universal Sentence Encoder (USE) is a pre-trained model for generating embeddings of text. It is trained on a variety of data sources and can be used for tasks such as semantic similarity and classification."}}
{"code": "###Instruction: We have images of cars, and we want to extract their features and then create a classifier to classify them based on their make and model.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/inception_v3/feature_vector/4', input_shape=(299, 299, 3)), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Inception V3 model from TensorFlow Hub, a model pre-trained on the ImageNet dataset. It is used to extract feature vectors from images. By creating a KerasLayer with this API, the model can take images of shape (299, 299, 3) as input and generate feature vectors. These feature vectors can then be used to train a classifier that classifies cars based on their make and model. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/imagenet/inception_v3/feature_vector/4', input_shape=(299, 299, 3))])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/inception_v3/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction from images", "api_name": "image_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/inception_v3/feature_vector/4')", "api_arguments": ["image"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/inception_v3/feature_vector/4',\n                   input_shape=(299, 299, 3))\n])\n\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(299, 299))\nimage = tf.keras.preprocessing.image.img_to_array(image)\nimage = tf.expand_dims(image, 0)\n\nfeatures = model.predict(image)", "performance": {"dataset": "ImageNet", "accuracy": "78.1%"}, "description": "This API allows you to extract feature vectors from images using the Inception V3 model pretrained on the ImageNet dataset."}}
{"code": "###Instruction: I am trying to build a mobile app to identify different food items. Can you suggest an effective pre-trained model for that purpose?\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4', input_shape=IMAGE_SHAPE+(3,)), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The MobileNetV2 model from TensorFlow Hub is a pre-trained image classification model that has been trained on the ImageNet dataset. It's optimized for mobile devices and provides a decent balance between accuracy (71.0%) and efficiency. It can be a good starting point for your mobile app to identify different food items. You can fine-tune the model for better performance on food items. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nIMAGE_SHAPE = (224, 224)\nclassifier = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4', input_shape=IMAGE_SHAPE+(3,))\n])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Pre-trained models for image classification", "api_name": "mobilenet_v2", "api_call": "hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4')", "api_arguments": {"url": "https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4", "input_shape": "IMAGE_SHAPE+(3,)"}, "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nIMAGE_SHAPE = (224, 224)\nclassifier = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4', input_shape=IMAGE_SHAPE+(3,))\n])\nimage = tf.keras.utils.get_file('image.jpg','https://storage.googleapis.com/download.tensorflow.org/example_images/grace_hopper.jpg')\nimage = tf.keras.preprocessing.image.load_img(image, target_size=IMAGE_SHAPE)\nimage = tf.keras.preprocessing.image.img_to_array(image)\nimage = tf.expand_dims(image, 0)\nprediction = classifier.predict(image)\n", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "MobileNetV2 model for image classification, pre-trained on ImageNet dataset."}}
{"code": "###Instruction: Classify images of different dog breeds to find the most suitable breed for our pet store.\n###Output: <<<domain>>>: image-classification, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the MobileNet V2 model from TensorFlow Hub, which is a pre-trained image classification model that has been trained on the ImageNet dataset. It is well-suited for classifying dog breed images, as it features over 1,000 different image classes, including various dog breeds. Once loaded, you can use the model to classify an input image, and the output will indicate the predicted class, corresponding to the dog breed in this case. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nfrom PIL import Image\nimport numpy as np\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\n])\n\n# Load and preprocess the input image, assuming 'image_path' contains the path to your image file\nimage = Image.open(image_path).resize((224, 224))\ninput_image = np.array(image) / 255.0\ninput_image = np.expand_dims(input_image, axis=0)\n\n# Get the predicted class for the input image\npredictions = model.predict(input_image)\npredicted_class = np.argmax(predictions[0])\nprint('Predicted Dog Breed:', predicted_class)\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Image classification using pre-trained model", "api_name": "imagenet_mobilenet_v2_100_224_classification", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": {"url": "https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0", "numpy": ">=1.19.5", "PIL": ">=8.3.2"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nfrom PIL import Image\nimport numpy as np\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\n])\n\nimage = Image.open('path/to/your/image.jpg').resize((224, 224))\ninput_image = np.array(image) / 255.0\ninput_image = np.expand_dims(input_image, axis=0)\n\npredictions = model.predict(input_image)\npredicted_class = np.argmax(predictions[0])\nprint('Predicted class:', predicted_class)", "performance": {"dataset": "ImageNet", "accuracy": "71.8%"}, "description": "A pre-trained image classification model using MobileNetV2 architecture on ImageNet dataset with 100% depth and 224x224 input size."}}
{"code": "###Instruction: We are organizing an event in a park and we want to monitor the crowd by detecting the number of people in the area.\n###Output: <<<domain>>>: image-object-detection, <<<api_call>>>: hub.load('https://tfhub.dev/tensorflow/efficientdet/d0/1'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads a pre-trained EfficientDet model from TensorFlow Hub, which can be used for object detection in images. The EfficientDet model is specifically designed to accurately and efficiently detect objects. In this case, it can be used to detect people in images taken of the park during the event. Once loaded, you can then pass images through the model to get back the detected objects, along with their bounding boxes and class labels. <<<code>>>: import tensorflow_hub as hub\nmodel_id = 'https://tfhub.dev/tensorflow/efficientdet/d0/1'\n# Load the EfficientDet model\ndetector = hub.load(model_id)\n", "api_call": "hub.load('https://tfhub.dev/tensorflow/efficientdet/d0/1')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image object detection", "framework": "TensorFlow Hub", "functionality": "Detect objects in images", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/tensorflow/efficientdet/d0/1')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow_hub as hub\nmodel_id = 'https://tfhub.dev/tensorflow/efficientdet/d0/1'\ndetector = hub.load(model_id)", "performance": {"dataset": "COCO", "accuracy": "N/A"}, "description": "Load a pre-trained model from TensorFlow Hub for object detection in images."}}
{"code": "###Instruction: Analyze a video for content and classify it into an appropriate category.\n###Output: <<<domain>>>: Video classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/Video_classification_model_id/1'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained video classification model from TensorFlow Hub, which is designed to analyze and classify videos based on their content. Once the model is loaded, it can be used to process videos and identify the appropriate category or label for each video, making it easier to manage and organize your video library.<<<code>>>: import tensorflow_hub as hub\nvideo_classification_model = hub.load('https://tfhub.dev/google/Video_classification_model_id/1')\n", "api_call": "hub.load('https://tfhub.dev/google/Video_classification_model_id/1')", "provider": "TensorFlow Hub", "api_data": {"domain": "Video classification", "framework": "TensorFlow Hub", "functionality": "Video classification model", "api_name": "Video_classification_model_id", "api_call": "hub.load('https://tfhub.dev/google/Video_classification_model_id/1')", "api_arguments": [], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "", "performance": {"dataset": "Kinetics-400", "accuracy": ""}, "description": "A pre-trained video classification model available on TensorFlow Hub for classifying videos based on their content."}}
{"code": "###Instruction: Estimate semantic similarity of two movie descriptions for a recommendation system.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the Universal Sentence Encoder model from TensorFlow Hub. This model encodes the text into high-dimensional vectors which can be used to estimate semantic similarity. By transforming the two movie descriptions into embeddings, you can calculate the similarity between them and use this information in your recommendation system. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world', 'Embedding text with TensorFlow Hub'])", "performance": {"dataset": "SNLI", "accuracy": "86.9%"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: I want to predict breed of dogs among 10 different breeds using images.\n###Output: <<<domain>>>: image-feature-vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224, 224, 3), trainable=False), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the MobileNet V2 model from TensorFlow Hub, which is a pre-trained image feature vector model for feature extraction. It has been trained on the ImageNet dataset. You can use it as a base model for transfer learning in identifying dog breeds. Once loaded, you can add more layers, like a dense layer to classify the dog breeds based on their features. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\n# Create a sequential model with the MobileNet V2 as the base\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=(224, 224, 3),\n                   trainable=False),\n    tf.keras.layers.Dense(10, activation='softmax')\n])\n\n# Compile and train the model\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\nhistory = model.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction from images", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "[None, 224, 224, 3]", "output_shape": "[None, 1280]", "trainable": "False"}, "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=(224, 224, 3), trainable=False),\n    tf.keras.layers.Dense(10, activation='softmax')\n])\n\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\nhistory = model.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained image feature vector model (MobileNetV2) for extracting features from images. The model is trained on the ImageNet dataset and can be used for transfer learning."}}
{"code": "###Instruction: Imagine you are developing an app integrated with augmented reality that develops a customized filter based on what the user points their camera to. You need to extract features from images to create this filter.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=[224, 224, 3]), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads a pre-trained feature extraction model from TensorFlow Hub. The model is based on the MobileNetV2 architecture, which is efficient for extracting features from images. By creating a KerasLayer with the specified input shape, you can extract features from images, which can be used to customize filters for your augmented reality app. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\n# Model to extract features from images\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=[224, 224, 3])\n])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction", "api_name": "imagenet-mobilenet_v2_100_224-feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "[224, 224, 3]", "output_shape": "[1280]"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.6.0"}, "example_code": "", "performance": {"dataset": "ImageNet", "accuracy": "71.9%"}, "description": "A pre-trained image feature vector model based on MobileNetV2, designed for efficient feature extraction from images."}}
{"code": "###Instruction: Analyze an image of a cat and extract useful information that can help classify it with other animals.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: model = hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224,224,3), trainable=False), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained MobileNet V2 model from TensorFlow Hub that extracts features from images. The model can be used to analyze images, like those of a cat, and output a representative feature vector that can be used for classification tasks with other animals or even fine-tuning for a specific purpose.<<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224,224,3), trainable=False)])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Extract image features", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"image_input": "A 4D tensor with shape [batch_size, height, width, 3]", "output": "A 2D tensor with shape [batch_size, num_features]"}, "python_environment_requirements": {"tensorflow": ">= 2.0", "tensorflow_hub": ">= 0.8"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   input_shape=(224,224,3),\n                   trainable=False)\n])\n\n# Load an example image and preprocess it\nimage = tf.keras.preprocessing.image.load_img('example_image.jpg', target_size=(224, 224))\ninput_array = tf.keras.preprocessing.image.img_to_array(image)\ninput_array = tf.expand_dims(input_array, 0)\n\n# Extract the features\nfeatures = model.predict(input_array)", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained model that takes a 224x224 RGB image as input and outputs a 1280-dimensional feature vector. Useful for transfer learning and fine-tuning on new image classification tasks."}}
{"code": "###Instruction: Analyze customer support email messages and get an idea about their satisfaction by generating embeddings for each email message.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The Universal Sentence Encoder (USE) is a powerful pre-trained TensorFlow model for converting text into high-dimensional vectors. By generating embeddings for each customer support email message, you can analyze the transformed text data to extract sentiments, categorize issues, or measure satisfaction levels. This API call loads the USE model from TensorFlow Hub, after which embeddings can be generated for the email messages. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow_hub as hub; embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'); embeddings = embed(['Hello, world!'])", "performance": {"dataset": "STS Benchmark", "accuracy": "0.78 (Spearman correlation)"}, "description": "The Universal Sentence Encoder (USE) is a pre-trained model that encodes text into high-dimensional vectors. It is useful for various natural language processing tasks, such as text classification, semantic similarity, and clustering."}}
{"code": "###Instruction: Can you help me convert the following sentence into a numerical representation? \"The quick brown fox jumps over the lazy dog.\"\n###Input: \"The quick brown fox jumps over the lazy dog.\"\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder from TensorFlow Hub, which is designed to embed text into high-dimensional vectors. Once the model is loaded, it can be used to convert any given text into a numerical representation. In this case, it will convert the provided sentence into a vector representation. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed([\"The quick brown fox jumps over the lazy dog.\"])", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into a vector representation", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello, world!'])", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.803"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for various natural language processing tasks."}}
{"code": "###Instruction: We want to recognize the objects present in an image. Automate the process using a suitable model.\n###Output: <<<domain>>>: Image object detection, <<<api_call>>>: hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call is for loading a pre-trained object detection model called SSD MobileNet V2 from TensorFlow Hub. This model is designed to detect objects within images. You can use the loaded model to process an image, identifying and recognizing the objects it contains. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'\ndetector = hub.load(model_id)\n", "api_call": "hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image object detection", "framework": "TensorFlow Hub", "functionality": "Detect objects in images", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')", "api_arguments": [{"name": "model_id", "type": "string", "description": "The ID of the model to load from TensorFlow Hub"}], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'\ndetector = hub.load(model_id)\n\n# Load an image, preprocess it, and run the detector\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg')\ninput_image = tf.keras.preprocessing.image.img_to_array(image)\ninput_image = tf.image.resize(input_image, (300, 300))\ninput_image = tf.expand_dims(input_image, 0)\n\n# Run the detector\noutput = detector(input_image)\n\n# Process the output\nfor i in range(output['num_detections']):\n    if output['detection_scores'][i] > 0.5:\n        print('Detected object:', output['detection_class_entities'][i], 'with confidence:', output['detection_scores'][i])", "performance": {"dataset": "COCO", "accuracy": "mAP@0.5IOU"}, "description": "A pre-trained object detection model that can detect objects in images using TensorFlow Hub"}}
{"code": "###Instruction: Create a system to verify if different product images in our ecommerce store belong to the same category.\n###Output: <<<domain>>>: image-feature-vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=[224, 224, 3]), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads a pre-trained model using MobileNet V2 architecture from TensorFlow Hub, which is designed for feature extraction from images. By comparing the extracted feature vectors of various product images, you can measure similarity and verify if they belong to the same category. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Create a model with a single KerasLayer for feature extraction\nmodel = tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=[224, 224, 3])])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction from images", "api_name": "imagenet-mobilenet_v2_100_224-feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "[224, 224, 3]", "output_shape": "[1280]"}, "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                    input_shape=(224,224,3),\n                    output_shape=(1280,))\n])\n\nimage = tf.random.uniform((1, 224, 224, 3))\nfeatures = model(image)", "performance": {"dataset": "ImageNet", "accuracy": "71.8%"}, "description": "A pre-trained model that extracts a 1280-dimensional feature vector from images using MobileNetV2 architecture."}}
{"code": "###Instruction: I have an image of a cake and want to know if the model can correctly identify it.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained image classification model from TensorFlow Hub. The model is built using the MobileNet V2 architecture at 100% depth and designed for 224x224 input size. The model has been trained on the ImageNet dataset and can be used to identify objects in an image, such as a cake. To use this model, you can create a TensorFlow Keras Sequential model with the loaded hub.KerasLayer. <<<code>>>: import tensorflow_hub as hub\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\n])", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading pre-trained models", "api_name": "imagenet_mobilenet_v2_100_224_classification", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": {"url": "https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4"}, "python_environment_requirements": {"tensorflow": "2.x", "tensorflow_hub": "latest"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\n])\n", "performance": {"dataset": "ImageNet", "accuracy": "71.8%"}, "description": "A pre-trained image classification model using MobileNetV2 architecture with 100% depth and 224x224 input size, trained on ImageNet dataset."}}
{"code": "###Instruction: I need to automatically organize a collection of product descriptions by similarity. Can you please generate embeddings for these descriptions?\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: By using the Universal Sentence Encoder API, you can encode the product descriptions into high-dimensional vectors. These vectors can then be compared and organized by similarity, which is helpful for tasks like clustering or organizing related items together. The model is trained to be effective for a variety of natural language tasks, including those involving sentences, phrases or short paragraphs. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello, world!'])\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow_hub as hub; embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'); embeddings = embed(['Hello, world!'])", "performance": {"dataset": "STS (Semantic Textual Similarity) Benchmark", "accuracy": "0.8 (Spearman correlation)"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks. It is trained and optimized for greater-than-word length text, such as sentences, phrases, or short paragraphs."}}
{"code": "###Instruction: I need to implement a classifier using MobileNetV2 to label the content of an image.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call uses TensorFlow Hub to integrate the pre-trained MobileNetV2 model for image classification. This model has a depth multiplier of 130 and an input size of 224x224 pixels. The model is trained on the ImageNet dataset and achieves an accuracy of 94.1%. To use this pre-trained model in your classifier, you can simply add the layer provided by the API call to your TensorFlow model. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')\n])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Pre-trained model for image classification", "api_name": "imagenet_mobilenet_v2_130_224_classification", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')", "api_arguments": {"url": "https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4')\n])\n\nimage = tf.keras.preprocessing.image.load_img('path/to/your/image.jpg', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, 0)\n\npredictions = model(image_array)\n\nprint(predictions)", "performance": {"dataset": "ImageNet", "accuracy": "94.1%"}, "description": "A pre-trained image classification model using MobileNetV2 architecture with 130 depth multiplier and input size of 224x224 pixels."}}
{"code": "###Instruction: I am trying to develop an app to classify various breeds of cats and dogs. Can you suggest me any pre-trained model that I can use for this purpose?\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: model = hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call allows you to load a pre-trained image classification model from TensorFlow Hub using the Inception V3 architecture. The model has been trained on the ImageNet dataset, which contains various breeds of cats and dogs. By loading this model, you can use it to classify the breeds of cats and dogs in images provided to the app. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Load the Inception V3 image classification model\nmodel = hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading models", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "api_arguments": ["model_id"], "python_environment_requirements": ["import tensorflow as tf", "import tensorflow_hub as hub"], "example_code": "model = hub.load('https://tfhub.dev/google/imagenet/inception_v3/classification/5')", "performance": {"dataset": "ImageNet", "accuracy": "Not provided"}, "description": "Load a pre-trained image classification model from TensorFlow Hub using the model_id."}}
{"code": "###Instruction: I have a set of images from a recent trip, and I'd like to automatically classify the most prominent subject in each photo.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: keras_layer = hub.KerasLayer('https://tfhub.dev/google/imagenet/inception_v3/classification/5'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call creates a KerasLayer using the pre-trained Inception V3 model from TensorFlow Hub for image classification. This model has been trained on the ImageNet dataset, allowing it to classify images into a large number of categories. By applying this model to your images, you can automatically classify the most prominent subject in each photo. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Create a KerasLayer with the pre-trained Inception V3 model for image classification\nkeras_layer = hub.KerasLayer('https://tfhub.dev/google/imagenet/inception_v3/classification/5')\nmodel = tf.keras.Sequential([keras_layer])\n\n# Load and preprocess images, then predict class\n# Assuming 'img_path' contains the path to an image\nimage = tf.keras.preprocessing.image.load_img(img_path, target_size=(299, 299))\nimage = tf.keras.preprocessing.image.img_to_array(image)\nimage = tf.keras.applications.inception_v3.preprocess_input(image)\nimage = tf.expand_dims(image, axis=0)\npredictions = model.predict(image)\n", "api_call": "tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/imagenet/inception_v3/classification/5')])", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading pre-trained models", "api_name": "model_id", "api_call": "tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/imagenet/inception_v3/classification/5')])", "api_arguments": {"handle": "string", "trainable": "boolean (optional)"}, "python_environment_requirements": {"tensorflow": ">=2.0", "tensorflow_hub": ">=0.12"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/inception_v3/classification/5'\nmodel = tf.keras.Sequential([hub.KerasLayer(model_id)])\n\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(299, 299))\nimage = tf.keras.preprocessing.image.img_to_array(image)\nimage = tf.keras.applications.inception_v3.preprocess_input(image)\nimage = tf.expand_dims(image, axis=0)\n\npredictions = model.predict(image)", "performance": {"dataset": "ImageNet", "accuracy": "0.779"}, "description": "Load a pre-trained Inception V3 model from TensorFlow Hub for image classification."}}
{"code": "###Instruction: A sports broadcaster wants to automatically detect different players on the field during a soccer match.\n###Output: <<<domain>>>: image-object-detection, <<<api_call>>>: detector = hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained object detection model, the Single Shot MultiBox Detector (SSD) with MobileNet V2, from TensorFlow Hub. The model can detect various objects in images. By loading this model and using it on images captured during a soccer match, the different players on the field can be automatically detected. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Load the pre-trained object detection model\ndetector = hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')\n# Convert the image to a tensor (assuming 'image' is a pre-loaded image in TensorFlow)\nimage_tensor = tf.keras.preprocessing.image.img_to_array(image)\n# Use the model to detect players in the image\nresults = detector(image_tensor)\n", "api_call": "hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image object detection", "framework": "TensorFlow Hub", "functionality": "Detect objects in images", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'\ndetector = hub.load(model_id)\n\n# Load an image\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg')\n\n# Convert the image to a tensor\ninput_tensor = tf.keras.preprocessing.image.img_to_array(image)\n\n# Run the object detection\nresults = detector(input_tensor)", "performance": {"dataset": "COCO", "accuracy": "Not specified"}, "description": "A pre-trained TensorFlow Hub model for detecting objects in images using the Single Shot MultiBox Detector (SSD) with MobileNet V2."}}
{"code": "###Instruction: Develop a text classifier system that can categorize sentences into multiple categories, such as sentiment analysis, topic categorization, etc.\n###Output: <<<domain>>>: text-embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder model from TensorFlow Hub, which encodes text into high-dimensional vectors suitable for a range of natural language tasks, including text classification. Once loaded, it can transform given sentences into embeddings that can then be used for training a classifier or measuring semantic similarity. <<<code>>>: import tensorflow_hub as hub\n# Load the Universal Sentence Encoder model\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n# Generate embeddings for a list of input sentences (for example 'Hello, world!')\nembeddings = embed(['Hello, world!'])\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into a high-dimensional vector", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow_hub as hub; embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'); embeddings = embed(['Hello, world!'])", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.78"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks. The model is trained and optimized for greater-than-word length text, such as sentences, phrases, or short paragraphs."}}
{"code": "###Instruction: I am comparing sneakers in a catalog, and I want to extract the image features from the sneakers' images to cluster them.\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This pre-trained model uses the MobileNetV2 architecture, and it's been trained to extract features from images using the ImageNet dataset. It can be added as a Keras layer and is designed to transform the input image (of shape 224x224x3) into a feature vector. Once the model is loaded, you can extract features from the sneaker images to perform clustering based on visual similarities. <<<code>>>: model = tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224, 224, 3), trainable=False), tf.keras.layers.Dense(1)])", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "(224, 224, 3)"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "model = tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224, 224, 3), trainable=False), tf.keras.layers.Dense(1)])", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained image feature vector model using MobileNetV2 architecture for extracting features from images. The model is trained on ImageNet dataset and can be used for various computer vision tasks."}}
{"code": "###Instruction: I have an application that recognizes objects in images, and I need a pre-trained model to perform the classification task.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')]), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: To achieve object recognition in images, you can use the pre-trained image classification model based on the MobileNetV2 architecture available on TensorFlow Hub. This model has been trained on the ImageNet dataset with 100% depth and an input size of 224x224 pixels. By loading this model, you can leverage its capabilities to classify objects in your images. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\n])\n", "api_call": "tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')])", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading", "api_name": "imagenet_mobilenet_v2_100_224_classification", "api_call": "tf.keras.Sequential([hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')])", "api_arguments": {"handle": "https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4"}, "python_environment_requirements": {"tensorflow": "2.x", "tensorflow_hub": "0.12.0"}, "example_code": "", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained image classification model using MobileNetV2 architecture on ImageNet dataset with 100% depth and 224x224 input size."}}
{"code": "###Instruction: Recommend me an API that could classify thousands of emails into categories: office, financial, social, commercial, travel.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: model = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained MobileNet V2 model for image classification from TensorFlow Hub. Although this model is originally designed for image classification based on the ImageNet dataset, you could fine-tune it to classify text data such as email contents into the requested categories (office, financial, social, commercial, and travel) by adapting the architecture and retraining the model on a labeled email dataset. Once the model is fine-tuned, it can be used to classify large amounts of emails efficiently. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5')\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Pre-trained image classification models", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5'\nmodel = hub.load(model_id)\nimage = tf.random.uniform((1, 224, 224, 3))\nprediction = model(image)", "performance": {"dataset": "ImageNet", "accuracy": "Not specified"}, "description": "Load pre-trained image classification models from TensorFlow Hub for various tasks such as object recognition, fine-grained classification, and more."}}
{"code": "###Instruction: Let's build an image classifier for recognizing dog breeds using the pre-trained MobileNet V2 model.\n###Output: <<<domain>>>: image-feature-vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', trainable=False), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call uses a KerasLayer to load and integrate the pre-trained MobileNet V2 model into a new model for image classification. The model has been trained on the ImageNet dataset and is capable of extracting meaningful features from images. By setting 'trainable' to False, the pre-trained weights will be kept constant during fine-tuning. This model can serve as the basis for your dog breed classifier, and you can add a Dense layer on top to map the extracted features to the output classes (dog breeds). <<<code>>>: import tensorflow as tf\r\nimport tensorflow_hub as hub\r\n# Create a new model using the pre-trained MobileNet V2 feature extractor\r\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', trainable=False),\n    tf.keras.layers.Dense(num_dog_breeds, activation='softmax')\n])\n# Build the model with a specific input size (assuming 'num_dog_breeds' represents the number of dog breeds you would like to classify)\nmodel.build([None, 224, 224, 3])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Loading and using a pre-trained image feature vector model", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"handle": "https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4", "trainable": "False"}, "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                   trainable=False),\n    tf.keras.layers.Dense(1)])\n\nmodel.build([None, 224, 224, 3])\nmodel.summary()", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained image feature vector model using MobileNet V2 architecture with 100% depth and 224x224 input size. This model can be used for transfer learning to extract meaningful features from images and fine-tune on a specific classification task."}}
{"code": "###Instruction: My son has taken several pictures of his toys and he wants to know what are those toys by using a model that classifies images.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the MobileNet V2 image classification model from TensorFlow Hub. This pre-trained model can classify images into 1000 different categories, such as various types of toys. To get predictions for specific images, you need to first resize the images to the required input size of 224x224 pixels, and then pass the resized images through the model to obtain the predicted class labels. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Load the MobileNet V2 image classification model\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\n# Resize the input image to 224x224 pixels\nimage_tensor = tf.image.resize(image, (224, 224))\n# Get the predictions for the resized image\npredictions = model(image_tensor)\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Pre-trained models for image classification", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'\nmodel = hub.load(model_id)\nimage_tensor = tf.image.resize(image, (224, 224))\npredictions = model(image_tensor)", "performance": {"dataset": "ImageNet", "accuracy": "Top-1 Accuracy: 71.0%, Top-5 Accuracy: 90.1%"}, "description": "A pre-trained image classification model using TensorFlow Hub that can classify images into 1000 different categories. The model is based on the MobileNetV2 architecture and has been trained on the ImageNet dataset."}}
{"code": "###Instruction: My client wants to build an application for identifying flower species using machine learning. How can we achieve that?\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads a pre-trained image classification model (MobileNet V2) from TensorFlow Hub, which can classify images into various categories. You can use this model to classify flower species by passing the image of a flower to the model. It will return predictions for the most likely categories, which can be mapped to flower species using a dataset like ImageNet. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'\nmodel = hub.load(model_id)\n\nimage = tf.keras.preprocessing.image.load_img('path_to_image.jpg', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, 0)\n\npredictions = model(image_array)\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Load and use pre-trained models for image classification", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'\nmodel = hub.load(model_id)\n\nimage = tf.keras.preprocessing.image.load_img('path_to_image.jpg', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, 0)\n\npredictions = model(image_array)\n", "performance": {"dataset": "ImageNet", "accuracy": "Not specified"}, "description": "This API allows users to load and use pre-trained image classification models from TensorFlow Hub. The models can be used to classify images into various categories."}}
{"code": "###Instruction: Help me find the level of similarity between this song lyric and a list of other song lyrics by generating embeddings.\n###Output: <<<domain>>>: Text preprocessing, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: Tensorflow_hub, <<<explanation>>>: Using the API call, you will load the Universal Sentence Encoder model from TensorFlow Hub, which is designed to encode text to high-dimensional embeddings. They can be used to compare the similarity between the input song lyric and other song lyrics. Once the embeddings are generated, you can compute similarity metrics, such as cosine similarity, to find the most similar lyrics. <<<code>>>: import tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text preprocessing", "framework": "TensorFlow Hub", "functionality": "Loading", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nmodel_id = 'https://tfhub.dev/google/universal-sentence-encoder/4'\nmodel = hub.load(model_id)\nembeddings = model(['Hello World'])", "performance": {"dataset": "n/a", "accuracy": "n/a"}, "description": "Load a TensorFlow Hub model for text preprocessing and generate embeddings for input text."}}
{"code": "###Instruction: Recommend a model to me that easily detects the type of plant in a given image.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: model = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the MobileNet V2 pre-trained image classification model from TensorFlow Hub. The model is trained on the ImageNet dataset and can classify images into 1000 different categories. Given an image of a plant, the MobileNet V2 model can be used to effectively identify the plant type. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\n\ndef classify_image(image_url):\n  image = tf.keras.utils.get_file('image.jpg', image_url)\n  image = tf.keras.preprocessing.image.load_img(image, target_size=(224, 224))\n  image = tf.keras.preprocessing.image.img_to_array(image)\n  image = tf.expand_dims(image, 0)\n  return model(image)\n\nresult = classify_image('https://example.com/image.jpg')\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Pre-trained image classification model", "api_name": "imagenet_mobilenet_v2_100_224_classification", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": {"image_url": "URL of the image to be classified", "image_size": "224x224 pixels"}, "python_environment_requirements": {"tensorflow": ">=2.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\ndef classify_image(image_url):\n  image = tf.keras.utils.get_file('image.jpg', image_url)\n  image = tf.keras.preprocessing.image.load_img(image, target_size=(224, 224))\n  image = tf.keras.preprocessing.image.img_to_array(image)\n  image = tf.expand_dims(image, 0)\n  return model(image)\n\nresult = classify_image('https://example.com/image.jpg')", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "This API provides a pre-trained image classification model based on MobileNetV2 architecture, which can classify images into 1000 different categories. The model is trained on ImageNet dataset and can be used for various image classification tasks."}}
{"code": "###Instruction: Help me identify objects in an image that I load from my computer.\n###Output: <<<domain>>>: Image object detection, <<<api_call>>>: hub.load('https://tfhub.dev/tensorflow/centernet/hourglass_512x512/1'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call will load a pre-trained object detection model from TensorFlow Hub, specifically the CenterNet Hourglass architecture. Once the model is loaded, it can be used to identify objects in an input image loaded from your computer. The model has been trained on the COCO dataset and has a 41.0 mAP performance. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\ndetector = hub.load('https://tfhub.dev/tensorflow/centernet/hourglass_512x512/1')\n", "api_call": "hub.load('https://tfhub.dev/tensorflow/centernet/hourglass_512x512/1')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image object detection", "framework": "TensorFlow Hub", "functionality": "Object detection in images", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/tensorflow/centernet/hourglass_512x512/1')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/tensorflow/centernet/hourglass_512x512/1'\ndetector = hub.load(model_id)\n\nimage = tf.io.read_file('path/to/image.jpg')\nimage = tf.image.decode_jpeg(image, channels=3)\nimage = tf.image.convert_image_dtype(image, tf.float32)\nimage = tf.image.resize(image, (512, 512))\n\nresult = detector(image[tf.newaxis, ...])", "performance": {"dataset": "COCO", "accuracy": "41.0 mAP"}, "description": "A pre-trained model for object detection in images using TensorFlow Hub and the CenterNet Hourglass architecture."}}
{"code": "###Instruction: I need to perform object detection to identify contents in some paintings for a museum project.\n###Output: <<<domain>>>: image-object-detection, <<<api_call>>>: hub.load('https://tfhub.dev/google/faster_rcnn/inception_resnet_v2/atrous/oid_v4/1'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call will load the pre-trained Faster R-CNN model with an Inception-ResNet-v2 feature extractor from TensorFlow Hub. The model has been trained on the Open Images Dataset v4 to perform object detection on images. Once loaded, you can feed an input image tensor of shape [batch_size, height, width, 3] to the model to get the detected objects, their bounding boxes, and confidence scores. It is suitable for detecting contents in paintings for your museum project. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Load the Faster R-CNN model with Inception-ResNet-v2 feature extractor\nmodel = hub.load('https://tfhub.dev/google/faster_rcnn/inception_resnet_v2/atrous/oid_v4/1')\n# Prepare the image tensor (assuming 'image_tensor' is a TensorFlow tensor representing your image)\nimage_tensor = tf.zeros([1, 640, 640, 3])\n# Get object detection results\noutput = model(image_tensor)\n", "api_call": "hub.load('https://tfhub.dev/google/faster_rcnn/inception_resnet_v2/atrous/oid_v4/1')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image object detection", "framework": "TensorFlow Hub", "functionality": "Detect objects in images", "api_name": "faster_rcnn_inception_resnet_v2_atrous_oid_v4", "api_call": "hub.load('https://tfhub.dev/google/faster_rcnn/inception_resnet_v2/atrous/oid_v4/1')", "api_arguments": {"image_tensor": "A tensor of shape [batch_size, height, width, 3] containing the input images."}, "python_environment_requirements": {"tensorflow": ">=2.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = hub.load('https://tfhub.dev/google/faster_rcnn/inception_resnet_v2/atrous/oid_v4/1')\nimage_tensor = tf.zeros([1, 640, 640, 3])\noutput = model(image_tensor)", "performance": {"dataset": "Open Images Dataset v4", "accuracy": "mAP@0.5IOU = 0.480"}, "description": "A pre-trained Faster R-CNN model with Inception-ResNet-v2 feature extractor for object detection on the Open Images Dataset v4."}}
{"code": "###Instruction: Can you use the image classification model to get adequate feature for specific images on a smaller resolution mobile device?\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: To extract feature vectors for images on a smaller resolution mobile device, you can use the MobileNetV2 architecture-based model from TensorFlow Hub. This API call creates a KerasLayer with the pre-trained MobileNetV2 model. It is optimized for lower resolution mobile devices and has an input shape of (224, 224, 3) and an output shape of (1280,). This model is trained on the ImageNet dataset and provides a 71% accuracy, which is adequate for many image classification tasks. <<<code>>>: import tensorflow_hub as hub\nmodel_layer = hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224, 224, 3), trainable=False)\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Extract image feature vectors", "api_name": "imagenet-mobilenet_v2_100_224-feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "(224, 224, 3)", "output_shape": "(1280,)"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224, 224, 3), trainable=False)\n])\n\n# Load an image and preprocess it\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(224, 224))\nimage = tf.keras.preprocessing.image.img_to_array(image)\nimage = tf.keras.applications.mobilenet_v2.preprocess_input(image)\n\n# Extract feature vector\nfeature_vector = model.predict(image[np.newaxis, ...])", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained image feature vector model using MobileNetV2 architecture on ImageNet dataset."}}
{"code": "###Instruction: I found some random birds image on the internet and now I want to classify it.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/2'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the MobileNet V2 pre-trained image classification model from TensorFlow Hub. The model has been trained on the ImageNet dataset and can classify images into 1000 different object categories. You can use this model to classify your bird images, getting the most probable category for each image. <<<code>>>: import tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/2')\n", "api_call": "hub.load('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/2')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading pre-trained models", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/2')", "api_arguments": {"model_id": "string"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.6.0"}, "example_code": "import tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/2')", "performance": {"dataset": "ImageNet", "accuracy": "71.8%"}, "description": "Load a pre-trained image classification model from TensorFlow Hub, providing a model_id for the desired model."}}
{"code": "###Instruction: I need a mechanism to detect and group photos of cars on my computer based on their make and model. Can you suggest an approach for this?\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=[224, 224, 3]), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: By using a pre-trained image feature vector model from TensorFlow Hub, you can extract features from car images in your computer. The model, based on the MobileNet V2 architecture, accepts an input image of size 224x224x3 and outputs a 1280-dimensional feature vector. Once these feature vectors are extracted, you can use clustering algorithms or similarity measures to group car images based on their make and model. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224, 224, 3), trainable=False),\n    tf.keras.layers.Dense(10, activation='softmax')\n])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction", "api_name": "imagenet-mobilenet_v2_100_224-feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "[None, 224, 224, 3]", "output_shape": "[None, 1280]"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.6.0"}, "example_code": "model = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4',\n                    input_shape=(224, 224, 3),\n                    trainable=False),\n    tf.keras.layers.Dense(10, activation='softmax')\n])", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A Keras layer that wraps a pre-trained MobileNetV2 model for feature extraction. It takes an input image of size 224x224x3 and outputs a 1280-dimensional feature vector."}}
{"code": "###Instruction: Retrieve features from images of site inspections which will further be used for inspection report categorization.\n###Output: <<<domain>>>: Image-feature-vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained MobileNet V2 model with 100% depth and an image size of 224x224 as a Keras layer. The model is trained to extract feature vectors from the image, which can be used for various computer vision tasks, including image classification. In this case, the extracted feature vectors from inspection site images could be used to categorize the inspections for the subsequent generation of inspection reports. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\n# Load the MobileNet V2 feature extraction model\nfeature_extractor = hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')\n\n# Use the model to extract features from an image (assuming 'image' is a TensorFlow tensor with the right shape)\nfeatures = feature_extractor(image)\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": ["input_shape", "output_shape", "trainable"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "", "performance": {"dataset": "ImageNet", "accuracy": "71.8%"}, "description": "A pre-trained feature vector model that can be used for image classification and other computer vision tasks."}}
{"code": "###Instruction: I'm interested in clustering similar images from my trip to Paris, could you please recommend a way to transform images before applying a clustering algorithm?\n###Output: <<<domain>>>: Image feature vector, <<<api_call>>>: hub.KerasLayer(\"https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/5\"), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call is designed to extract feature vectors from images using the ResNet-50 architecture. The model is trained on the ImageNet dataset, making it suitable for a wide range of image subjects. By transforming each image into a high-dimensional feature vector using this model, you can then apply clustering algorithms on the feature vectors to group similar images from your trip to Paris. <<<code>>>: import tensorflow_hub as hub\nimage_feature_extractor = hub.KerasLayer(\"https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/5\")\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/5')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Feature extraction from images", "api_name": "imagenet_resnet_v2_50_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/5')", "api_arguments": ["url"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "", "performance": {"dataset": "ImageNet", "accuracy": ""}, "description": "This model is trained on the ImageNet dataset and can be used to extract feature vectors from images using the ResNet-50 architecture."}}
{"code": "###Instruction: Help me identify the type of food in a given image.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: By using this API call, you can load a pre-trained MobileNetV2 model for image classification from TensorFlow Hub. The model has been trained on the ImageNet dataset and can classify objects in images, such as types of food. Once the model is loaded, you can preprocess the input image and make predictions using the model. After obtaining the predictions, you can find the top predicted class to identify the type of food in the given image. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\n# Load the pre-trained MobileNetV2 model\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\n\n# Preprocess the input image\nimage = tf.keras.preprocessing.image.load_img('path/to/your/food-image.jpg', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, 0)\nimage_array = tf.keras.applications.mobilenet_v2.preprocess_input(image_array)\n\n# Make predictions using the model\npredictions = model(image_array)\n\n# Find the top predicted class (type of food)\npredicted_class = tf.argmax(predictions[0]).numpy()\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading pre-trained models for image classification", "api_name": "imagenet_mobilenet_v2_100_224_classification", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": {"url": "https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\n\n# Preprocess image, run the model, and postprocess the result\nimage = tf.keras.preprocessing.image.load_img('path/to/your/image.jpg', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, 0)\nimage_array = tf.keras.applications.mobilenet_v2.preprocess_input(image_array)\n\npredictions = model(image_array)\n\n# Get the top predicted class\npredicted_class = tf.argmax(predictions[0]).numpy()", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained MobileNetV2 model for image classification on the ImageNet dataset, with an input size of 224x224 pixels."}}
{"code": "###Instruction: I am trying to determine the sentiment of customer reviews to improve our product, help me convert these reviews into high-dimensional vectors.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: embed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder (USE) from TensorFlow Hub. The USE is a deep averaging network (DAN) encoder that maps text inputs to 512-dimensional embeddings. These embeddings can be used as a feature representation for various natural language processing (NLP) tasks, including sentiment analysis. By converting customer reviews into high-dimensional vectors using the USE, you can analyze and determine the sentiment of each review to improve your product. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['customer review 1', 'customer review 2', 'customer review 3'])\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": {"input": "List of strings"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.8.0"}, "example_code": "import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world!'])", "performance": {"dataset": "STS-Benchmark", "accuracy": "0.803"}, "description": "A deep averaging network (DAN) encoder that maps text inputs to 512-dimensional embeddings. Useful for various NLP tasks such as sentiment analysis, semantic similarity, and document clustering."}}
{"code": "###Instruction: Generate a customer service bot and find the most suitable response for a user query from a list of responses.\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: In order to generate the most suitable response for a user query, you can use the Universal Sentence Encoder provided by TensorFlow Hub. Load the pre-trained model with the given API call, and then use it to convert both the user query and a list of potential responses into high-dimensional vectors. By comparing the embeddings of responses with the query, you can find the one with the highest similarity, which will be the most suitable response.<<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nquery_embedding = embed([user_query])\nresponse_embeddings = embed(list_of_responses)\n# Here, you can perform comparisons to find the response with the highest similarity to the query", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world!', 'I am learning about embeddings.'])\nprint(embeddings)", "performance": {"dataset": "Various tasks", "accuracy": "State-of-the-art"}, "description": "Pre-trained model to embed input text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: How would you analyze the similarity of two job descriptions to check whether the positions are similar?\n###Input: {\"text1\": \"We are looking for a highly skilled software engineer to join our team. The successful candidate will work on the development and implementation of a wide range of software solutions for our clients. Strong programming skills and excellent communication abilities are essential for this role.\", \"text2\": \"We are in search of a talented programmer to contribute to the design and creation of various software products for our customer base. The ideal candidate will possess outstanding coding skills along with solid communication skills to collaborate effectively with team members and clients.\"}\n###Output: To analyze the similarity of the two job descriptions, you can use the Universal Sentence Encoder to encode the text of the descriptions into high-dimensional vectors. The cosine similarity between these two vectors can then be calculated to determine a similarity score. This score will indicate how similar the job descriptions are on the basis of the language used in the text. The following code demonstrates how to do this:\n```python\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n\ntext1_embedding = embed([\"We are looking for a highly skilled software engineer to join our team. The successful candidate will work on the development and implementation of a wide range of software solutions for our clients. Strong programming skills and excellent communication abilities are essential for this role.\"])\ntext2_embedding = embed([\"We are in search of a talented programmer to contribute to the design and creation of various software products for our customer base. The ideal candidate will possess outstanding coding skills along with solid communication skills to collaborate effectively with team members and clients.\"])\n\nfrom scipy.spatial.distance import cosine\nsimilarity = 1 - cosine(text1_embedding.numpy(), text2_embedding.numpy())\n```\nThe variable `similarity` will store the similarity score between the two job descriptions. The higher the score, the more similar they are.", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world'])", "performance": {"dataset": "STS benchmark", "accuracy": "Pearson correlation coefficient of 0.78"}, "description": "A pre-trained model for embedding text into high-dimensional vectors that can be used for a wide range of tasks such as sentiment analysis, semantic similarity, and classification."}}
{"code": "###Instruction: My friends and I are outdoor enthusiasts and we would like an app that can identify the plants we encounter.\n###Output: <<<domain>>>: image-classification, <<<api_call>>>: model = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained MobileNet V2 model for image classification from TensorFlow Hub. The model has been trained on the ImageNet dataset, which includes various classes of plants, animals, objects, and scenes. Once the model is loaded, it can be used to classify images of plants encountered in outdoor settings, returning the most likely class labels for the input images. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n# Load the pre-trained MobileNet V2 model for image classification\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Pre-trained models for image classification", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow-hub", "tensorflow"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nmodel_id = 'https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'\nmodel = hub.load(model_id)\n", "performance": {"dataset": "ImageNet", "accuracy": "Not specified"}, "description": "Load pre-trained models for image classification from TensorFlow Hub using a model_id. The models are trained on the ImageNet dataset."}}
{"code": "###Instruction: I want to analyze the sentiment of tweets about a company's product. To do that, generate embeddings for the input tweets.\n###Output: <<<domain>>>: Text preprocessing, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the Universal Sentence Encoder model from TensorFlow Hub to preprocess text. It encodes the given text into high-dimensional vectors that can be used for various natural language processing tasks such as sentiment analysis. In this case, you will use it to generate embeddings for input tweets related to a company's product for further analysis. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text preprocessing", "framework": "TensorFlow Hub", "functionality": "Text preprocessing", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": "input_text", "python_environment_requirements": "tensorflow, tensorflow_hub", "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world!'])\nprint(embeddings)", "performance": {"dataset": "STS benchmark", "accuracy": "pearson correlation coefficient of 0.803"}, "description": "A pre-trained text encoder that converts text into a 512-dimensional vector. Useful for a wide range of natural language processing tasks."}}
{"code": "###Instruction: We want to analyze a collection of images for their features and create a summary of their distinct characteristics.\n###Output: <<<domain>>>: image-feature-vector, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=[224, 224, 3]), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the pre-trained MobileNet V2 model, which is designed to extract image features. The model, trained on the ImageNet dataset, accepts images of shape [224, 224, 3] and outputs a feature vector of shape [1280]. Using these feature vectors, you can analyze the images to identify their unique characteristics and develop a summary of their distinct properties. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224, 224, 3), trainable=False)\n])\n\nfeatures = model(images)\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image feature vector", "framework": "TensorFlow Hub", "functionality": "Extract image features", "api_name": "imagenet_mobilenet_v2_100_224_feature_vector", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4')", "api_arguments": {"input_shape": "[batch_size, 224, 224, 3]", "output_shape": "[batch_size, 1280]"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', input_shape=(224, 224, 3), trainable=False)\n])\n\nfeatures = model(images)", "performance": {"dataset": "ImageNet", "accuracy": "71.8%"}, "description": "This API provides a pre-trained MobileNetV2 model for extracting image features. It takes an input image of shape (batch_size, 224, 224, 3) and returns a feature vector of shape (batch_size, 1280). The model is trained on the ImageNet dataset and achieves 71.8% accuracy."}}
{"code": "###Instruction: We just took many different images of the front of a house and want to isolate the windows part from the whole image.\n###Output: <<<domain>>>: Image segmentation, <<<api_call>>>: hub.load('https://tfhub.dev/tensorflow/deeplabv3_257_mv_gpu/1'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: DeepLabv3 is a deep learning model for image segmentation that assigns a semantic label to each pixel in the input image. It can be used to isolate specific parts of an image, such as windows. By loading this model from TensorFlow Hub, you'll be able to pass in the images of the front of the house and obtain segmented versions of those images, allowing for the isolation of the windows. <<<code>>>: import tensorflow_hub as hub\nmodel = hub.load(\"https://tfhub.dev/tensorflow/deeplabv3_257_mv_gpu/1\")\n", "api_call": "hub.load('https://tfhub.dev/tensorflow/deeplabv3_257_mv_gpu/1')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image segmentation", "framework": "TensorFlow Hub", "functionality": "Image segmentation model", "api_name": "deeplabv3_257_mv_gpu", "api_call": "hub.load('https://tfhub.dev/tensorflow/deeplabv3_257_mv_gpu/1')", "api_arguments": {"url": "https://tfhub.dev/tensorflow/deeplabv3_257_mv_gpu/1"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.6.0"}, "example_code": "import tensorflow_hub as hub\nmodel = hub.load(\"https://tfhub.dev/tensorflow/deeplabv3_257_mv_gpu/1\")\nsegmentation = model(input_image)", "performance": {"dataset": "PASCAL VOC 2012", "accuracy": "0.897"}, "description": "DeepLabv3 is a state-of-the-art deep learning model for image segmentation. It assigns a semantic label to each pixel in the input image, allowing for a more detailed understanding of the image content. This model is trained on the PASCAL VOC 2012 dataset and achieves a mean intersection-over-union (mIoU) score of 0.897."}}
{"code": "###Instruction: We have been receiving user-generated content that is sometimes not safe for work. We would like to develop a system to classify such images.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained MobileNet V2 image classification model from TensorFlow Hub. It has been trained on the ImageNet dataset and can be used to classify images into various categories. You can use this model to analyze the user-generated content and identify images that are not safe for work. By processing the images through this model, you can get predictions on predefined categories and filter out inappropriate content. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\n\n# Load the pre-trained MobileNet V2 model\nmodel_id = 'https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'\nmodel = hub.load(model_id)\n\n# Load an image and preprocess it\nimage = tf.keras.preprocessing.image.load_img('path/to/your/image.jpg', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, 0)\n\n# Make predictions\npredictions = model(image_array)\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Pre-trained image classification models", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'\nmodel = hub.load(model_id)\n\n# Load an image and preprocess it\nimage = tf.keras.preprocessing.image.load_img('path/to/your/image.jpg', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, 0)\n\n# Make predictions\npredictions = model(image_array)\n", "performance": {"dataset": "ImageNet", "accuracy": "71.8%"}, "description": "This API provides pre-trained image classification models from TensorFlow Hub. Users can load a model using its model_id and make predictions on images."}}
{"code": "###Instruction: My nephew is passionate about animals, and I want to create an app that tells him the type of animal in a picture.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call incorporates the pre-trained MobileNetV2 image classification model from TensorFlow Hub. The model has been trained on the ImageNet dataset and can classify images into 1000 different categories. By loading this model, you can build an app that takes an input image and predicts the type of animal or objects present in the picture. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5')\n])\n-image = tf.keras.preprocessing.image.load_img('path/to/your/image.jpg', target_size=(224, 224))\ninput_image = tf.keras.preprocessing.image.img_to_array(image)\ninput_image = tf.expand_dims(input_image, 0)\npredictions = model.predict(input_image)\nclass_names = tf.keras.applications.mobilenet_v2.decode_predictions(predictions, top=1)\nprint(class_names)\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Image classification using pre-trained models", "api_name": "imagenet_mobilenet_v2_130_224_classification", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5')", "api_arguments": {"url": "https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5"}, "python_environment_requirements": {"tensorflow": "2.x", "tensorflow_hub": "0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5')\n])\n\n# Load an image and preprocess it\nimage = tf.keras.preprocessing.image.load_img('path/to/your/image.jpg', target_size=(224, 224))\ninput_image = tf.keras.preprocessing.image.img_to_array(image)\ninput_image = tf.expand_dims(input_image, 0)\n\n# Make predictions\npredictions = model.predict(input_image)\n\n# Decode the predictions\nclass_names = tf.keras.applications.mobilenet_v2.decode_predictions(predictions, top=1)\nprint(class_names)", "performance": {"dataset": "ImageNet", "accuracy": "Not specified"}, "description": "A pre-trained image classification model using MobileNetV2 architecture from TensorFlow Hub. The model is trained on ImageNet dataset and can classify images into 1000 different categories."}}
{"code": "###Instruction: I have an image of a dog breed, and I want to know the breed.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: model = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained image classification model called MobileNet V2, which is trained on the ImageNet dataset, from TensorFlow Hub using the specified model_id. Once loaded, the model can be used to classify images, including those of dog breeds, into one of the many classes it has been trained on.<<<code>>>: import tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading a model", "api_name": "model_id", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": ["model_id"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodel_id = 'https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'\nmodel = hub.load(model_id)", "performance": {"dataset": "", "accuracy": ""}, "description": "Load a pre-trained image classification model from TensorFlow Hub using the specified model_id."}}
{"code": "###Instruction: How to identify dog breed through a mobile app by taking a dog picture as they walk?\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call creates a Keras layer using a pre-trained MobileNet V2 model from TensorFlow Hub. The model is designed for image classification and has been trained on the ImageNet dataset. It's optimized for mobile devices because it's lightweight and efficient. You can create a TensorFlow model that uses this layer and process the images taken by your mobile app to identify the dog breed. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\n])\n", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Pre-trained model for image classification", "api_name": "imagenet_mobilenet_v2_100_224_classification", "api_call": "hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": {"URL": "https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4"}, "python_environment_requirements": {"tensorflow": ">=2.0.0", "tensorflow_hub": ">=0.12.0"}, "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = tf.keras.Sequential([\n    hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\n])\nimage = tf.keras.preprocessing.image.load_img('path/to/image.jpg', target_size=(224, 224))\nimage_array = tf.keras.preprocessing.image.img_to_array(image)\nimage_array = tf.expand_dims(image_array, 0)\npredictions = model.predict(image_array)", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained image classification model using MobileNetV2 architecture on ImageNet dataset with 100% depth and 224x224 input size."}}
{"code": "###Instruction: My friend has taken a photo of a plant, and I want to know what species it is.\n###Output: <<<domain>>>: Image classification, <<<api_call>>>: model = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads a pre-trained tensorflow image classification model using the MobileNetV2 architecture. The model has been trained on the ImageNet dataset and can identify and classify images into various classes. By providing the image of the plant, the model can help identify the species of the plant in the photo. <<<code>>>: import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\n", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Image classification", "framework": "TensorFlow Hub", "functionality": "Loading pre-trained models", "api_name": "imagenet_mobilenet_v2_100_224_classification", "api_call": "hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')", "api_arguments": "URL of the pre-trained model", "python_environment_requirements": "tensorflow, tensorflow_hub", "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nmodel = hub.load('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4')\nimage = tf.keras.preprocessing.image.load_img('image.jpg', target_size=(224, 224))\ninput_array = tf.keras.preprocessing.image.img_to_array(image)\ninput_array = tf.expand_dims(input_array, 0)\npredictions = model(input_array)\nprint(predictions)", "performance": {"dataset": "ImageNet", "accuracy": "71.0%"}, "description": "A pre-trained image classification model using MobileNetV2 architecture on ImageNet dataset with 100% depth and 224x224 input size."}}
{"code": "###Instruction: Can you help me to find similarity between movie plot descriptions, so that I can recommend similar movies?\n###Output: <<<domain>>>: Text embedding, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the Universal Sentence Encoder model from TensorFlow Hub, which encodes text into high-dimensional vectors. By encoding the plot descriptions of movies into these vectors, you can calculate the similarity between these representations and identify movies with similar plot descriptions. This will allow you to recommend similar movies to users effectively. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text embedding", "framework": "TensorFlow Hub", "functionality": "Embedding text into high-dimensional vectors", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow as tf\nimport tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world!'])\nprint(embeddings)", "performance": {"dataset": "Various", "accuracy": "N/A"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks."}}
{"code": "###Instruction: Design a natural language processing model using text tokenization and vectorization. I need some preprocessing before dealing with classifiers.\n###Output: <<<domain>>>: Text preprocessing, <<<api_call>>>: hub.load('https://tfhub.dev/google/universal-sentence-encoder/4'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: The API call loads the Universal Sentence Encoder model from TensorFlow Hub, which is designed for encoding text into high-dimensional vectors. It performs text tokenization and vectorization. These vectors can be used for tasks such as text classification, semantic similarity, clustering, and other natural language tasks. By preprocessing text data using this API call, you can create a better foundation for dealing with classifiers, as it simplifies the text input and reduces noise. <<<code>>>: import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "provider": "TensorFlow Hub", "api_data": {"domain": "Text preprocessing", "framework": "TensorFlow Hub", "functionality": "Text tokenization and vectorization", "api_name": "universal-sentence-encoder", "api_call": "hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')", "api_arguments": ["input_text"], "python_environment_requirements": ["tensorflow", "tensorflow_hub"], "example_code": "import tensorflow_hub as hub\nembed = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\nembeddings = embed(['Hello world!'])", "performance": {"dataset": "Various", "accuracy": "N/A"}, "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks. It is a pre-trained model available on TensorFlow Hub."}}
