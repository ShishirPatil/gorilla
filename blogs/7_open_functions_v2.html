<!DOCTYPE html>
<html>

<head>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-NRZJLJCSH6"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());

        gtag('config', 'G-NRZJLJCSH6');
    </script>


    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=0.8">
    <title>OpenFunctions v2</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.5.0/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Source+Sans+Pro">
    <link rel="stylesheet" href="../assets/css/blog.css">
    <link rel="stylesheet" href="../assets/css/styles.css">

</head>

<body>
    <!-- Navigation Bar -->
    <div class="navbar" style="position: absolute; top: 0; right: 20px; padding: 10px; z-index: 100;; font-size: 18px;">
        <a href="/index.html">Home</a>
        <a href="/blog.html">Blogs</a>
        <a href="/leaderboard.html">Leaderboard</a>
        <a href="/apizoo/">API Zoo Index</a>
    </div>
    <div class="highlight-clean-blog" style="padding-bottom: 10px;">
        <h1 class="text-center" style="padding-bottom: 10px;">ü¶ç Gorilla: Large Language Model Connected with Massive APIs</h1>
        <div class=" box-index">
            <h3>Blog 7: Gorilla OpenFunctions v2</h3>
            <ul>
                <ul>
                        <li><a href="7_open_functions_v2.html#whats_new">See What's New!! &#128640</a></li>
                        <li><a href="7_open_functions_v2.html#how_to_use_open_functions">Integrating OpenFunctions-v2 in your App üî®</a></li>
                        <li><a href="7_open_functions_v2.html#benchmarking">Performance on Berkeley Function-Calling Leaderboard üî•</a></li>
                        <li><a href="7_open_functions_v2.html#data_composition">OpenFunctions Data Composition </a></li>
                        <li><a href="7_open_functions_v2.html#conclusion">Conclusion</a></li>
                        <li class="more-blogs">
                            <a href="javascript:void(0);" onclick="toggleMoreBlogs()">More Blogs <span class="caret">&#9654;</span></a>
                            <ul class="sub-menu">
                                <li><a href="8_berkeley_function_calling_leaderboard.html">Berkeley Function-Calling Leaderboard</a></li>
                                <li><a href="6_api_zoo.html">The API Zoo: A Keystone for Building API-connected LLMs</a></li>
                                <li><a href="5_how_to_gorilla.html">How to Use Gorilla: A Step-by-Step Walkthrough
                                <li><a href="4_open_functions.html">Gorilla OpenFunctions
</a></li>
</a></li>
                                <!-- Add more blog entries as needed -->
                            </ul>
                        </li>  
                </ul>
                <!-- Add more entries as needed -->
            </ul>
        </div>

        <div class="blog-container container">
            <div class="blog-post">
                <h2 class="blog-title">Gorilla OpenFunctions v2</h2>
                <div class="col-md-12">
                    <h4 class="text-center" style="margin: 0px;">
                        <p></p>
                        <a class="author" href="https://charliejcj.github.io/">Charlie Cheng-Jie Ji<sup>*</sup></a>
                        <a class="author" href="https://huanzhimao.com/">Huanzhi Mao<sup>*</sup></a>
                        <a class="author" href="https://fanjia-yan.github.io/">Fanjia Yan<sup>*</sup></a>
                        <a class="author" href="https://people.eecs.berkeley.edu/~istoica">Ion Stoica</a>
                        <a class="author" href="https://people.eecs.berkeley.edu/~jegonzal/">Joseph E. Gonzalez</a>
                        <a class="author" href="https://people.eecs.berkeley.edu/~shishirpatil/">Shishir G. Patil</a>
                        <a class="author" href="https://tianjunz.github.io">Tianjun Zhang</a>
                        <p></p>
                    </h4>
                </div>
                    <img src="../assets/img/blog_post_7_demo.gif" alt="Gorilla introductory image" style="width: 100%;">
                    <p width="80%" style="text-align:center; margin-left:10%; margin-right:10%; padding-bottom: -10px">
                        <i style="font-size: 0.9em;">
                            Gorilla OpenFunctions-v2! SoTA for open-source models. On-par with commercial models. 
                        </i>
                    </p>

                <div class="preview">
                    <p>
                        With the latest iteration of Gorilla OpenFunctions-v2, we are delighted to mark significant advancements in function calling for LLMs within the open-source community. As a direct substitute for its predecessor, Gorilla OpenFunctions-v2 retains its open-source ethos while introducing exciting enhancements. These include support for multiple programming languages such as Python, Java, JavaScript, and REST API - the first among both open-source and closed-source models, alongside the ability to handle multiple and parallel function calls, and the ability to determine function relevance. This update cements Gorilla OpenFunctions-v2's position at the forefront of function calling capabilities among LLMs. Moreover, the drop-in replacement allows for seamless integration of OpenFunctions into a diverse range of applications, from social media platforms like Instagram to delivery services like DoorDash, as well as utility tools including Google Calendar and Stripe.
                    </p>
                </div>

                <h4 id="whats_new"> See What's New!! &#128640 </h4>
                <div class="body">
                    <p>
                        The five new exciting features we are happy to launch with OpenFunctions-v2 are:
                    </p>
                    <p style="text-align: center; margin-bottom: 0">
                        <img src="../assets/img/blog_post_7_open_function_v2_features.png" alt="New-Features in Gorilla LLMs" style="width:100%" >
                        <br>
                    </p>
                    
                    <ul>
                        <li style="margin-bottom: 5px;"><strong>More Data Types:</strong> Gorilla OpenFunctions-v2 can now support diverse
                            languages with expanded support for argument types in function calls. This includes
                            <code style="background-color: #eee; padding: 2px 4px; border-radius: 4px;">[string, number, boolean, list, tuple, dict, any]</code> for Python,
                            <code style="background-color: #eee; padding: 2px 4px; border-radius: 4px;">[string, number, boolean, list, tuple, dict, any]</code> for Java and
                            <code style="background-color: #eee; padding: 2px 4px; border-radius: 4px;">[string, number, boolean, dict, bigint, array, date, any]</code> for Javascript. For
                            reference, OpenAI and many others only support JSON schema, i.e.,
                            <code style="background-color: #eee; padding: 2px 4px; border-radius: 4px;">[string, number, integer, object, array, and boolean]</code>. Native support for these
                            types means, you can now plug-and-play openfunctions-v2 without having to weave through
                            string literals.</li>
                        <li style="margin-bottom: 5px;"><strong>Parallel & Multiple Functions:</strong> Support for Parallel and Multiple Functions.
                            Multiple functions refers to the scenario where the user can input multiple functions when
                            they are not sure which exact function is best to service the prompt. In this scenario, the
                            Gorilla model picks one or more (or none) of the functions provided to respond to the user's
                            requests. In parallel functions, the user's prompt could be serviced by multiple calls to
                            the same function. Gorilla not only supports both of these, but the benefits stack
                            one-on-top of the other! </li>
                        <li style="margin-bottom: 5px;"><strong>Function Relevance Detection:</strong> Reduce hallucinations in scenarios when no
                            function, or even no relevant function is provided. Gorilla openfunctions v2 can now
                            automatically detect whether the functions provided to the model can address the user's
                            prompt. Recognizing this, the LLM raises an ‚ÄúError‚Äù message to the user providing them with
                            additional information.</li>
                        <li style="margin-bottom: 5px;"><strong>Enhanced Capabilities for RESTful APIs:</strong> Enhance ability to format RESTful
                            API calls. RESTful APIs are a common phenomenon within the web powering many popular
                            software services including Slack, PayPal, etc. Our model is specially trained to handle
                            RESTful API calls with good quality.</li>
                    </ul>

                    <p>
                        <b>Quick Links</b>:
                    <ul>
                        <li style="margin-bottom: 5px;">How well to other function-calling models perform: <a
                                href="https://gorilla.cs.berkeley.edu/leaderboard.html">Berkeley Function Calling
                                Leaderboard</a></li>
                        <li style="margin-bottom: 5px;">Play with the model online: <a
                                href="https://gorilla.cs.berkeley.edu/leaderboard.html#api-explorer">Gorilla OpenFunctions-v2
                                web-demo</a></li>
                        <li style="margin-bottom: 5px;">Check out the project: <a
                                href="https://github.com/ShishirPatil/gorilla/tree/main/openfunctions">GitHub</a></li>
                        <li style="margin-bottom: 5px;">Model (6.91B) on HuggingFace ü§ó: <a
                                href="https://huggingface.co/gorilla-llm/gorilla-openfunctions-v2">gorilla-llm/gorilla-openfunctions-v2</a>
                        </li>
                    </ul>
                    </p>
                </div>

                <h4 id="how_to_use_open_functions">Integrating OpenFunctions-v2 in your App üî®</h4>
                <div class="body">
                    <p>Using Gorilla OpenFunctions-v2 is straightforward:
                        <ol>
                        <li style="margin-bottom: 5px;">To help with quick prototyping, we provide a hosted Gorilla Openfunctions-v2 model for inference. Or you can run it locally, or self-host it by accessing the model from <a href="https://huggingface.co/gorilla-llm/gorilla-openfunctions-v2">HuggingFace</a>. The example below, demonstrates how to invoke the hosted Gorilla Openfunctions-v2 model:</li>
                        <pre style="white-space:pre-wrap; width:100%; overflow-x: auto; background-color: #f4f4f4; color: #333;">
<span style="color: #d14;">import</span> openai

<span style="color: #d14;">def</span> <span style="color: #069;">get_gorilla_response</span>(prompt=<span style="color: #d14;">""</span>, model=<span style="color: #d14;">"gorilla-openfunctions-v2"</span>, functions=[]):
    openai.api_key = <span style="color: #d14;">"EMPTY"</span>  <span style="color: #60a0b0; font-style: italic;"># Hosted for free with</span> <span style="color:#ff0000;">‚ù§Ô∏è</span> <span style="color: #60a0b0; font-style: italic;">from UC Berkeley</span>
    openai.api_base = <span style="color: #d14;">"https://luigi.millennium.berkeley.edu/v1"</span>
    <span style="color: #d14;">try</span>:
        completion = openai.ChatCompletion.create(
            model=<span style="color: #d14;">"gorilla-openfunctions-v2"</span>,
            temperature=0.0,
            messages=[{<span style="color: #d14;">"role"</span>: <span style="color: #d14;">"user"</span>, <span style="color: #d14;">"content"</span>: prompt}],
            functions=functions,
        )
        <span style="color: #60a0b0; font-style: italic;"># completion.choices[0].message.content, string format of the function call</span> 
        <span style="color: #60a0b0; font-style: italic;"># completion.choices[0].message.functions, Json format of the function call</span>
        <span style="color: #d14;">return</span> completion.choices[0]</pre>

                        <li style="margin-bottom: 5px;">Prompt the model:</li>
                        <code style="background-color: #eee; padding: 2px 4px; border-radius: 4px;">What's the weather like in the two cities of Boston and San Francisco?</code>
                        <li style="margin-bottom: 5px;">Format your function call: The model will return the function call based on your request.</li>
                        <pre style="white-space:pre-wrap; width:100%; overflow-x: auto; background-color: #f4f4f4; color: #333;">
<span style="color: #333;">query</span> = <span style="color: #d14;">"What's the weather like in the two cities of Boston and San Francisco?"</span>
<span style="color: #333;">functions</span> = [
    {
        <span style="color: #333;">"name"</span>: <span style="color: #d14;">"get_current_weather"</span>,
        <span style="color: #333;">"description"</span>: <span style="color: #d14;">"Get the current weather in a given location"</span>,
        <span style="color: #333;">"parameters"</span>: {
            <span style="color: #333;">"type"</span>: <span style="color: #d14;">"object"</span>,
            <span style="color: #333;">"properties"</span>: {
                <span style="color: #333;">"location"</span>: {
                    <span style="color: #333;">"type"</span>: <span style="color: #d14;">"string"</span>,
                    <span style="color: #333;">"description"</span>: <span style="color: #d14;">"The city and state, e.g. San Francisco, CA"</span>,
                },
                <span style="color: #333;">"unit"</span>: {<span style="color: #333;">"type"</span>: <span style="color: #d14;">"string"</span>, <span style="color: #333;">"enum"</span>: [<span style="color: #d14;">"celsius"</span>, <span style="color: #d14;">"fahrenheit"</span>]},
            },
            <span style="color: #333;">"required"</span>: [<span style="color: #d14;">"location"</span>],
        },
    }
]</pre>

                        <li style="margin-bottom: 5px;">Get Your Function Call: The model will return a Python function call based on your request.</li>
                        This opens up possibilities for developers and non-developers alike, allowing them to leverage complex functionalities without writing extensive code.</p>
                        <p><b>Input:</b></p>
                        <pre style="white-space:pre-wrap; width:100%; overflow-x: auto; background-color: #f4f4f4; color: #333;">
<span style="color: #333;">get_gorilla_response</span>(prompt=<span style="color: #333;">query</span>, functions=[<span style="color: #333;">functions</span>])
</pre>
                        <p><b>Output:</b></p>
                        <pre style="white-space:pre-wrap; width:100%; overflow-x: auto; background-color: #f4f4f4; color: #333;">
[<span style="color: #333;">get_current_weather</span>(location=<span style="color: #d14;">'Boston, MA'</span>), <span style="color: #333;">get_current_weather</span>(location=<span style="color: #d14;">'San Francisco, CA'</span>)]
</pre>

                    <p>With the example above, you can use Gorilla OpenFunctions-v2 to provide a well formatted output,
                        or call a function with your own definition! Then you can use this freely within your
                        applications and chatbot!</p>

                    <p>Note: Gorilla through our hosted end-point is currently only supported with
                        <code style="background-color: #eee; padding: 2px 4px; border-radius: 4px;">openai==0.28.1</code>. We will migrate to also include support for
                        <code style="background-color: #eee; padding: 2px 4px; border-radius: 4px;">openai==1.xx</code> soon with which <code style="background-color: #eee; padding: 2px 4px; border-radius: 4px;">functions</code> is replaced by
                        <code style="background-color: #eee; padding: 2px 4px; border-radius: 4px;">tool_calls</code>.</p>
                </div>

                <!-- OpenFunction BenchMarking  -->

                <h4 id="benchmarking">Performance on Berkeley Function-Calling Leaderboard &#128293</h4>
                <div class="body">

                    <p style="text-align: center; margin-bottom: 0">
                        <img src="../assets/img/blog_post_7_open_function_v2_summary.png" alt="Open functions types of data" style="width:100%" >
                        <br>
                    </p>
                    <p width="80%" style="text-align:center; margin-left:10%; margin-right:10%; padding-bottom: -10px">
                        <i style="font-size: 0.9em;">
                            We perform exhaustive and comprehensive evaluation on the Berkeley Function-Calling
                            Leaderboard, we benchmark our model against current state-of-the-art models GPT-4-1106-preview
                            as well as GPT-4 and GPT-3.5-turbo function calling features. In addition, we also compare
                            our model with the other open-source models, demonstrating superior behavior among them. Our
                            evaluation consists of 2k distinct query, API documentation pairs from different domains
                            (including travel, finance, scheduling meetings, etc) and languages (java, javascript,
                            python, REST API).
                        </i>
                    </p>
                    <p> To dive into details about how our model performs in each category, we provide a detailed table below from the <a href="https://gorilla.cs.berkeley.edu/leaderboard.html">Berkeley Function-Calling Leaderboard</a>. We see that when compared to the current state-of-the-art, GPT-4's function calling, in Python, Gorilla OpenFunctions-v2 does better at simple function calling category, but not as good on function calls that involve multiple and parallel functions. This new feature continues to be an exciting area of research for us, and the open-source community in general. It is worth highlighting that our model provides a very stable executable function calls - function calls that were evaluated by actually executing them - with no intervention in-between. Unsurprisingly, having been trained, our model outperforms GPT-4 on function calls on the programming languages other than Python (e.g., Java, Javascript and REST APIs). For REST APIs, our model provides more stable outputs that includes all the required fields including the <strong>url</strong>, <strong>params</strong> and <strong>header</strong> making our model ripe for immediate adoption.</p>
                    <p style="text-align: center; margin-bottom: 0">
                        <img src="../assets/img/blog_post_7_open_function_v2_leaderboard.png" alt="Open functions types of data" style="width:100%" >
                        <br>
                    </p>
                    <p width="80%" style="text-align:center; margin-left:10%; margin-right:10%; padding-bottom: -10px">
                        <i style="font-size: 0.9em;">
                            Gorilla OpenFunctions-v2's performance on <a href="https://gorilla.cs.berkeley.edu/leaderboard.html">Berkeley Function-Calling Leaderboard</a>


                        </i>
                    </p>
                    <div class="container">
                        <div class="code-block">
                    <pre style="white-space:pre-wrap; width:100%; overflow-x: auto; background-color: #f4f4f4;">
"User": "Can you fetch me the weather data for the coordinates 
37.8651 N, 119.5383 W, including the hourly forecast for temperature, 
wind speed, and precipitation for the next 10 days?"

"Function": 
{
    ...
    "parameters": 
    {
        "type": "object", 
        "properties": 
        {
            "url": 
            {
                "type": "string", 
                "description": "The API endpoint for fetching weather
                data from the Open-Meteo API for the given latitude
                and longitude, default 
                <span style="color:#0000FF;">https://api.open-meteo.com/v1/forecast</span>"
            }
            ...
        }
    }
}

"Gorilla OpenFunctions-v2 output":
{
    "name": "requests.get",
    "parameters": {
        "url": "<span style="color:#0000FF;">https://api.open-meteo.com/v1/forecast</span>",
        "params": 
        {
            "latitude": "37.8651",
            "longitude": "-119.5383",
            "forecast_days": 10
        },
    }
}
                    </pre>
                    </div>
                        <div class="code-block">
                    <pre style="white-space:pre-wrap; width:100%; overflow-x: auto; background-color: #f4f4f4;">
"User": "Can you fetch me the weather data for the coordinates 
37.8651 N, 119.5383 W, including the hourly forecast for temperature, 
wind speed, and precipitation for the next 10 days?"

"Function": 
{
    ...
    "parameters": 
    {
        "type": "object", 
        "properties": 
        {
            "url": 
            {
                "type": "string", 
                "description": "The API endpoint for fetching weather
                data from the Open-Meteo API for the given latitude
                and longitude, default 
                <span style="color:#0000FF;">https://api.open-meteo.com/v1/forecast</span>"
            }
            ...
        }
    }
}

"GPT-4 output":
{
    "name": "requests.get",
    "parameters": {
        "params": 
        {
            "latitude": "37.8651",
            "longitude": "-119.5383",
            "forecast_days": 10
        },
    }
}
                    </pre>
</div>
                    </div>

                    <p width="80%" style="text-align:center; padding-bottom: -10px">
                        <i style="font-size: 0.9em;">
                            The left hand side is GPT-4 generated, and the right hand side is openfunctions-v2
                            generated. As we can see from the above mistakes that when GPT-4 function call is dealing
                            with functions involving complex parameter structures (e.g., dict inside a dict) with
                            default values, the model tends to have trouble, especially on parsing default values.
                            Rather than being a corner-case, the example above is a common paradigm for REST APIs.
                        </i>
                    </p>

                </div>

                <!-- OpenFunctions Data Composition -->

                <h4 id="data_composition"> OpenFunctions Data Composition & Training &#127829</h4>
                <div class="body">
                    <p>
                        Gorilla OpenFunctions-v2 is a 6.91B parameter model trained further upon on the
                        Deepseek-Coder-7B-Instruct-v1.5 6.91B model. To train the model, we collect in total of <b>65,283
                        question-function-answer pairs</b> from three different sources: Python packages (19,353), Java
                        repositories (16,586), Javascript Repositories (4,245), public-API (6,009), and Command Line
                        Tools (19,090) from various cloud providers. The data composition is shown in the figure below.
                    </p>
                    <p>
                        After the data collection, we carry out <b>four data augmentations</b> to diversify our training
                        dataset. First, we change the function names. This is critical to ensure the model does not
                        "memorize" the API mapping. Second, we add random (randomly chosen, and random number of)
                        functions to make our data-set compatible with parallel functions. This way we can
                        generate multiple-function datasets from simple functions. Third, we adopt similar strategies
                        of perturbing the prompt to generate scenarios of parallel-functions. We then extend it to also
                        include multiple- and parallel- functions in the same data-points. Finally, we mix some portion
                        of the dataset in which the functions provided during the input is not sufficient to the task.
                        We flag these as `Relevance Detection` scenarios. As with most LLM training, we extensively
                        varied the extents of each data augmentation to train a robust model.
                    </p>
                    <ul>
                        <li style="margin-bottom: 5px;"><strong>Function Name Transformation:</strong> From the original question-function-answer pairs, we augment this with a differnt function names to avoid the model memorizing the correlation between function names and the question (e.g., 'uber' API is used for transportation). 
                            <pre style="white-space:pre-wrap; width:100%; overflow-x: auto; background-color: #f4f4f4; color: #333;">
<span style="color: #333;">query</span> + [{'name': <span style="color: #d14;">'func1'</span>, 'description': <span style="color: #d14;">'order takeout'</span>}] -> <span style="color: #333;">ans1</span> => 
<span style="color: #333;">query</span> + [{'name': <span style="color: #d14;">'func2'</span>, 'description': <span style="color: #d14;">'order takeout'</span>}] -> [<span style="color: #333;">ans2</span>]
</pre>

                        </li>
                        <li style="margin-bottom: 5px;"><strong>Parallel Functions Transformation:</strong> To handle a more complex case where multiple functions will be selected to answer the user's request, we change the original question to ask for multiple outputs.  
                        <pre style="white-space:pre-wrap; width:100%; overflow-x: auto; background-color: #f4f4f4; color: #333;">
<span style="color: #333;">query1</span> + [{'name': <span style="color: #d14;">'func1'</span>, 'description': <span style="color: #d14;">'order takeout'</span>}] -> <span style="color: #333;">ans1</span> => 
<span style="color: #333;">query2</span> + [{'name': <span style="color: #d14;">'func1'</span>, 'description': <span style="color: #d14;">'order takeout'</span>}] -> [<span style="color: #333;">ans1</span>, <span style="color: #333;">ans2</span>]
</pre>

                        </li>
                        <li style="margin-bottom: 5px;"><strong>Multiple Functions Transformation:</strong> Transform the original function with multiple function calls included in the training, so that the model can learn to choose which function call to use.
                        <pre style="white-space:pre-wrap; width:100%; overflow-x: auto; background-color: #f4f4f4; color: #333;">
<span style="color: #333;">query</span> + [{'name': <span style="color: #d14;">'func1'</span>, 'description': <span style="color: #d14;">'order takeout'</span>}] -> <span style="color: #333;">ans1</span> => 
<span style="color: #333;">query</span> + [{'name': <span style="color: #d14;">'func1'</span>, 'description': <span style="color: #d14;">'order takeout'</span>}, {'name': <span style="color: #d14;">'func2'</span>, 'description': <span style="color: #d14;">'get weather'</span>}] -> [<span style="color: #333;">ans1</span>]
</pre>

                        </li>
                        <li style="margin-bottom: 5px;"><strong>Parallel Multiple Functions Transformation:</strong> The combined of the above parallel, and multiple transforms. 
                        <pre style="white-space:pre-wrap; width:100%; overflow-x: auto; background-color: #f4f4f4; color: #333;">
<span style="color: #333;">query1</span> + [{'name': <span style="color: #d14;">'func1'</span>, 'description': <span style="color: #d14;">'order takeout'</span>}] -> <span style="color: #333;">ans1</span> => 
<span style="color: #333;">query2</span> + [{'name': <span style="color: #d14;">'func1'</span>, 'description': <span style="color: #d14;">'order takeout'</span>}, {'name': <span style="color: #d14;">'func2'</span>, 'description': <span style="color: #d14;">'get weather'</span>}] -> [<span style="color: #333;">ans1</span>, <span style="color: #333;">ans2</span>]
</pre>

                        </li>
                        <li style="margin-bottom: 5px;"><strong>Function Relevance Detection Transformation:</strong> We also include some portion of the dataset in which the functions provided cant not solve the task. We call this `Relevance Detection`.
                        <pre style="white-space:pre-wrap; width:100%; overflow-x: auto; background-color: #f4f4f4; color: #333;">
<span style="color: #333;">query1</span> + [{'name': <span style="color: #d14;">'func1'</span>, 'description': <span style="color: #d14;">'order takeout'</span>}] -> <span style="color: #333;">ans1</span> => 
<span style="color: #333;">query2</span> + [{'name': <span style="color: #d14;">'func1'</span>, 'description': <span style="color: #d14;">'order takeout'</span>}] -> [<span style="color: #d14;">Error</span>, <span style="color: #d14;">the function cannot solve the question.</span>]
</pre>

                        </li>
                    </ul>
                    <p>
                        Following the completion of the data augmentation process, we further refine the dataset by employing the Rouge score for deduplication, effectively eliminating redundant entries. This step is a recognized standard practice.
                    <p>

                    </p>

                </div>

                <!-- Conclusion  -->
                <h4 id="conclusion">Conclusion</h4>

                <div class="body">
                    <p>We are happy to release <code style="background-color: #eee; padding: 2px 4px; border-radius: 4px;">gorilla-openfunctions-v2</code>, a 6.91B parameter model trained on
                        top of the Deepseek-Coder-7B-Instruct-v1.5 LLM.
                        It takes-in the users prompt along with multiple API calls and returns the functions with the
                        right arguments. With OpenFunctions we extended native
                        support for parameter types in Python, Java, and JavaScript, and RESTful APIs.
                        For more information, check out our blog on Berkeley Function Calling Leaderboard for
                        evaluation, and our GitHub page for the model.
                        All of the results in the blog are generated using <code style="background-color: #eee; padding: 2px 4px; border-radius: 4px;">gorilla-openfunctions-v2</code>.
                    </p>

                    <br> 
                    <h4 id="conclusion">Licensing:</h4>
                        Gorilla OpenFunctions v2 is distributed under the Apache 2.0 license. This software incorporates
                        elements from the Deepseek model. Consequently, the licensing of Gorilla OpenFunctions v2
                        adheres to the Apache 2.0 license, with additional terms as outlined in Appendix A of the
                        Deepseek license.
                    </br>

                    <hr class="post-separator">

                    <p>
                        We hope you enjoyed this blog post. We would love to hear from you on <a
                            href="https://discord.gg/grXXvj9Whz">Discord</a>, Twitter (#GorillaLLM), and <a
                            href="https://github.com/ShishirPatil/gorilla/">GitHub</a>.<br>
                    </p>
                    <p id="gorilla-bibtex">
                        If you would like to cite Gorilla:<br>
                        @inproceedings{gorilla-openfunctions-v2,<br>
                        &nbsp; title={Gorilla OpenFunctions v2},<br>
                        &nbsp; author={Charlie Cheng-Jie Ji, Huanzhi Mao, Fanjia Yan, Shishir G. Patil, Tianjun Zhang,
                        Ion Stoica, Joseph E. Gonzalez},<br>
                        &nbsp; year={2024},<br>
                        &nbsp; howpublished={\url{https://gorilla.cs.berkeley.edu//blogs/7_open_functions_v2.html}},<br>
                        }</p>
                </div>
            </div>
        </div>
    </div>

    <style>
        body {
            margin: 0;
            padding: 0;
            background: white;
            justify-content: center;
            align-items: center;
        }
        .container {
            display: flex;
        }

        .blog-container {
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
        }
        .blog-post {
            margin: 20px;
            padding: 20px;
            max-width: 1000px; 
            justify-content: center;
        }
        .blog-post img {
            display: block;
            margin: 0 auto;
        }
        .blog-title{
            color: #055ada;
            text-align: center;
        }

        .author-date {
                display: flex;
                margin-bottom: 0px;
                justify-content: center; 
        }
        .author {
                font-size: 16px;
                color: #1E90FF;
                margin-right: 20px;
        }

        .date {
            font-size: 16px;
            color: #7e8790;
        }

        .preview {
            text-align: justify; 
            text-justify: inter-word; 
        }

        .highlight-clean-blog {
            color: #313437;
            background-color: #fff;
            padding: 50px 0;
        }

        .box-index {
        position: fixed;
        top: 50%; 
        left: 0px; 
        transform: translateY(-50%);
        background-color: #f9f9f9;
        padding: 20px;
        border-radius: 8px;
        box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
        max-width: 150px;
        }

        .box-index h3 {
        font-size: 1.2em;
        margin-bottom: 10px;
        }

        .box-index ul {
        list-style-type: disc;
        padding: 0;
        }

        .box-index ul li {
        margin-bottom: 10px;
        }

        .box-index ul li a {
        text-decoration: none;
        color: #333;
        }

        .box-index ul li a:hover {
        color: #1E90FF;
        }

        .more-blogs .sub-menu {
            display: none;
        }

        .more-blogs .sub-menu.expanded {
            display: block;
            max-height: 200px; /* Adjust the max height as needed */
            overflow-y: auto;
        }

        .more-blogs .sub-menu li {
            padding: 10px;
            border-bottom: 1px solid #ccc;
        }

        .more-blogs .sub-menu li:last-child {
            border-bottom: none;
        }

        .more-blogs .caret {
            transition: transform 0.3s ease-in-out;
            display: inline-block;
            transform: rotate(0deg);
            font-size: 12px; /* Adjust the font size to change the caret size */
        }

        .more-blogs.expanded .caret {
            transform: rotate(90deg);
        }

        @media screen and (max-width: 768px) {
        .blog-post {
            padding: 10px; /* Adjust spacing for smaller screens */
        }
        .blog-post img {
            max-width: 80%; /* Reduce image size for smaller screens */
        }
        .box-index {
        display: none; /* Hide the index on smaller screens */
        }
    }

    </style>
</body>

</html>

<script>
    function toggleMoreBlogs() {
        var subMenu = document.querySelector('.more-blogs .sub-menu');
        var parentItem = document.querySelector('.more-blogs');
        subMenu.classList.toggle('expanded');
        parentItem.classList.toggle('expanded');
    }
</script>

