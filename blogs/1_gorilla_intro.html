<!DOCTYPE html>
<html>
<head>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-NRZJLJCSH6"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-NRZJLJCSH6');
    </script>


    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, shrink-to-fit=no">
    <title>Introduction to Gorilla LLM</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.5.0/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Source+Sans+Pro">
    <link rel="stylesheet" href="../assets/css/Highlight-Clean.css">
    <link rel="stylesheet" href="../assets/css/styles.css">
    <link rel="stylesheet" href="../assets/css/Team-Clean.css">

</head>

<body>
    <!-- Navigation Bar -->
    <div class="navbar" style="position: absolute; top: 0; right: 20px; padding: 10px; z-index: 100;; font-size: 18px;">
        <a href="/index.html">Home</a>
        <a href="/blog.html">Blogs</a>
        <a href="/leaderboard.html">BFCL Leaderboard</a>
        <!-- <a href="/apizoo/">API Zoo Index</a> -->
    </div>

    <div class="highlight-clean-blog" style="padding-bottom: 10px;">
        <h1 class="text-center" style="padding-bottom: 10px;"> ü¶ç Gorilla: Large Language Model Connected with Massive APIs</h1>

        <div class="box-index">
            <h3>Blog 1: Gorilla LLM</h3>
            <ul>
                <ul>
                    <li><a href="1_gorilla_intro.html#evolving-apis">Keeping up with frequently evolving data</a></li> 
                    <li><a href="1_gorilla_intro.html#llm-and-retrievers">LLMs and Retrievers</a></li> 
                    <li><a href="1_gorilla_intro.html#hallucination">Hallucination</a></li> 
                    <li><a href="1_gorilla_intro.html#try-gorilla">How to use Gorilla</a></li>
                    <li class="more-blogs">
                        <a href="javascript:void(0);" onclick="toggleMoreBlogs()">More Blogs <span class="caret">&#9654;</span></a>
                        <ul class="sub-menu">
                            <li><a href="2_hallucination.html">How to Measure Hallucination?</a></li>
                            <li><a href="3_retreiver_aware_training.html">Retrieval Aware Training (RAT)</a></li>
                            <!-- Add more blog entries as needed -->
                        </ul>
                    </li>                    
                </ul>
                <!-- Add more entries as needed -->
            </ul>
        </div>


        <div class="blog-container">
            <div class="blog-post">
                <h2 class="blog-title">Introduction to Gorilla LLM</h2>
                <div class="author-date">
                    <p class="author"> <a href="https://www.lisabdunlap.com/">Lisa Dunlap</a> </p>
                    <p class="date">Oct 3, 2023</p>
                </div>
                    <img src="../assets/img/blog_post_1_teaser.gif" alt="Gorilla introductory image" style="width: 95%;">
                    <p width="80%" style="text-align:center; margin-left:10%; margin-right:10%; padding-bottom: -10px">
                        <i style="font-size: 0.9em;">
                            Gorilla LLM can write accurate API calls, including Kubernetes, GCP, AWS, Azure, OpenAPI, and more. (Salesforce, servicenow, and datadog coming soon!) Gorilla outperforms GPT-4, Chat-GPT and Claude, significantly reducing hallucination errors. 
                        </i>
                    </p>

                <div class="preview">
                    <p>
                        Gorilla is designed to connect large language models (LLMs) with a wide range of tools, services, and applications exposed through APIs. Imagine if ChatGPT could interact with thousands of services ranging from Instagram and Doordash to tools like Google Calendar and Stripe to help you accomplish tasks.  You could ask to book a meeting for your collaborators, order their favorite foods, and pay for it. This may be how we interact with computers and even the web in the future.

                        Gorilla is an LLM that we train using a concept we call - retriever-aware training, that can pick the right API to perform a task, that a user can specify in natural language. We also introduce an Abstract Syntax Tree (AST) based sub-tree algorithm, which for the first time can measure hallucination of LLMs! 
                    </p>

                    <p>
                        The use of API's and Large Language Models(LLMs) has changed what it means to program. 
                        Previously, building complex models required extensive time and specialized skills. 
                        Now with tools like the HuggingFace API, an engineer can set up a deep learning pipeline 
                        with a few lines of code. Instead of searching through StackOverflow and sifting through documentation, 
                        developers can ask models like GPT for solutions and receive immediate, actionable code with docstrings. 
                        Yet, employing off-the-shelf LLMs to generate precise API calls is impractical as there are millions 
                        of available API's which are frequently updated.

                        Gorilla connects LLM's with API's, a system which takes in an instruction like "build me a classifier 
                        for medical images" and outputs the corresponding imports and API calls, along with a step-by-step 
                        explanation of the process. Gorilla uses self-instruct fine-tuning and retrieval to enable LLMs to 
                        accurately select from a large, overlapping, and changing set tools expressed using their APIs and 
                        API documentation. With the development of API generation methods comes a question of how to evaluate, 
                        as many APIs will have overlapping functionality with nuanced limitations and constraints. Thus, we 
                        construct APIBench, a large corpus of APIs including Kubernetes, AWS, GCP, Azure, GitHub, Conda, Curl, 
                        Sed, Huggingface, Tensorflow, Torch Hub, and develop a novel evaluation framework which uses sub-tree 
                        matching to check functional correctness and measures hallucination. 

                    </p>
                </div>

                <div class="body">
                    <p>
                        Using APIBench, we trained Gorilla, an Apache 2.0 licensed, 7B LLM model with document retrieval and show that it significantly 
                        outperforms both open-source and closed-source models like Claude and GPT-4 in terms of API functionality 
                        accuracy as well as a reduction in API argument hallucination errors. 
                    </p>
                </div>


                <!-- APIs change frequently -->
                <p style="text-align: center; margin-bottom: 0">
                    <img src="../assets/img/blog_post_1_apichange.png" alt="APIs change frequently" width="95%">
                    <br>
                </p>
                <p width="80%" style="text-align:center; margin-left:10%; margin-right:10%; padding-bottom: -10px">
                    <i style="font-size: 0.9em;">
                        APIs evolve frequently! For example, there were 31 API modifications for AWS APIs just yesterday.
                    </i>
                </p>

                <h4 id="evolving-apis"> Keeping up with frequently evolving data</h4>
                <div class="body">
                    <p>
                        APIs are known to evolve frequently - more frequently than it is possible to re-train LLMs. So, how can LLMs keep up with this, and not serve the user out-lawed APIs? To handle this, Gorilla, can be used for inference in two modes: <em>zero-shot</em> and <em>with retrieval</em>. In zero-shot, during inference, user provides the prompt in natural language. This can be for a simple task (e.g, "I would like to identify the objects in an image"), or you can specify a vague goal, (e.g, "I am going to the zoo, and would like to track animals"). This prompt (with NO further prompt tuning) is fed to the Gorilla LLM model which then returns the API call that will help in accomplishing the task and/or goal. 
                        In retrieval mode, the retriever first retrieves the most up-to-date API documentation stored in APIZoo, an API Database for LLMs.
                        Before being sent to Gorilla, the API documentation is concatenated to the user prompt along with the message "Use this API documentation for reference:"  The output of Gorilla is an API to be invoked. The retriever aware inference mode, enables Gorilla to be robust to frequent changes in APIs! We have open-sourced our APIZoo, and in our continued commitment to the open-source community, today we've released an additional ~20k meticulously documented APIs including KubeCtl, GCP, Azure, AWS, GitHub, etc. We will continue to add more APIs to APIZoo, and welcome contributions from the community!
                    </p>

                </div>


                <!-- Retrievers and LLMs  -->
                <p style="text-align: center; margin-bottom: 0">
                    <img src="../assets/img/blog_post_1_inference.jpg" alt="Gorilla can be used in zero-shot and with retrievers" width="95%">
                    <br>
                </p>
                <p width="80%" style="text-align:center; margin-left:10%; margin-right:10%; padding-bottom: -10px">
                    <i style="font-size: 0.9em;">
                        Gorilla, can be used for inference in two modes: <em>zero-shot</em> and <em>with retrieval</em>. In zero-shot, the prompt is directly fed to the Gorilla LLM model. 
                        In retrieval mode, the retriever first retrieves the most up-to-date API documentation stored in APIZoo. 
                    </i>
                </p>

                <h4 id="llm-and-retrievers">Love at First Query: The Untold Bond of LLMs and Retrievers</h4>
                <div class="body">
                    <p>
                        If you are deploying LLMs in production today, you might be
                        augmenting your model with retrievers such as in Retriever Augmented Generation (RAG) paradigms. Given, most LLMs today are used with retrievers, shouldn't the training recipe for the LLM consider this!! In Gorilla, we consider retrievers to be first class citizens, and train our models to be <em>retriever aware</em>. If you are thinking about integrating LLMs with llamaindex, vector databases such as Weviate, etc check out our blog post on <a class="continue-link" href="blogs/blog_post_2_rat.html"> Retrieval Aware Training (RAT)</a> where we teach LLMs to "work-together" with retrievers! 
                    </p>
                </div>


                <!-- Gorilla side by side comparison -->
                <p style="text-align: center; margin-bottom: 0">
                    <img src="../assets/img/blog_post_1_result.png" alt="How well does Gorilla perform" width="65%">
                    <br>
                </p>
                <p width="80%" style="text-align:center; margin-left:10%; margin-right:10%; padding-bottom: -10px">
                    <i style="font-size: 0.9em;">
                        Examples of API calls. In this example, for the given prompt GPT-4 presents a model that doesn't exist, and Claude picks an incorrect library. In contrast, our Gorilla model can identify the task correctly and suggest a fully-qualified API call.
                    </i>
                </p>

                <h4 id="hallucination">Reality Bytes: When LLMs See Things That Aren't There</h4>
                <div class="body">
                    <p>
                        Hallucination is the center of discussions for all things LLMs. In the context of API generation, hallucination can be defined as the model generating API calls that do not exist. An LLM generation can be in-accurate or it could be hallucinated. One does not mean the other. For example, if the user asks for a classifier for medical images, if the model generates a Stripe API call for a image classifier - it is hallucination, since it doesn't exist! On the other hand, if the model recommends to use the Stripe API for checking your balance, it is an incorrect usage of the API, but at least not made up (noh-hallucinated). In our blog <a href=""></a> we describe Gorilla's innovative approach of using Abstract Syntax Trees (ASTs) to measure hallucination of the generated API calls. 
                        Though not generalizable to all tasks, to the best of our knowledge, Gorilla is the first to measure and quantify hallucination for LLM generations! 

                    </p>
                </div>
                <h4 id="try-gorilla">How to use Gorilla?</h4>
                <div class="body">
                    <p>
                        Gorilla is a open-source artifact from UC Berkeley! You can try Gorilla in a few different ways. The easiest is through our <a href="https://colab.research.google.com/drive/1y78Zj7xHysX0xMpr9S468HYs12Mj6X1F?usp=sharing" >Colab notebook</a>. Our hosted Gorilla model can be a drop in replacement for your OpenAI Chatcompletion API calls. Here is a <a href="https://colab.research.google.com/drive/1jyRIHQkfI8lnEi2rjJYoUQ2sV4PC1Gfz?usp=sharing">Colab notebook</a> notebook, demonstrating how you could use Gorilla along with Langchain agents. For those of you who are interested in playing around with our models, or would like to host it yourself, the Gorilla models are open-sourced and available on <a href="https://huggingface.co/gorilla-llm">HuggingFace</a>. You can also try Gorilla in your CLI - the most popular way to use Gorilla! Just <em>pip install gorilla-cli</em> to talk to your command line in plane english and  have Gorilla come up with the right CLI command for you!
                    </p>
                    <hr class="post-separator">

                    <p>
                        We hope you enjoyed this blog post. We would love to hear from you on <a href="https://discord.gg/grXXvj9Whz">Discord</a>, <a href="https://twitter.com/shishirpatil_/status/1661780076277678082">Twitter (#GorillaLLM)</a>, and <a href="https://github.com/ShishirPatil/gorilla/">GitHub</a>.<br> 

                        This post was authored by Lisa Dunlap, who is a PhD student at UC Berkeley advised by Joey Gonzalez in Sky Computing Lab and Trevor Darrell in BAIR. Lisa's research focuses on evaluating, advising, and monitoring vision models from a data-centric angle, and is currently working on making vision models more robust with language, training on low-quality datasets, and discovering concepts in large scale datasets. 
                    </p>
                    <p id="gorilla-bibtex">
                        If you would like to cite Gorilla:<br>
                        @inproceedings{patil2023gorilla,
                        &nbsp; 	title={Gorilla: Large Language Model Connected with Massive APIs},
                        &nbsp; 	author={Shishir G. Patil and Tianjun Zhang and Xin Wang and Joseph E. Gonzalez},
                        &nbsp; 	year={2023},
                        &nbsp;	journal={arXiv preprint arXiv:2305.15334}
                    }</p>
                </div>
            </div>
        </div>
    </div>

    <style>
        body {
            font-family: 'Source Sans Pro', sans-serif;
            margin: 0;
            padding: 0;
            background: white;
            justify-content: center;
            align-items: center;
        }
        .blog-container {
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
        }
        .blog-post {
            margin: 20px;
            padding: 20px;
            max-width: 1000px; 
            justify-content: center;
        }
        .blog-post img {
            display: block;
            margin: 0 auto;
        }
        .blog-title{
            color: #055ada;
            text-align: center;
        }

        .author-date {
                display: flex;
                margin-bottom: 0px;
                justify-content: center; 
        }
        .author {
                font-size: 16px;
                color: #1E90FF;
                margin-right: 20px;
        }

        .date {
            font-size: 16px;
            color: #7e8790;
        }

        .preview {
            text-align: justify; 
            text-justify: inter-word; 
        }

        .highlight-clean-blog {
            color: #313437;
            background-color: #fff;
            padding: 50px 0;
        }

        .box-index {
        position: fixed;
        top: 50%; 
        left: 0px; 
        transform: translateY(-50%);
        background-color: #f9f9f9;
        padding: 20px;
        border-radius: 8px;
        box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
        max-width: 150px;
        }

        .box-index h3 {
        font-size: 1.2em;
        margin-bottom: 10px;
        }

        .box-index ul {
        list-style-type: disc;
        padding: 0;
        }

        .box-index ul li {
        margin-bottom: 10px;
        }

        .box-index ul li a {
        text-decoration: none;
        color: #333;
        }

        .box-index ul li a:hover {
        color: #1E90FF;
        }

        .more-blogs .sub-menu {
            display: none;
        }

        .more-blogs .sub-menu.expanded {
            display: block;
            max-height: 200px; /* Adjust the max height as needed */
            overflow-y: auto;
        }

        .more-blogs .sub-menu li {
            padding: 10px;
            border-bottom: 1px solid #ccc;
        }

        .more-blogs .sub-menu li:last-child {
            border-bottom: none;
        }

        .more-blogs .caret {
            transition: transform 0.3s ease-in-out;
            display: inline-block;
            transform: rotate(0deg);
            font-size: 12px; /* Adjust the font size to change the caret size */

        }

        .more-blogs.expanded .caret {
            transform: rotate(90deg);
        }

        @media screen and (max-width: 768px) {
        .blog-post {
            padding: 10px; /* Adjust spacing for smaller screens */
        }
        .blog-post img {
            max-width: 80%; /* Reduce image size for smaller screens */
        }
        .box-index {
            display: none; /* Hide the index on smaller screens */
        }
    }

    </style>
</body>
</html>

<script>
    function toggleMoreBlogs() {
        var subMenu = document.querySelector('.more-blogs .sub-menu');
        var parentItem = document.querySelector('.more-blogs');
        subMenu.classList.toggle('expanded');
        parentItem.classList.toggle('expanded');
    }
</script>