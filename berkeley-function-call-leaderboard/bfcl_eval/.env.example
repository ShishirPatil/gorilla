# Provide the API key for the model(s) you intend to use
OPENAI_API_KEY=sk-XXXXXX
MISTRAL_API_KEY=
FIREWORKS_API_KEY=
ANTHROPIC_API_KEY=
NVIDIA_API_KEY=nvapi-XXXXXX
DEEPSEEK_API_KEY=sk-XXXXXX
# We use Alibaba Cloud (aliyun.com) to inference Qwen models
QWEN_API_KEY=sk-XXXXXX
GLM_API_KEY=sk-XXXXXX
KIMI_API_KEY=sk-XXXXXX
YI_API_KEY=
COHERE_API_KEY=
GROK_API_KEY=xai-XXXXXX
GOGOAGENT_API_KEY=
WRITER_API_KEY=
MINING_BASE_URL=XXXXXX
MINING_API_KEY=sk-XXXXXX
DMCITO_BASE_URL=XXXXXX
DMCITO_API_KEY=sk-XXXXXX

# We use Google AI Studio to inference Google Gemini models
GOOGLE_API_KEY=

AWS_ACCESS_KEY_ID=
AWS_SECRET_ACCESS_KEY=

DATABRICKS_API_KEY=
DATABRICKS_AZURE_ENDPOINT_URL=

# [OPTIONAL] For inference via Novita AI endpoint
NOVITA_API_KEY=sk-XXXXXX

# We use the API Key from Alipay to inference Bailing (Ling) models (see https://zxb.alipay.com/llm/landing)
LING_API_KEY=sk-XXXXXX

# [OPTIONAL] For local vllm/sglang server configuration
# Defaults to localhost port 1053 if not provided
VLLM_ENDPOINT=localhost
VLLM_PORT=1053

# [OPTIONAL] Required for WandB to log the generated .csv in the format 'entity:project
WANDB_BFCL_PROJECT=ENTITY:PROJECT